from cnvrgv2.modules.labels.utils import LabelColor

# COMMON
CLI_UNEXPECTED_ERROR = "Unexpected error while executing command. details: {0}"
OUTPUT_DIR_LOCATION = "the location of the output directory"
PAGE_SIZE_HELP = "The size of Page to load"
SORT_HELP = "key to sort the list by (-key -> DESC | key -> ASC)"
# LOGIN
LOGIN_PROMPT_DOMAIN = "Please enter your cnvrg domain"
LOGIN_PROMPT_EMAIL = "Please enter your email"
LOGIN_PROMPT_PASSWORD = "Please enter your password"
LOGIN_HELP_AUTH_TOKEN = "Enter authentication token instead of password"
LOGIN_ORGANIZATION_HELP = "Organization to log in to"
LOGIN_ALREADY_LOGGED_IN = "Seems you\'re already logged in"
LOGIN_SUCCESS = "Successfully logged in as {0}"
LOGIN_INVALID_CREDENTIALS = "Invalid credentials"

# LOGOUT
LOGOUT_SUCCESS = "Logged out successfully"
LOGOUT_CONFIG_MISSING = "Cannot logout. Config file is missing. Try logging in first"

# ME
ME_SUCCESS_API = "API: {0}/api/v2"
ME_SUCCESS_LOGS = "Logs file located at: {0}"
ME_SUCCESS = "Logged in as: {0}"
ME_LOGGER_SUCCESS = "Successfully printed user's details (cnvrgv2 me)"

# DATA OWNER
DATA_UPLOAD_SUCCESS = "Successfully uploaded updated files"
DATA_DOWNLOAD_SUCCESS = "Successfully downloaded updated files"
DATA_COMMIT_MESSAGE = "Commit message"
DATA_UPLOAD_HELP_GIT_DIFF = "From the list of files, upload those who returned from git diff command."
DATA_UPLOAD_HELP_FORCE = "Enable to create an empty commit without files from parent commit."
DATA_UPLOAD_HELP_OVERRIDE = "Enable to re-upload even if the file already exists."
DATA_LOCATION_IN_STORAGE = "Specify the destination directory for saving uploaded files on cnvrg"
DATA_UPLOAD_HELP_THREADS = "Number of threads that will be used to preform the upload"
DATA_UPLOAD_HELP_CHUNKS = "Number of chunks that will be used to preform the upload"
DATA_PROMPT_COMMIT = "Please enter sha1 to clone"
DATA_PROMPT_CACHE = "Please enter sha1 to cache"
DATA_DOWNLOAD_ERROR = "Unexpected error while executing command"
SYNC_OUTPUT_DIR = "The directory that will be synced inside the project"
DEBUG_MODE_HELP = "Enable to create start commit in debug mode"
CLONE_NUMBER_OF_THREADS = "Number of threads that will be used to preform the clone"
QUERY_SLUG = "Query slug"

# DATASET
DATASET_PROMPT_CLONE = "Please enter dataset name to clone"
DATASET_HELP_CLONE = "Name of the dataset to clone"
DATASET_HELP_CACHE = "Name of the dataset to cache"
DATASET_HELP_UNCACHE = "Name of the dataset to uncache"
DATASET_HELP_CLONE_OVERRIDE = "Whether or not re-clone in case the dataset already cloned"
DATASET_HELP_CLONE_COMMIT = "The commit sha1 to clone"
DATASET_CLONE_SKIP = "Dataset {0} is already cloned, therefore skip clone." \
                     " If you want to override, run again using -o flag."
DATASET_PROMPT_NAME = "Please enter dataset name"
DATASET_PROMPT_DISK_NAME = "Please enter disk name"
DATASET_HELP_NAME = "Name of the dataset"
DATASET_CLONE_SUCCESS = "Successfully cloned dataset: {0}"
DATASET_PUT_PROMPT_FILES = "Please enter a comma separated list of file paths to upload. use . " \
                           "to upload the whole directory"
DATASET_PUT_HELP_FILES = "A comma separated list of file paths to upload. use . " \
                         "to upload the whole directory"
DATASET_REMOVE_PROMPT_FILES = "Please enter a comma separated list of file paths to remove. Wildcards allowed"
DATASET_REMOVE_HELP_FILES = "A comma separated list of file paths to remove. use Wildcards allowed"
DATASET_REMOVE_SUCCESS = "Files removed successfully"
DATASET_PROMPT_DELETE = "Please enter dataset name to delete"
DATASET_HELP_DELETE = "Name of the dataset to delete"
DATASET_HELP_LABELS__NAME = "Name of the dataset."
DATASET_HELP_LABELS__LABEL_NAME = "Name of the label."
DATASET_HELP_LIST_FILES = "Name for the dataset"
DATASET_HELP_LIST_FILES_LENGTH = "Number of files to display"
DATASET_DELETE_CONFIRM = "Are you sure you want to delete dataset: {0}?"
DATASET_DELETE_SUCCESS = "Successfully deleted dataset: {0}"
DATASET_ADD_LABEL_SUCCESS = "Successfully assigned label {0} to dataset: {1}"
DATASET_REMOVE_LABEL_SUCCESS = "Successfully removed label from dataset: {0}"
DATASET_SYNC_SUCCESS = "Successfully synced dataset {0}"
DATASET_PROMPT_CREATE = "Please enter dateset name to create"
DATASET_HELP_CREATE = "Name for the new dataset"
DATASET_CREATE_FOLDER_NOT_EMPTY = "Warning! You're about to associate a non empty folder with the new dataset." \
                                  "\r\nContinue?"
DATASET_CREATING_MESSAGE = "Creating new dataset"
DATASET_CONFIGURING_FOLDER = "Configuring dataset folder"
DATASET_CREATE_SUCCESS = "Successfully created dataset:" \
                         "\r\nDataset name: {0}" \
                         "\r\nDataset slug: {1}"
DATASET_SCAN_START = "Scanning datasets"
DATASET_LIST_FILES_HELP_CHUNK_SIZE = "Number of files to show in each print"
DATASET_LIST_FILES_HELP_LIMIT = "Limit the number of files"
DATASET_SCAN_NO_RESULTS = "No datasets found in working dir"
DATASET_VERIFY_STATUS = "Success: {0}"
DATASET_UNCACHE_SUCCESS = "Dataset successfully uncached"
DATASET_CACHE_SUCCESS = "Dataset successfully cached"
DATASET_NAMES = "Dataset names"
DATASET_NAMES_HELP = "Dataset names to verify"
DATASET_VERIFY_TIMEOUT = "Timeout"

# PROJECT
PROJECT_PROMPT_CLONE = "Please enter project name to clone"
PROJECT_HELP_CLONE = "Name of the project to clone"
PROJECT_PROMPT_DELETE = "Please enter project name to delete"
PROJECT_HELP_DELETE = "Name of the project to delete"
PROJECT_HELP_LIST_FILES = "Name of the project"
PROJECT_HELP_LABELS__NAME = "Name of the project"
PROJECT_HELP_LABELS__LABEL_NAME = "Name of the label."
PROJECT_HELP_CLONE_OVERRIDE = "Whether or not re-clone in case the project already cloned"
PROJECT_HELP_CLONE_COMMIT = "The commit sha1 to clone"
PROJECT_CLONE_SKIP = "Project {0} is already cloned, therefore skip clone." \
                     " If you want to override, run again using -o flag."
PROJECT_CLONE_SUCCESS = "Successfully cloned project: {0}"
PROJECT_DELETE_SUCCESS = "Successfully deleted project: {0}"
PROJECT_ADD_LABEL_SUCCESS = "Successfully assigned label {0} to project: {1}"
PROJECT_REMOVE_LABEL_SUCCESS = "Successfully removed label from project: {0}"
PROJECT_DELETE_CONFIRM = "Are you sure you want to delete project: {0}?"
PROJECT_DOWNLOAD_SUCCESS = "Successfully downloaded updated files"
PROJECT_LINK_PROMPT_NAME = "Please enter a name for the new project"
PROJECT_LINK_HELP_NAME = "Name for the new project"
PROJECT_PROMPT_NAME = "Please enter project name"
PROJECT_HELP_NAME = "Name of the project"
PROJECT_LINK_GIT_PROMPT_NAME = "Please enter the name of the git project"
PROJECT_LINK_GIT_HELP_NAME = "Name of the git project"
SOFT_LINK_GIT_PROJECT = "Link the git project, if it hasn't done before"
PROJECT_GIT_LINK_SKIP = "Project {0} is already linked, therefore skip linking"
PROJECT_JOB_SLUG_HELP_NAME = "Slug of the job"
PROJECT_SLUG_HELP_TITLE = "The slug of the project"
PROJECT_LINK_SUCCESS = "Finished linking project {0} successfully."
PROJECT_CREATE_NEW = "Creating new project {0}"
PROJECT_CONFIGURING_FOLDER = "Configuring project folder"
PROJECT_UPLOAD = "Uploading project files"
PROJECT_PROMPT_CREATE = "Please enter project name to create"
PROJECT_HELP_CREATE = "Name for the new project"
PROJECT_CREATE_FOLDER_NOT_EMPTY = "Warning! You're about to associate a non empty folder with the new project." \
                                  "\r\nContinue?"
PROJECT_CREATING_PROJECT = "Creating new project {0}"
PROJECT_CREATE_SUCCESS = "Successfully created project {0}"
PROJECT_SYNC_SUCCESS = "Successfully synced project {0}, commit_sha1: {1}"
PROJECT_IS_UP_TO_DATE = "\N{check mark} Project {0} is up to date"
PROJECT_HELP_CURRENT_DIR = "Wheteher or not to clone into the current directory"

# FILES
FILES_UPLOAD_SUCCESS = "Successfully uploaded files"
COMMIT_SHA1_MESSAGE = "Commit sha1: {0}"

# LIBRARIES
LIBRARY_PROMPT_CLONE = "Please enter library name to clone"
LIBRARY_VERSION_PROMPT_CLONE = "Please enter library version name to clone (default = \"latest\")"
LIBRARY_CLONE_SKIP = "Library {0} is already cloned, skipping action"
LIBRARY_CLONE_SUCCESS = "Successfully cloned library: {0}"

# MEMBERS
MEMBER_ADDED_SUCCESS = "{0} was added successfully with role {1}"
MEMBER_UPDATED_SUCCESS = "{0} was updated successfully to role {1}"
MEMBER_ENTER_EMAIL = "Please enter a valid user email"
MEMBER_HELP_EMAIL = "A valid email of exists user"
MEMBER_ENTER_ROLE = "Please enter a valid role [admin, manager, member, reviewer]"
MEMBER_HELP_ROLE = "A role for the user, must be one of the following: admin, manager, member, reviewer"
MEMBER_REMOVED_SUCCESS = "{0} was removed successfully"

# EXPERIMENT
EXPERIMENT_PROMPT_TITLE = "Please enter a title for the experiment"
EXPERIMENT_PROMPT_COMMIT = "Please enter commit to merge"
EXPERIMENT_ARTIFACTS_PROMPT_COMMIT = "Please enter commit"
EXPERIMENT_HELP_COMMIT = "Commit sha1 to merge"
EXPERIMENT_ARTIFACTS_HELP_COMMIT = "Commit sha1 of artifacts"
EXPERIMENT_HELP_TITLE = "Name of the experiment"
EXPERIMENT_HELP_TEMPLATES = "Comma separated list of template names"
EXPERIMENT_HELP_LOCAL = "Boolean. Run the experiment locally"
EXPERIMENT_PROMPT_COMMAND = "Please enter a command to run as experiment"
EXPERIMENT_HELP_COMMAND = "The command to run"
EXPERIMENT_HELP_DATASETS = "List of dictionaries containing slug, commit sha1 or query"
EXPERIMENT_HELP_DATASOURCES = "List of datasource slugs"
EXPERIMENT_HELP_VOLUME = "A volume name to attach to this experiment"
EXPERIMENT_HELP_SYNC_BEFORE = "Boolean. Sync environment before running the experiment"
EXPERIMENT_HELP_SYNC_AFTER = "Boolean. sync environment after the experiment finished"
EXPERIMENT_HELP_IMAGE = "Image name and tag to create experiment with. format - image_name:tag"
EXPERIMENT_HELP_GIT_BRANCH = "The branch to pull files from for the experiment, in case project is git project"
EXPERIMENT_HELP_GIT_COMMIT = "The commit to pull files from for the experiment, in case project is git project"
EXPERIMENT_HELP_GRID = "Run a grid search using a YAML file outlining the parameters"
EXPERIMENT_HELP_LOCAL_FOLDERS = "Local folders to mount with experiment"
EXPERIMENT_CREATE_SUCCESS = "Experiment {0} created successfully. \r\nExperiment is available at: {1}"
EXPERIMENT_GRID_CREATE_SUCCESS = "Grid {0} created successfully. \r\nGrid is available at: {1}"
EXPERIMENT_MERGE_SUCCESS = "Commit successfully merged to master"
EXPERIMENT_GIT_ERROR_MESSAGE = "Cannot merge commits for git projects"
EXPERIMENT_DATASET_QUERY_ERROR_MESSAGE = "Cant use commit and query for dataset {0}, please use only one"
EXPERIMENT_DOES_NOT_EXIST = "Couldn't find experiment. Try with env variables or passing --slug"
EXPERIMENT_LOG_ARTIFACTS_SUCCESS = "Successfully logged artifacts"
EXPERIMENT_LOG_IMAGES_SUCCESS = "Successfully logged images"
EXPERIMENT_PULL_ARTIFACTS_SUCCESS = "Successfully pulled artifacts"
EXPERIMENT_HELP_WORK_DIR = "Working Dir to upload files to"
EXPERIMENT_HELP_OUTPUT_DIR = "Sets the output folder for cnvrg to track experiment artifacts"
EXPERIMENT_DELETE_ARTIFACTS = "Delete related artifacts from the storage"
EXPERIMENT_DELETE_SUCCESS = "Successfully deleted experiment"
EXPERIMENT_DELETE_ARTIFACTS_PROMPT = "This action will delete related artifacts from the storage. Are you sure?"
EXPERIMENT_DELETE_ARTIFACTS_ABORTED = "User aborted delete experiments"
EXPERIMENT_HELP_LOG = "Display the log of the experiment"
EXPERIMENT_HELP_WAIT = "Wait for the experiment to finish"

# LOGS
LOG_START_COMMAND = "Starting command {0}. Options: {1}"
LOG_CLONING_PROJECT = "Cloning project: {0}"
LOG_CLONING_LIBRARY = "Cloning library: {0}=={1}"
LOG_CLONING_DATASET = "Cloning dataset: {0}"
LOG_LIST_FILES_PROJECT = "List files from project: {0}"
LOG_LIST_FILES_DATASET = "List files from dataset: {0}"
LOG_LIST_LABELS_DATASET = "List labels from dataset: {0}"
LOG_LIST_LABELS_PROJECT = "List labels from project: {0}"

# SSH
SSH_HELP_PORT = "Port to bind on host"
SSH_HELP_USERNAME = "Username to login in container, default will be image default user"
SSH_HELP_PASSWORD = "Password for login"
SSH_HELP_KUBECTL = "Full path to kubeconfig file, otherwise default will be used"
SSH_STARTING_SESSION = "Starting a new ssh session"
SSH_WAITING_FOR_READY = "Waiting for ssh session to be ready..."
SSH_READY = "\r\nSsh session is ready to receive connections.\r\n" \
            "\r\nIn order to connect to your job, define your ssh connection with the following params:\r\n" \
            "host: 127.0.0.1\r\n" \
            "port: {0}\r\n" \
            "username: {1}\r\n" \
            "password: {2}"

# WORKSPACE
WORKSPACE_DOES_NOT_EXIST = "Workspace was not found, check env or pass slug"
WORKSPACE_SLUG = "Slug of the workspace"
WORKSPACE_HELP_SYNC_REMOTE = "Sync the workspace"
WORKSPACE_HELP_DATASETS = "List of comma separated datasets names to use in the workspace"
WORKSPACE_HELP_DATASOURCE = "List datasource slugs"
WORKSPACE_HELP_VOLUME = "A volume name to attach to this workspace"
WORKSPACE_HELP_GIT_BRANCH = "The branch to pull files from for the workspace, in case project is git project"
WORKSPACE_HELP_GIT_COMMIT = "The commit to pull files from for the workspace, in case project is git project"
WORKSPACE_HELP_TEMPLATES = "Comma separated list of template names"
WORKSPACE_HELP_NOTEBOOK_TYPE = "The type of the created notebook"
WORKSPACE_HELP_TITLE = "Name of the workspace"
WORKSPACE_HELP_IMAGE = "Image name and tag to create workspace with. format - image_name:tag"
WORKSPACE_CREATE_SUCCESS = "Workspace {0} created successfully. \r\nWorkspace is available at: {1}"
WORKSPACE_HELP_COMMIT = "Sha1 of the commit to use, default: latest"
WORKSPACE_HELP_LOCAL_FOLDERS = "Local folders to mount with workspace"

# DATASOURCE
DATASOURCE_SLUG_HELP = "The slug of the requested datasource"
DATASOURCE_SLUG = "The slug of the datasource"
DATASOURCE_PAGE_SIZE_HELP = "Page size: The size of each individual page downloaded"
DATASOURCE_MAX_WORKERS_HELP = "Max number of workers that clone the datastore at the same time"
DATASOURCE_LOCAL_DIRECTORY_HELP = "When true, The files will be downloaded directly to the current local directory"
DATASOURCE_NAME = "The given name of the datasource"
DATASOURCE_NAME_HELP = "Provide a unique name for the datasource you are creating"
DATASOURCE_TYPE = "The storage type"
DATASOURCE_TYPE_HELP = "Storage type (like: s3...)"
DATASTORE_BUCKET = "The name of the bucket associated with the datasource"
DATASTORE_BUCKET_HELP = "Name the bucket you wish to be associated with the datasource"
DATASOURCE_CREDENTIALS = "Credentials to the datasource"
DATASOURCE_CREDENTIALS_HELP = "Credentials to the datasource in form of a dictionary"
DATASOURCE_REGION = "The region of the bucket associated with the datasource"
DATASOURCE_REGION_HELP = "The region of the bucket associated with the datasource"
DATASOURCE_DESCRIPTION = "Description"
DATASOURCE_DESCRIPTION_HELP = "Description"
DATASOURCE_PUBLIC = "Is the datasource public?"
DATASOURCE_PUBLIC_HELP = "Is the datasource public?"
DATASOURCE_PATH = "The Path for items within the datasource"
DATASOURCE_PATH_HELP = "The Path for items within the datasource"
DATASOURCE_ENDPOINT = "The endpoint of the service associated with the datasource"
DATASOURCE_ENDPOINT_HELP = "The endpoint of the service associated with the datasource"
DATASOURCE_USERS = "The users with permissions to the datasource"
DATASOURCE_USERS_HELP = "The users with permissions to the datasource (a list of emails)"
DATASOURCE_FORCE = "Force re-cloning datasource. Note: All previous local data will be removed!"
DATASOURCE_IGNORE_FILE_ERROR = "Ignore the cloning request of the datasource if it already exists"

# WEBAPP
WEBAPP_HELP_SLUG = "Slug of the webapp"
WEBAPP_HELP_FREQUENCY = "The frequency to pull the logs event in seconds"

# ENDPOINT
ENDPOINT_DOES_NOT_EXIST = "Endpoint was not found, check env or pass slug"
ENDPOINT_SLUG = "Slug of the endpoint"
ENDPOINT_HELP_VERSION_SLUG = "Slug of the version to rollback to"
ENDPOINT_PROMPT_METRIC_NAME = "Please enter the metric name"
ENDPOINT_PROMPT_METRIC_X = "Please enter the metric x value"
ENDPOINT_PROMPT_METRIC_Y = "Please enter the metric y value"
ENDPOINT_PROMPT_FUNCTION_NAME = "Please enter The name of the function the endpoint will route to"
ENDPOINT_PROMPT_FILE_NAME = "Please enter the file name"
ENDPOINT_PROMPT_TITLE_NAME = "Please enter the endpoint title name"
ENDPOINT_METRIC_NAME = "The metric name"
ENDPOINT_METRIC_X = "The metric x value"
ENDPOINT_METRIC_Y = "The metric y value"
ENDPOINT_ROLLBACK_SUCCESS = "Endpoint {0} rollback to version slug {1} successfully"
ENDPOINT_UPDATE_SUCCESS = "Endpoint {0} updated successfully"
ENDPOINT_HELP_ARGS = "Optional arguments in key=value format. Partial list:\t\t\ngeneric_command=<Command to run the service>"
ENDPOINT_HELP_MAX_TIMEOUT = "Time in minutes to wait until timeout"
ENDPOINT_HELP_PREP_FUNCTION = "Name of new preprocess function"
ENDPOINT_HELP_PREP_FILE = "Name of new preprocess file"
ENDPOINT_HELP_FUNCTION_NAME = "The name of the function the endpoint will route to"
ENDPOINT_HELP_FILE_NAME = "The file containing the endpoint's functions"
ENDPOINT_UPDATE_IN_PROGRESS = "Updating endpoint..."
ENDPOINT_HELP_TITLE = "Name of the endpoint"
ENDPOINT_HELP_KIND = "The endpoint kind"
ENDPOINT_HELP_ENV_SETUP = "The interpreter to use python_2,python_3,pyspark,r_endpoint"
ENDPOINT_HELP_TEMPLATES = "Comma separated list of template names"
ENDPOINT_HELP_KAFKA_BROKERS = "Comma separated list of kafka brokers"
ENDPOINT_HELP_KAFKA_INPUT_TOPICS = "Comma separated list of kafka input topics"
ENDPOINT_CREATE_SUCCESS = "Endpoint {0} created successfully. \r\nEndpoint is available at: {1}"
ENDPOINT_PROMPT_LOG_MESSAGE = "Please enter the log messages, separated by comma"
ENDPOINT_HELP_LOG_MESSAGE = "Comma separated list of logs to write to endpoint"
ENDPOINT_HELP_LOGS_TYPE = "Level of the logs , default: output. [output, error, warning, info]"
ENDPOINT_LOG_LEVEL_NOT_SUPPORTED = "Log level {0} not supported, supported levels: output, error, warning, info"
ENDPOINT_NO_PREDICTIONS = "No predictions were found for endpoint"
ENDPOINT_HELP_MODEL_NUMBER = "The endpoint model number to query"
ENDPOINT_HELP_BATCH_SIZE = "The batch size of predictions to return"
ENDPOINT_HELP_OFFSET = "The offset of the predictions to return"
ENDPOINT_HELP_END_TIME = "The end time of the predictions to return"
ENDPOINT_HELP_START_TIME = "The start time of the predictions to return"

# FLOWS
FLOW_YAML_PATH = "Path to yaml file, describing the new flow"
FLOW_CREATE_SUCCESS = "Flow {0} created successfully."

# CONFIG
CONFIG_HELP_CHECK_CERTIFICATE = "{0} ssl validation on https requests"
CONFIG_UPDATE_SUCCESS = "Config updated successfully"
CONFIG_HELP_ORGANIZTION = "Name of organization to switch to"
CONFIG_NO_ARGS_LOG = "No arguments sent. Showing help message instead"

# IMAGE
IMAGE_HELP_TAG = "Image tag"
IMAGE_HELP_SLUG = "Image slug"
IMAGE_HELP_NAME = "Image repository name"
IMAGE_HELP_LOGO = "Image logo"
IMAGE_HELP_CUSTOM = "Is custom image (requires dockerfile)"
IMAGE_HELP_README = "Readme path for the image"
IMAGE_HELP_REGISTRY = "Image registry"
IMAGE_HELP_DOCKERFILE = "Dockerfile path to build a custom image"

IMAGE_PROMPT_TAG = "Please enter image tag"
IMAGE_PROMPT_SLUG = "Please enter image slug"
IMAGE_PROMPT_NAME = "Please enter image name (repository)"
IMAGE_PROMPT_LOGO = "Please enter image logo"
IMAGE_PROMPT_REGISTRY = "Please enter image registry"

IMAGE_INVALID_README = "Readme path is invalid"
IMAGE_INVALID_DOCKERFILE = "Dockerfile path is invalid"

IMAGE_CREATE_SUCCESS = "Successfully created image {0}"

# REGISTRY
REGISTRY_HELP_URL = "Registry url"
REGISTRY_HELP_TYPE = "Registry type (cnvrg, dockerhub, gcr, acr, ecr, ...)"
REGISTRY_HELP_SLUG = "Registry slug"
REGISTRY_HELP_TITLE = "Registry title"
REGISTRY_HELP_USERNAME = "Registry username for private registries"
REGISTRY_HELP_PASSWORD = "Registry password for private registries"

REGISTRY_PROMPT_URL = "Please enter registry url"
REGISTRY_PROMPT_TITLE = "Please enter registry tag"

REGISTRY_CREATE_SUCCESS = "Successfully created registry {0}"

# LABELS
LABEL_HELP_KIND = "Label kind (projects, datasets)"
LABEL_HELP_NAME = "Label name"
LABEL_HELP_COLOR_NAME = "Label color. available colors: {0}".format(LabelColor.ALL_COLORS)

LABEL_PROMPT_KIND = "Please enter the kind (either 'projects' or 'datasets')"

LABEL_CREATE_SUCCESS = "Successfully created label {0}"
LABEL_DELETE_SUCCESS = "Successfully deleted dataset: {0}"

# ORGANIZATION SETTINGS
ORGANIZATION_SETTINGS_HELP_DEFAULT_COMPUTES = "Default computes"
ORGANIZATION_SETTINGS_HELP_INSTALL_DEPENDENCIES = "Install dependencies"
ORGANIZATION_SETTINGS_HELP_SLACK_WEBHOOK_URL = "Slack webhook URL"
ORGANIZATION_SETTINGS_HELP_DEBUG_TIME = "Debug time"
ORGANIZATION_SETTINGS_HELP_EMAIL_ON_ERROR = "Send email on error"
ORGANIZATION_SETTINGS_HELP_EMAIL_ON_SUCCESS = "Send email on success"
ORGANIZATION_SETTINGS_HELP_QUEUED_COMPUTE_WAIT_TIME = "Queued compute wait time"
ORGANIZATION_SETTINGS_HELP_IDLE_ENABLED = "Enable or Disable idle time"
ORGANIZATION_SETTINGS_HELP_IDLE_TIME = "Idle time"
ORGANIZATION_SETTINGS_HELP_MAX_DURATION_WORKSPACES = "Max duration for workspaces"
ORGANIZATION_SETTINGS_HELP_MAX_DURATION_EXPERIMENTS = "Max duration for experiments"
ORGANIZATION_SETTINGS_HELP_MAX_DURATION_ENDPOINTS = "Max duration for endpoints"
ORGANIZATION_SETTINGS_HELP_MAX_DURATION_WEBAPPS = "Max duration for webapps"
ORGANIZATION_SETTINGS_HELP_AUTOMATICALLY_CLEAR_CACHED_COMMITS = "Number of cached commits to be cleared" \
                                                                " automatically"
ORGANIZATION_SETTINGS_HELP_CUSTOM_PYPI_ENABLED = "Enable custom PYPI"
ORGANIZATION_SETTINGS_HELP_CUSTOM_PYPI_URL = "Custom PYPI URL"

# Storage Class
CREATED_SUCCESSFULLY = "successfully created\nStorage Class title {0}\nStorage class slug: {1}"
STORAGE_CLASS_HELP_TITLE = "Title of the storage class to create"
STORAGE_CLASS_HELP_CONNECT_TITLE = "Title of the storage class to connect"
STORAGE_CLASS_CREATING_MESSAGE = "Creating new storage class"
STORAGE_CLASS_CONNECT_MESSAGE = "Connect new storage class"
STORAGE_CLASS_PROMPT_TITLE = "Please enter storage class title"
STORAGE_CLASS_PROMPT_CONNECT_TITLE = "Please enter storage class title in kubernetes"
STORAGE_CLASS_PROMPT_HOST_IP = "Please enter storage class host ip"
STORAGE_CLASS_PROMPT_HOST_PATH = "Please enter storage class host path"
STORAGE_CLASS_PROMPT_CLUSTER = "Please enter cluster slug"
STORAGE_CLASS_CONNECT_ALL_VOLUMES_PROMPT = "Do you want to connect all volumes?(true/false)"
STORAGE_CLASS_CONNECT_ALL_VOLUMES_HELP = "to connect all volumes that exist on the storage class"
STORAGE_CLASS_PROMPT_SLUG = "Please enter storage class slug"
STORAGE_CLASS_HELP_HOST_IP = "storage class host ip"
STORAGE_CLASS_HELP_HOST_PATH = "storage class host path"
STORAGE_CLASS_HELP_CLUSTER = "cluster slug to create storage class on"
DISCONNECT_MESSAGE_SUCCESSFULLY = "successfully disconnected\nStorage Class title {0}\nStorage class slug: {1}"
STORAGE_CLASS_SLUG_PROMPT = "Please enter storage class slug"
STORAGE_CLASS_HELP_SLUG = "Storage class slug"
STORAGE_CLASS_WAIT = "Wait until Storage class create/connected"
DELETE_MESSAGE_SUCCESSFULLY = "Successfully deleted Storage Class:\n title: {0}\nslug: {1}"
# volume
VOLUME_CREATING_MESSAGE = "Creating new volume"
VOLUME_CONNECT_MESSAGE = "Connect new volume"
VOLUME_CREATED_SUCCESSFULLY = "successfully created\nvolume title {0}\nvolume slug: {1}"
VOLUME_CONNECT_SUCCESSFULLY = "successfully connect\nvolume title {0}\nvolume slug: {1}"
VOLUME_TITLE_PROMPT = "Please enter volume title"
VOLUME_HELP_TITLE = "Title of the Volume"
VOLUME_SIZE_PROMPT = "Please enter volume size in GB"
READ_WRITE_MANY_PROMPT = "Do you want volume to be read write many(true/false)"
VOLUME_HELP_SIZE = "Size of the Volume"
VOLUME_HELP_CLUSTER_SLUG = "Cluster slug which contain the storage class"
VOLUME_HELP_STORAGE_CLASS_SLUG = "Storage class slug to create volume on"
VOLUME_HELP_RWM = "the access mode of the volume"
VOLUME_HELP_SLUG = "volume slug"
VOLUME_DELETE_MESSAGE_SUCCESSFULLY = "successfully deleted volume: {0}"
VOLUME_DISCONNECTED_MESSAGE_SUCCESSFULLY = "successfully disconnected volume: {0}"
PVC_CLAIM_NAME_PROMPT_TITLE = "Please enter PVC name in kubernetes"
PVC_CLAIM_NAME_HELP_TITLE = "PVC name in kubernetes"
# cluster
CLUSTER_SLUG_PROMPT = "Please enter cluster slug"
