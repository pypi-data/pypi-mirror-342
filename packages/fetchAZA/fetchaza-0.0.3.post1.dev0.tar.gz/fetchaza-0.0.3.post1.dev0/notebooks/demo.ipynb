{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a29764-f39c-431c-8e77-fbc6bfe20f01",
   "metadata": {},
   "source": [
    "# Parsing data from the Sonardyne FETCH AZA\n",
    "\n",
    "The purpose of this notebook is to demonstrate the functionality of `fetchAZA` python package.\n",
    "\n",
    "The demo is organised to show\n",
    "\n",
    "- Step 1: Reading the *.csv files into xarray datasets\n",
    "\n",
    "- Step 2: Writing the xarray datasets into individual netCDF files\n",
    "\n",
    "- Step 3: Various plots\n",
    "\n",
    "\n",
    "Note that when you submit a pull request, you should `clear all outputs` from your python notebook for a cleaner merge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1920f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "script_dir = pathlib.Path().parent.absolute()\n",
    "parent_dir = script_dir.parents[0]\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import datetime\n",
    "from fetchAZA import convertAZA, readers, writers, plotters, tools, timetools, utilities\n",
    "import warnings\n",
    "import re\n",
    "import glob\n",
    "import logging\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "# Specify the path for writing datafiles\n",
    "data_path = os.path.join(parent_dir, 'data')\n",
    "fig_path = os.path.join(parent_dir, 'figures')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"In a future version of xarray decode_timedelta will default to False rather than None. To silence this warning, set decode_timedelta to True, False, or a 'CFTimedeltaCoder' instance.\")\n",
    "warnings.filterwarnings(\"ignore\", category=xr.SerializationWarning, message=\"SerializationWarning: Can't decode floating point timedelta to 's' without precision loss, decoding to 'ns' instead. To silence this warning use time_unit='ns' in call to decoding function.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1508e1e7",
   "metadata": {},
   "source": [
    "## Step 1 & 2 as convertAZA.convertAZA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "721efe8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data*.nc\n",
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_KLR.nc\n",
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_AZAseq.nc\n",
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_INC.nc\n",
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_TMP.nc\n",
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_DQZ.nc\n",
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_PIES.nc\n",
      "Dataset AZAseq not included in combined datasets\n",
      "Deleting file: /Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_KLR.nc\n",
      "Deleting file: /Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_TMP.nc\n",
      "Deleting file: /Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_DQZ.nc\n",
      "Deleting file: /Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/data/sample_data_PIES.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eddifying/Cloudfree/gitlab-cloudfree/fetchAZA/fetchAZA/writers.py:96: UserWarning: Times can't be serialized faithfully to int64 with requested units 'seconds since 1970-01-01'. Resolution of 'milliseconds' needed. Serializing times to floating point instead. Set encoding['dtype'] to integer dtype to serialize to int64. Set encoding['dtype'] to floating point dtype to silence this warning.\n",
      "  ds.to_netcdf(output_file)\n"
     ]
    }
   ],
   "source": [
    "fn = 'sample_data.csv'\n",
    "STN = 'sample'\n",
    "deploy_date = '2023-02-27'\n",
    "recovery_date = '2023-03-08T08:00:00'\n",
    "latitude = 26.5\n",
    "longitude = -76.75\n",
    "water_depth = -3800\n",
    "\n",
    "ds_pressure, ds_AZA = convertAZA.convertAZA(data_path, fn, STN, deploy_date, recovery_date, latitude, longitude, water_depth, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe211d",
   "metadata": {},
   "source": [
    "## Step 1: Read the *csv file for Logging Events.  \n",
    "\n",
    "This is done with readers.process_csv_to_xarray().  All logging events are read into individual xarray datasets, stored as a dictionary of datasets where the key.  In addition, the AZA sequence (events following the pattern AZS-AZA-AZA-AZA-AZS) are read into an additional dataset with key 'AZAseq'.  Since this dataset does not contain every individual AZA or AZS event, it does not replace the individual datasets.\n",
    "\n",
    "A log of the processing is also generated.\n",
    "\n",
    "Optionally, the deployment and recovery dates can be passed.  If they are, then the datasets will be sliced to these dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73497da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 'sample_data.csv'\n",
    "STN = 'sample'\n",
    "deploy_date = '2023-02-27'\n",
    "recovery_date = '2023-03-08T08:00:00'\n",
    "\n",
    "# Process filename\n",
    "file_path = os.path.join(data_path, fn)\n",
    "file_root = fn.split('.')[0]\n",
    "platform_id = file_root\n",
    "today = datetime.datetime.now()\n",
    "start_time = today.strftime(\"%Y%m%dT%H\")\n",
    "\n",
    "# Create a log file\n",
    "log_file = os.path.join(data_path, f\"{platform_id}_{start_time}_read.log\")\n",
    "logf_with_path = os.path.join(data_path, log_file)\n",
    "logging.basicConfig(\n",
    "    filename=logf_with_path, \n",
    "    encoding='utf-8',\n",
    "    format=\"%(asctime)s %(levelname)-8s %(funcName)s %(message)s\",\n",
    "    filemode=\"w\", # 'w' to overwrite, 'a' to append\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%Y%m%dT%H%M%S\",\n",
    "    force=True,\n",
    "    )\n",
    "_log.info('Reading AZA from CSV to netCDF')\n",
    "_log.info('Processing data from: %s', file_path)\n",
    "\n",
    "\n",
    "# Process the CSV file and create xarray datasets containing the data\n",
    "datasets = readers.read_csv_to_xarray(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a84ba",
   "metadata": {},
   "source": [
    "## Step 2: Write the data to netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affaa641",
   "metadata": {},
   "outputs": [],
   "source": [
    "writers.save_datasets(datasets, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad927bb2",
   "metadata": {},
   "source": [
    "## Step 3: Further processing of pressure records and AZA sequence records\n",
    "\n",
    "Note that in the steps above, the original data were not changed, with the exception of changes noted in the log file.\n",
    "\n",
    "This means that each of the newly created *.nc mirrors--almost exactly--the original data.\n",
    "\n",
    "Here we carry out additional steps including:\n",
    "\n",
    "1. Load netCDF datasets based on provided keys. (`readers.load_netcdf_datasets(data_path, file_root, keys)`)\n",
    "2. Convert units and adjust time formats. (`timetools.convert_seconds_to_float(ds)`)\n",
    "3. Assign sampling time for the AZA sequence dataset. (`timetools.assign_sample_time()`)\n",
    "4. Filter datasets to the deployment period. (`timetools.cut_to_deployment(datasets, deploy_date, recovery_date)`)\n",
    "5. Reindex datasets on time. (`timetools.reindex_on_time(ds)`)\n",
    "6. Rename variables in datasets using predefined mappings. (using `vars_to_rename`, a dict)\n",
    "7. Add dataset-specific attributes to variables.\n",
    "8. Combine selected datasets into a single dataset. (using `xr.merge()`)\n",
    "9. Interpolate the combined dataset to an evenly spaced time grid. (after determining median interval of hourly with `timetools.calculate_sample_rate(ds)`)\n",
    "10. Clean and organize dataset attributes and variables.\n",
    "11. Process the AZA sequence dataset, including renaming attributes and cleaning variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54879aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pressure, ds_AZA = tools.process_datasets(data_path, file_root, deploy_date, recovery_date)\n",
    "ds_pressure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875d8714",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c8970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datasets\n",
    "output_file = os.path.join(data_path, f\"{STN}_{deploy_date.replace(\"-\",\"\")}_use.nc\")\n",
    "writers.save_dataset(ds_pressure, output_file)\n",
    "\n",
    "output_file = os.path.join(data_path, f\"{STN}_{deploy_date.replace('-','')}_AZA.nc\")\n",
    "writers.save_dataset(ds_AZA, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c897440",
   "metadata": {},
   "source": [
    "### Plot variables in ds_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c49c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "plotters.plot_temperature_variables(ds_pressure, ['TEMPERATURE', 'PRESSURE'],\"sample\")\n",
    "\n",
    "print(\"From the analysis, we determine that PRESSURE_DQZ and PRESSURE_PIES are identical.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a914e",
   "metadata": {},
   "source": [
    "# Diagnostics & basic statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcabd7c",
   "metadata": {},
   "source": [
    "## 1. Plot variables which are against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30562979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot all variables against RECORD_TIME\n",
    "#fig, axs = plotters.plot_all_variables_against_time(ds_pressure, time_var='RECORD_TIME')\n",
    "fig,axs = plotters.plot_all_variables(ds_pressure, 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aceedc",
   "metadata": {},
   "source": [
    "## 2. Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "plotters.plot_histograms(ds_pressure, \"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb11d62",
   "metadata": {},
   "source": [
    "## 3. Compare pressure\n",
    "\n",
    "### Plot the pressure from the ambient (KLR) and transfer (DQZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "fig, axs = plotters.compare_pressure(ds_pressure, ['PRESSURE_DQZ', 'PRESSURE_KLR'], \"sample\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c25d5",
   "metadata": {},
   "source": [
    "### Plot the pressure during an AZA sequence (transfer, ambient and low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_compare=['TRANSFER_PRESSURE','AMBIENT_PRESSURE','LOW_PRESSURE']\n",
    "\n",
    "# Example usage\n",
    "fig, axs = plotters.plot_AZA_pressure(ds_AZA, variables_to_compare)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb49834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all pressure variables in ds_AZA on the same axes with symbols and lines\n",
    "plt.figure(figsize=(8, 4))\n",
    "pressure_vars = ['TRANSFER_PRESSURE', 'AMBIENT_PRESSURE', 'LOW_PRESSURE']\n",
    "time_var = 'SAMPLE_TIME'\n",
    "# Define marker styles to cycle through\n",
    "markers = ['o', 'v', 's', 'D', '^']\n",
    "\n",
    "for idx, var in enumerate(pressure_vars):\n",
    "    plt.plot(\n",
    "        ds_AZA[time_var], \n",
    "        ds_AZA[var], \n",
    "        label=var, \n",
    "        marker=markers[idx % len(markers)], \n",
    "        linestyle='-', \n",
    "        markerfacecolor='none'\n",
    "    )\n",
    "\n",
    "plt.title('Pressure Variables in AZA')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Pressure (kPa)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().invert_yaxis()  # Invert the y-axis\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a674711",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
