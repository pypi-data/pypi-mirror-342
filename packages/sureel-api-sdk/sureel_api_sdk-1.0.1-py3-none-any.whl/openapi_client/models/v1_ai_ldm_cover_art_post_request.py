# coding: utf-8

"""
    Sureel API

    API for the Sureel network.

    The version of the OpenAPI document: 
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from openapi_client.models.style_image import StyleImage
from openapi_client.models.text_to_image_request_upscale import TextToImageRequestUpscale
from openapi_client.models.v1_ai_ldm_cover_art_post_request_description_weight import V1AiLdmCoverArtPostRequestDescriptionWeight
from openapi_client.models.v1_ai_ldm_cover_art_post_request_font_first_line import V1AiLdmCoverArtPostRequestFontFirstLine
from openapi_client.models.v1_ai_ldm_cover_art_post_request_font_second_line import V1AiLdmCoverArtPostRequestFontSecondLine
from openapi_client.models.v1_ai_ldm_cover_art_post_request_frame import V1AiLdmCoverArtPostRequestFrame
from typing import Optional, Set
from typing_extensions import Self

class V1AiLdmCoverArtPostRequest(BaseModel):
    """
    V1AiLdmCoverArtPostRequest
    """ # noqa: E501
    frame: Optional[V1AiLdmCoverArtPostRequestFrame] = None
    text_first_line: Optional[StrictStr] = Field(default=None, description="The text that will appear in the first line on the cover art, e.g. artist name.", alias="textFirstLine")
    text_second_line: Optional[StrictStr] = Field(default=None, description="The text that will appear in the second line on the cover art, e.g. album name.", alias="textSecondLine")
    font_first_line: Optional[V1AiLdmCoverArtPostRequestFontFirstLine] = Field(default=None, alias="fontFirstLine")
    font_second_line: Optional[V1AiLdmCoverArtPostRequestFontSecondLine] = Field(default=None, alias="fontSecondLine")
    font_color_first_line: Optional[Annotated[List[Annotated[int, Field(le=256, strict=True, ge=0)]], Field(min_length=3, max_length=3)]] = Field(default=None, description="The font color in RGB of the text in the first line.", alias="fontColorFirstLine")
    font_color_second_line: Optional[Annotated[List[Annotated[int, Field(le=256, strict=True, ge=0)]], Field(min_length=3, max_length=3)]] = Field(default=None, description="The font color in RGB of the text in the second line.", alias="fontColorSecondLine")
    cover_content: StrictStr = Field(description="The content of the cover art.", alias="coverContent")
    cover_style: StrictStr = Field(description="The style of the cover art.", alias="coverStyle")
    cover_color_scheme: Optional[StrictStr] = Field(default=None, description="The color scheme of the cover art.", alias="coverColorScheme")
    album_genre: Optional[StrictStr] = Field(default=None, description="The album genre.", alias="albumGenre")
    album_seasonality: Optional[StrictStr] = Field(default=None, description="The album seasonality.", alias="albumSeasonality")
    reference_cover_art: Annotated[List[StyleImage], Field(min_length=1, max_length=10)] = Field(alias="referenceCoverArt")
    song_titles: Optional[StrictStr] = Field(default=None, description="If you want to create a cover art for multiple songs, you can provide the song titles here.", alias="songTitles")
    song_path: Optional[StrictStr] = Field(default=None, description="If you want to create a cover art for a single song, you can provide this song here.                 The `songPath` can either be an audio URL, a YouTube URL, or the audio path returned from the `/audio-ldm/upload-audio` or `/artist/post-upload-urls` endpoint.                 Supported formats include .mp3 and .wav", alias="songPath")
    lyrics: Optional[StrictStr] = Field(default=None, description="If you want to create a cover art for a single song, you can provide the lyrics of this song here.")
    description_weight: Optional[V1AiLdmCoverArtPostRequestDescriptionWeight] = Field(default=None, alias="descriptionWeight")
    negative_prompt: Optional[StrictStr] = Field(default=None, description="A list of negative attributes or undesired features that describes what the desired image should **not** look like.", alias="negativePrompt")
    apply_watermark: Optional[StrictBool] = Field(default=None, description="Flag whether to apply a watermark to the images or not.     The watermark can be either the Sureel watermark or a custom watermark provided through the `customWatermark` parameter.", alias="applyWatermark")
    custom_watermark: Optional[StrictStr] = Field(default=None, description="Define a custom watermark image to be applied to the images.             It should be square and must have an alpha channel.             The watermark should be oriented towards the lower left corner of the watermark image.             The `customWatermark` can either be an image URL or the image path returned from the `/ldm/upload-images` or `/artist/post-upload-urls` endpoint.             Supported formats include PNG.", alias="customWatermark")
    upscale: Optional[TextToImageRequestUpscale] = None
    inference_steps: Optional[Annotated[int, Field(le=100, strict=True, ge=10)]] = Field(default=None, description="Number of diffusion steps that iteratively improve the images generated by the model.", alias="inferenceSteps")
    cfg: Optional[Union[Annotated[float, Field(le=15, strict=True, ge=0)], Annotated[int, Field(le=15, strict=True, ge=0)]]] = Field(default=None, description="Classifier-free guidance: This scale determines how strictly the diffusion process adheres to the prompt.             Higher values keep the image closer to the prompt.")
    seed: Optional[Annotated[int, Field(le=2147483647, strict=True, ge=-2147483648)]] = Field(default=None, description="Seed to control randomness in the generation process and enable reproducibility.             If not specified, the generation process is random.             If the seed is fixed to the same number, the generation will always yield the same result.")
    generate_attribution: Optional[StrictBool] = Field(default=None, description="Flag whether to enable the attribution calculation. Attribution describes the influence of training data on content generated using AI.     When training an AI model with different collections of data, each collection has a certain amount of influence on the resulting model.     When generating new content with the resulting model, the influence each collection has on the new content is referred to as the attribution of the new content.", alias="generateAttribution")
    batch_size: Optional[Annotated[int, Field(le=12, strict=True, ge=1)]] = Field(default=None, description="Number of images that are generated in a single request.", alias="batchSize")
    remove_bg: Optional[StrictBool] = Field(default=None, description="Flag whether to remove the semantic background of the image.", alias="removeBg")
    generate_preview: Optional[StrictBool] = Field(default=None, description="Flag whether to generate 256px and 512px preview images for lower resolution previews in a front-end.", alias="generatePreview")
    webhook: Optional[StrictStr] = Field(default=None, description="Webhook URL where you receive notifications regarding completed requests.")
    __properties: ClassVar[List[str]] = ["frame", "textFirstLine", "textSecondLine", "fontFirstLine", "fontSecondLine", "fontColorFirstLine", "fontColorSecondLine", "coverContent", "coverStyle", "coverColorScheme", "albumGenre", "albumSeasonality", "referenceCoverArt", "songTitles", "songPath", "lyrics", "descriptionWeight", "negativePrompt", "applyWatermark", "customWatermark", "upscale", "inferenceSteps", "cfg", "seed", "generateAttribution", "batchSize", "removeBg", "generatePreview", "webhook"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of V1AiLdmCoverArtPostRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of frame
        if self.frame:
            _dict['frame'] = self.frame.to_dict()
        # override the default output from pydantic by calling `to_dict()` of font_first_line
        if self.font_first_line:
            _dict['fontFirstLine'] = self.font_first_line.to_dict()
        # override the default output from pydantic by calling `to_dict()` of font_second_line
        if self.font_second_line:
            _dict['fontSecondLine'] = self.font_second_line.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in reference_cover_art (list)
        _items = []
        if self.reference_cover_art:
            for _item_reference_cover_art in self.reference_cover_art:
                if _item_reference_cover_art:
                    _items.append(_item_reference_cover_art.to_dict())
            _dict['referenceCoverArt'] = _items
        # override the default output from pydantic by calling `to_dict()` of description_weight
        if self.description_weight:
            _dict['descriptionWeight'] = self.description_weight.to_dict()
        # override the default output from pydantic by calling `to_dict()` of upscale
        if self.upscale:
            _dict['upscale'] = self.upscale.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of V1AiLdmCoverArtPostRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "frame": V1AiLdmCoverArtPostRequestFrame.from_dict(obj["frame"]) if obj.get("frame") is not None else None,
            "textFirstLine": obj.get("textFirstLine"),
            "textSecondLine": obj.get("textSecondLine"),
            "fontFirstLine": V1AiLdmCoverArtPostRequestFontFirstLine.from_dict(obj["fontFirstLine"]) if obj.get("fontFirstLine") is not None else None,
            "fontSecondLine": V1AiLdmCoverArtPostRequestFontSecondLine.from_dict(obj["fontSecondLine"]) if obj.get("fontSecondLine") is not None else None,
            "fontColorFirstLine": obj.get("fontColorFirstLine"),
            "fontColorSecondLine": obj.get("fontColorSecondLine"),
            "coverContent": obj.get("coverContent"),
            "coverStyle": obj.get("coverStyle"),
            "coverColorScheme": obj.get("coverColorScheme"),
            "albumGenre": obj.get("albumGenre"),
            "albumSeasonality": obj.get("albumSeasonality"),
            "referenceCoverArt": [StyleImage.from_dict(_item) for _item in obj["referenceCoverArt"]] if obj.get("referenceCoverArt") is not None else None,
            "songTitles": obj.get("songTitles"),
            "songPath": obj.get("songPath"),
            "lyrics": obj.get("lyrics"),
            "descriptionWeight": V1AiLdmCoverArtPostRequestDescriptionWeight.from_dict(obj["descriptionWeight"]) if obj.get("descriptionWeight") is not None else None,
            "negativePrompt": obj.get("negativePrompt"),
            "applyWatermark": obj.get("applyWatermark"),
            "customWatermark": obj.get("customWatermark"),
            "upscale": TextToImageRequestUpscale.from_dict(obj["upscale"]) if obj.get("upscale") is not None else None,
            "inferenceSteps": obj.get("inferenceSteps"),
            "cfg": obj.get("cfg"),
            "seed": obj.get("seed"),
            "generateAttribution": obj.get("generateAttribution"),
            "batchSize": obj.get("batchSize"),
            "removeBg": obj.get("removeBg"),
            "generatePreview": obj.get("generatePreview"),
            "webhook": obj.get("webhook")
        })
        return _obj


