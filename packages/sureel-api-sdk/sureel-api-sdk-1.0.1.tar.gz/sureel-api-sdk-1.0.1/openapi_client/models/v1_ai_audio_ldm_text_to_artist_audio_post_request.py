# coding: utf-8

"""
    Sureel API

    API for the Sureel network.

    The version of the OpenAPI document: 
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from openapi_client.models.v1_ai_audio_ldm_text_to_artist_audio_post_request_artist_preset_inner import V1AiAudioLdmTextToArtistAudioPostRequestArtistPresetInner
from typing import Optional, Set
from typing_extensions import Self

class V1AiAudioLdmTextToArtistAudioPostRequest(BaseModel):
    """
    V1AiAudioLdmTextToArtistAudioPostRequest
    """ # noqa: E501
    prompt: StrictStr = Field(description="Text input to condition the audio synthesis.     More details improve the resulting audio quality, although repeating concepts and overly long prompts should be avoided.")
    audio_length: Annotated[int, Field(le=60, strict=True, ge=5)] = Field(description="Length of generated audio in seconds.", alias="audioLength")
    artist_preset: Annotated[List[V1AiAudioLdmTextToArtistAudioPostRequestArtistPresetInner], Field(min_length=1, max_length=2)] = Field(description="List of artist collections who should contribute to the generated data.", alias="artistPreset")
    genre: Optional[StrictStr] = Field(default=None, description="The main category of music that the song belongs to, such as Rock, Jazz, Pop, etc.")
    sub_genre: Optional[StrictStr] = Field(default=None, description="A more specific classification within the main genre, such as Hard Rock, Bebop, Trap, etc.", alias="subGenre")
    mood: Optional[StrictStr] = Field(default=None, description="The emotional tone or atmosphere of the song, such as happy, sad, energetic, mellow, etc.")
    song_key: Optional[StrictStr] = Field(default=None, description="The key in which the song is composed, indicating the scale and tonal center, such as G major, A minor, etc.", alias="songKey")
    tempo: Optional[StrictStr] = Field(default=None, description="The speed or pace of the song, typically measured in beats per minute (BPM).")
    negative_prompt: Optional[StrictStr] = Field(default=None, description="A list of negative attributes or undesired features that describes what the desired audio should **not** look like.", alias="negativePrompt")
    split_stem: Optional[StrictBool] = Field(default=None, description="Flag to split the audio into stems or not.", alias="splitStem")
    inference_steps: Optional[Annotated[int, Field(le=50, strict=True, ge=10)]] = Field(default=None, description="Number of diffusion steps that iteratively improve the audio files generated by the model.", alias="inferenceSteps")
    cfg: Optional[Union[Annotated[float, Field(le=15, strict=True, ge=0)], Annotated[int, Field(le=15, strict=True, ge=0)]]] = Field(default=None, description="Classifier-free guidance: This scale determines how strictly the diffusion process adheres to the prompt.             Higher values keep the audio closer to the prompt.")
    seed: Optional[Annotated[int, Field(le=2147483647, strict=True, ge=-2147483648)]] = Field(default=None, description="Seed to control randomness in the generation process and enable reproducibility.             If not specified, the generation process is random.             If the seed is fixed to the same number, the generation will always yield the same result.")
    batch_size: Optional[Annotated[int, Field(le=4, strict=True, ge=1)]] = Field(default=None, description="Number of audio files that are generated in a single request.", alias="batchSize")
    webhook: Optional[StrictStr] = Field(default=None, description="Webhook URL where you receive notifications regarding completed requests.")
    generate_attribution: Optional[StrictBool] = Field(default=None, description="Flag whether to enable the attribution calculation. Attribution describes the influence of training data on content generated using AI.     When training an AI model with different collections of data, each collection has a certain amount of influence on the resulting model.     When generating new content with the resulting model, the influence each collection has on the new content is referred to as the attribution of the new content.", alias="generateAttribution")
    surprise_me: Optional[StrictBool] = Field(default=None, description="Flag whether to create a surprise text description fitting any given presets.", alias="surpriseMe")
    __properties: ClassVar[List[str]] = ["prompt", "audioLength", "artistPreset", "genre", "subGenre", "mood", "songKey", "tempo", "negativePrompt", "splitStem", "inferenceSteps", "cfg", "seed", "batchSize", "webhook", "generateAttribution", "surpriseMe"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of V1AiAudioLdmTextToArtistAudioPostRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in artist_preset (list)
        _items = []
        if self.artist_preset:
            for _item_artist_preset in self.artist_preset:
                if _item_artist_preset:
                    _items.append(_item_artist_preset.to_dict())
            _dict['artistPreset'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of V1AiAudioLdmTextToArtistAudioPostRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "prompt": obj.get("prompt"),
            "audioLength": obj.get("audioLength"),
            "artistPreset": [V1AiAudioLdmTextToArtistAudioPostRequestArtistPresetInner.from_dict(_item) for _item in obj["artistPreset"]] if obj.get("artistPreset") is not None else None,
            "genre": obj.get("genre"),
            "subGenre": obj.get("subGenre"),
            "mood": obj.get("mood"),
            "songKey": obj.get("songKey"),
            "tempo": obj.get("tempo"),
            "negativePrompt": obj.get("negativePrompt"),
            "splitStem": obj.get("splitStem"),
            "inferenceSteps": obj.get("inferenceSteps"),
            "cfg": obj.get("cfg"),
            "seed": obj.get("seed"),
            "batchSize": obj.get("batchSize"),
            "webhook": obj.get("webhook"),
            "generateAttribution": obj.get("generateAttribution"),
            "surpriseMe": obj.get("surpriseMe")
        })
        return _obj


