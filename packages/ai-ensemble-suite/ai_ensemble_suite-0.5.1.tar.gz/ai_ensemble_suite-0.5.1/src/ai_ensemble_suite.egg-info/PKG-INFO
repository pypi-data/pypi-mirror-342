Metadata-Version: 2.4
Name: ai-ensemble-suite
Version: 0.5.1
Summary: Python framework for multiple GGUF language models to collaborate on tasks
Author-email: Stephen Genusa <github@genusa.com>
License-Expression: MIT
Project-URL: Homepage, https://github.com/StephenGenusa/ai-ensemble-suite
Project-URL: Bug Tracker, https://github.com/StephenGenusa/ai-ensemble-suite/issues
Project-URL: Documentation, https://stephengenusa.github.io/ai-ensemble-suite
Keywords: llm,ai,ensemble,language-model,gguf,llama,ai-ensemble
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: llama-cpp-python
Requires-Dist: pyyaml
Requires-Dist: colorama
Requires-Dist: Jinja2
Requires-Dist: psutil
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.20.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: tox>=4.0.0; extra == "dev"
Requires-Dist: mkdocs>=1.4.0; extra == "dev"
Requires-Dist: mkdocs-material>=8.5.0; extra == "dev"
Requires-Dist: mkdocstrings>=0.19.0; extra == "dev"
Requires-Dist: mkdocstrings-python>=0.8.0; extra == "dev"
Provides-Extra: rich
Requires-Dist: rich>=12.0.0; extra == "rich"
Dynamic: license-file

# AI Ensemble Suite

> **Alpha Release (v0.5)**: This library is in active development. While already functional and useful for real-world applications, some APIs may change, and additional cleanup and feature development are in progress. Feedback and contributions are welcome!

[![Python Versions](https://img.shields.io/badge/python-3.10%20%7C%203.11%20%7C%203.12-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Status](https://img.shields.io/badge/status-alpha-orange.svg)](https://github.com/StephenGenusa/ai-ensemble-suite)

Python framework for multiple GGUF language models to collaborate on tasks using structured communication patterns, aggregating their outputs into coherent responses. While I chose to support GGUF to begin with, I plan to add OpenAI compatible server support allowing local LLM server and Internet APIs to be called.

## Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Key Features](#key-features)
- [Ensembles Explained](#ai-ensembles-explained)
- [Why Ensembles Work](#why-ensembles-work)
- [Why This Library?](#why-this-library)
- [Examples](#examples)
- [Decision Guide: Choosing Collaboration & Aggregation Patterns](#decision-guide-choosing-collaboration--aggregation-patterns)
- [Collaboration Phases](#collaboration-phases)
- [Aggregation Strategies](#aggregation-strategies)
- [Architecture Diagram](#architecture-diagram)
- [Class Hierarchy and Interaction Diagram](#class-hierarchy-and-interaction-diagram)
- [Project File Structure](#project-file-structure)
- [API Reference](#api-reference)
- [Requirements](#requirements)
- [Contributing](#contributing)
- [Running Tests](#running-tests)
- [Roadmap](#roadmap)
- [License](#license)
- [Special Thanks](#special-thanks)

## Installation

### Prerequisites

- Python >= 3.10
- Sufficient RAM for running multiple language models
- Preferably a GPU with sufficient VRAM to load multiple models, otherwise your llama-cpp will store models in RAM and use your CPU for inference

### Install via pip

For GPU acceleration note the export/set See optional dependencies below before installing

```bash
export CMAKE_ARGS="-DGGML_CUDA=on"
export FORCE_CMAKE=1
pip install ai-ensemble-suite
```

```windows
SET CMAKE_ARGS="-DGGML_CUDA=on"
SET FORCE_CMAKE=1
pip install ai-ensemble-suite
```
### Optional Dependencies

The library has optional dependencies that can be installed with:

```bash
pip install "ai-ensemble-suite[rich]"  # For enhanced console output
pip install "ai-ensemble-suite[dev]"   # For development tools
```


### Installation with GPU acceleration

For NVIDIA GPU acceleration:

```bash
CMAKE_ARGS="-DGGML_CUDA=on" FORCE_CMAKE=1 pip install llama-cpp-python
pip install ai-ensemble-suite
```

For Apple Metal (macOS):

```bash
CMAKE_ARGS="-DLLAMA_METAL=on" FORCE_CMAKE=1 pip install llama-cpp-python
pip install ai-ensemble-suite
```

### Development Installation

To install the package with development dependencies:

```bash
git clone https://github.com/StephenGenusa/ai-ensemble-suite.git
cd ai-ensemble-suite
pip install -e ".[dev]"
```

[Back to top](#ai-ensemble-suite)

## Quick Start

You will want to determine which GGUF models you wish to work with. Download them and place in the root folder of the project under a /models directory... or change the YAML to point to the location of your models.

Here's a minimal example to get started with AI Ensemble Suite:

```python
from ai_ensemble_suite import Ensemble

# Initialize the ensemble with a configuration
ensemble = Ensemble(config_path="path/to/config.yaml")

# Initialize models (loads them into memory)
await ensemble.initialize()

# Ask a question
try:
    response = await ensemble.ask("What are the key considerations for sustainable urban planning?")
    print(response)
finally:
    # Release resources when done
    await ensemble.shutdown()

# Alternatively, use with async context manager
async with Ensemble(config_path="path/to/config.yaml") as ensemble:
    response = await ensemble.ask("What are the key considerations for sustainable urban planning?")
    print(response)
```

[Back to top](#ai-ensemble-suite)

## Key Features

- ‚úÖ **Multiple Collaboration Phases**: Choose from over a dozen different collaboration methods to design your ensemble approach
- ‚úÖ **Specialized Model Roles**: Assign different roles (critic, synthesizer, researcher, etc.) to models, allowing them to specialize in different aspects of task completion
- ‚úÖ **Flexible Aggregation Strategies**: Use different methods for combining model outputs into coherent, high-quality responses
- ‚úÖ **Advanced Tracing**: Get detailed traces of model interactions and decision-making processes
- ‚úÖ **Extensible Design**: Easily add custom collaboration phases or aggregation strategies
- ‚úÖ **Built for GGUF Models**: Optimized for running multiple smaller GGUF language models locally
- ‚úÖ **Confidence Estimation**: Token probability analysis and self-evaluation capabilities
- ‚úÖ **Concurrent Model Management**: Efficient loading and execution of multiple models
- ‚úÖ **Async-First Design**: Native async/await support with context manager
- ‚úÖ **YAML Configuration for Models**: YAML configuration files to hold model parameters and queries
- ‚úÖ **Jinja2 Templating**: The (query) "templates" portion of the the YAML configuration file support Jinja2

[Back to top](#ai-ensemble-suite)


## AI Ensembles Explained

Think of AI ensembles like getting advice from a group of experts instead of just one person. Just as you might ask several friends for opinions before making an important decision, AI ensembles combine the strengths of multiple AI systems or approaches to produce better results than any single AI could achieve alone. Instead of relying on one AI that might have blind spots or make certain types of mistakes, ensembles bring together diverse AI perspectives that can check each other's work, complement each other's strengths, and collectively arrive at more reliable answers. It's similar to how a team of doctors with different specialties might collaborate on a difficult medical case‚Äîthe combined expertise leads to better outcomes than what any individual doctor could provide on their own.

**Brief Explanations of AI Ensemble Techniques**

* **AsyncThinking**: Like a rapid brainstorming session where multiple people jot down ideas independently before sharing, this technique generates diverse initial thoughts quickly without influence from other perspectives.

* **StructuredCritique**: Similar to having your work reviewed by a tough but fair editor, this approach systematically evaluates ideas, identifies logical flaws, and improves the rigor of thinking.

* **SynthesisOriented**: Acts like a skilled mediator who finds common ground between opposing viewpoints, integrating different perspectives into a balanced, comprehensive analysis.

* **RoleBasedDebate**: Resembles a panel discussion with experts from different fields, each contributing specialized knowledge to address complex topics from multiple angles.

* **HierarchicalReview**: Works like a multi-stage editing process, where content is refined layer by layer, with each review focusing on different aspects for progressive improvement.

* **CompetitiveEvaluation**: Functions like a contest where multiple solutions compete, and the strongest approach wins based on objective criteria.

* **PerspectiveRotation**: Similar to walking around a sculpture to view it from all sides, this technique examines issues from different stakeholder perspectives, ethical frameworks, or creative angles.

* **ChainOfThoughtBranching**: Like mapping out a complex maze with multiple possible paths, this method explores different reasoning routes for problems with multiple decision points.

* **AdversarialImprovement**: Acts as a stress-test or devil's advocate, actively looking for weaknesses in a solution to strengthen it against potential problems.

* **RoleBasedWorkflow**: Operates like a production line with specialized stations, creating a structured process where different roles handle specific aspects of a multi-stage analysis.

* **Bagging**: Works like taking the average of multiple poll results to get a more stable prediction, reducing the impact of outliers or unusual patterns.

* **UncertaintyBasedCollaboration**: Similar to how a group might work together on a puzzle with missing pieces, this approach handles ambiguous questions by combining different levels of confidence.

* **StackedGeneralization**: Functions like a team of specialists with a coordinator, where outputs from different AI models are combined to leverage their unique strengths and minimize weaknesses.

[Back to top](#ai-ensemble-suite)

## Why Ensembles Work

Ensemble methods have a strong theoretical and empirical foundation in machine learning, and they're particularly effective with language models for several reasons:

1. **Diverse Knowledge and Perspectives**: Different language models, even when trained on similar data, develop slightly different internal representations and "expertise areas." By combining multiple models, you access a broader knowledge base than any single model contains.

2. **Error Reduction Through Aggregation**: Models tend to make different errors. When their outputs are combined intelligently, errors from one model can be corrected by others, leading to more accurate results.

3. **Specialization Through Roles**: When models adopt specialized roles (like critic, researcher, or synthesizer), they can focus on specific aspects of a task. This division of cognitive labor mirrors effective human teams and leads to more thorough analysis.

4. **Iterative Refinement**: Multi-step collaboration allows initial ideas to be critiqued, refined, and expanded. This resembles human drafting and editing processes, typically producing higher quality results than single-pass generation.

5. **Confidence Calibration**: Ensemble techniques help identify areas of uncertainty or disagreement between models, leading to better-calibrated confidence in the final output.

Research consistently shows that properly designed ensembles outperform even the strongest individual models, often by significant margins. AI Ensemble Suite provides the infrastructure to easily tap into these powerful techniques.

[Back to top](#ai-ensemble-suite)

## Why This Library?

AI Ensemble Suite was created to address two key challenges:

1. **The Need for Human-Friendly Ensemble AI**: After extensive searching for a comprehensive yet easy-to-use library for ensemble AI work that followed a "for humans" philosophy, nothing quite fit the bill. This library makes it easy to harness multiple smaller language models on local machines to produce enhanced AI responses.

2. **Structured Collaboration Patterns**: Rather than just averaging model outputs, AI Ensemble Suite implements sophisticated collaboration patterns where models can critique, refine, and extend each other's work - resulting in higher quality responses that benefit from diverse model strengths.

The framework is designed with simplicity in mind for common use cases while providing comprehensive customization for advanced users.

Additionally, this project served as a meta-challenge to build a medium sized Python library using AI assistance despite context window limitations, developing techniques to work around these constraints.

[Back to top](#ai-ensemble-suite)

## Examples

The library includes several example scripts demonstrating different ensemble techniques:

- **Basic Usage**: Non-ensembled simple usage with default configurations
- **Structured Debate**: Models present opposing viewpoints to refine conclusion
- **Expert Committee**: Specialized models contribute domain expertise
- **Hierarchical Review**: Progressive refinement through layers of specialized models
- **Competitive Evaluation**: Multiple solutions generated and evaluated against criteria
- **Perspective Rotation**: Problem analyzed through different framing lenses
- **Chain-of-Thought Branching**: Reasoning paths that branch and reconverge
- **Adversarial Improvement**: One model finds flaws in another's reasoning
- **Role-based Workflow**: Models adopt complementary roles in a structured process
- **Bagging**: Combines models to reduce prediction variance

> **Note on Examples**: Some example files require additional libraries not included in requirements.txt. Several examples also generate graphic charts to disk, which were implemented to help visualize how the ensemble builds the final result. These visualization features are optional but helpful for testing and understanding the process.

[Back to top](#ai-ensemble-suite)

## Decision Guide: Choosing Collaboration & Aggregation Patterns

### Collaboration Patterns

| When you need... | Use this collaboration pattern | Best for |
|------------------|-------------------------------|----------|
| Quick independent analyses | **AsyncThinking** | Simple questions, brainstorming, diverse initial ideas |
| Critical evaluation of ideas | **StructuredCritique** | Evaluating arguments, finding flaws, improving rigor |
| Balanced perspectives | **SynthesisOriented** | Finding common ground, integrating viewpoints, balanced analysis |
| Multiple specialist perspectives | **RoleBasedDebate** | Complex topics requiring multiple forms of expertise |
| Progressive improvement | **HierarchicalReview** | Content requiring layer-by-layer refinement or fact-checking |
| Competition between solutions | **CompetitiveEvaluation** | Generating multiple solutions and selecting the best one |
| Examining from different angles | **PerspectiveRotation** | Ethical analysis, stakeholder considerations, creative ideation |
| Complex reasoning paths | **ChainOfThoughtBranching** | Mathematical problems, logic puzzles, decision trees |
| Stress-testing solutions | **AdversarialImprovement** | Finding edge cases, improving robustness, anticipating objections |
| Structured workflow process | **RoleBasedWorkflow** | Research projects, content creation, multi-stage analysis |
| Stabilizing volatile outputs | **Bagging** | Reducing variance, improving prediction stability |
| Handling uncertainty | **UncertaintyBasedCollaboration** | Questions with ambiguity, calibrating confidence |
| Model stacking | **StackedGeneralization** | Leveraging strengths of different model types, boosting performance |

### Aggregation Strategies

| When you need... | Use this aggregation strategy | Best for |
|------------------|------------------------------|----------|
| To prioritize some models over others | **WeightedVoting** | When certain models perform better for specific tasks |
| To use the final result of a sequence | **SequentialRefinement** | When using phases that progressively refine content |
| To choose the most confident output | **ConfidenceBased** | When models have reliable confidence estimation |
| To evaluate along multiple criteria | **MultidimensionalVoting** | Complex evaluation requiring different quality dimensions |
| To blend multiple perspectives | **EnsembleFusion** | Creating a coherent synthesis from diverse inputs |
| Dynamic strategy selection | **AdaptiveSelection** | When different queries benefit from different aggregation approaches |

[Back to top](#ai-ensemble-suite)

## Collaboration Phases

AI Ensemble Suite implements various collaboration phases that can be combined or used individually:

### Core Phases

- ‚úÖ **AsyncThinking**: Models work independently on a problem before combining insights
- ‚úÖ **Integration/Refinement**: Models refine responses based on feedback and insights
- ‚úÖ **ExpertCommittee**: Final processing/structuring of model outputs before aggregation

### Structured Debate Patterns

- ‚úÖ **StructuredCritique**: Models evaluate others' responses using structured formats
- ‚úÖ **SynthesisOriented**: Models focus on finding common ground and integrating perspectives
- ‚úÖ **RoleBasedDebate**: Models interact according to assigned specialized roles

### Advanced Collaboration Methods

- ‚úÖ **HierarchicalReview**: Content is progressively reviewed by models in a hierarchical structure
- ‚úÖ **CompetitiveEvaluation**: Models are pitted against each other in a competition
- ‚úÖ **PerspectiveRotation**: Models iterate on a problem by assuming different perspectives
- ‚úÖ **ChainOfThoughtBranching**: Models trace through multiple reasoning paths
- ‚úÖ **AdversarialImprovement**: Models improve a solution by seeking its weaknesses
- ‚úÖ **RoleBasedWorkflow**: Models function in specialized roles like researcher, analyst, and writer
- ‚úÖ **Bagging**: Models process different variations of the same input
- ‚úÖ **UncertaintyBasedCollaboration**: Uncertainty measurements guide model interactions
- ‚úÖ **StackedGeneralization**: Base models process input, then a meta-model combines their outputs

[Back to top](#ai-ensemble-suite)

## Aggregation Strategies

The library provides several strategies for aggregating the outputs from multiple models:

- ‚úÖ **WeightedVoting**: Models are assigned different weights based on performance or expertise
- ‚úÖ **SequentialRefinement**: Assumes phases run in a sequence where later phases refine earlier ones
- ‚úÖ **ConfidenceBased**: Selects output with the highest confidence score
- ‚úÖ **MultidimensionalVoting**: Evaluates outputs along multiple dimensions
- ‚úÖ **EnsembleFusion**: Uses a model to synthesize multiple outputs into one
- ‚úÖ **AdaptiveSelection**: Dynamically selects and executes another aggregation strategy

[Back to top](#ai-ensemble-suite)

## Architecture Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                              Ensemble                                                   ‚îÇ
‚îÇ                                    (Main user-facing interface)                                         ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ Attributes:             ‚îÇ ‚îÇ Core Methods:             ‚îÇ ‚îÇ Interaction Methods:                       ‚îÇ‚îÇ
‚îÇ ‚îÇ ‚óè config_manager        ‚îÇ ‚îÇ ‚óè __init__()              ‚îÇ ‚îÇ ‚óè initialize() ‚Üí ModelManager.initialize() ‚îÇ‚îÇ
‚îÇ ‚îÇ ‚óè model_manager         ‚îÇ ‚îÇ ‚óè ask()                   ‚îÇ ‚îÇ ‚óè shutdown() ‚Üí ModelManager.shutdown()     ‚îÇ‚îÇ
‚îÇ ‚îÇ ‚óè template_manager      ‚îÇ ‚îÇ ‚óè configure()             ‚îÇ ‚îÇ ‚óè _execute_collaboration_phases()          ‚îÇ‚îÇ
‚îÇ ‚îÇ ‚óè _initialized          ‚îÇ ‚îÇ ‚óè __aenter__(),           ‚îÇ ‚îÇ ‚óè _aggregate_results()                     ‚îÇ‚îÇ
‚îÇ ‚îÇ ‚óè _initialization_lock  ‚îÇ ‚îÇ   __aexit__()             ‚îÇ ‚îÇ                                            ‚îÇ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                       ‚îÇ                            ‚îÇ
                  ‚îÇ                       ‚îÇ                            ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ ConfigManager‚îÇ       ‚îÇ   ModelManager   ‚îÇ        ‚îÇ  TemplateManager ‚îÇ
          ‚îÇ (YAML Config ‚îÇ       ‚îÇ   (GGUF Models)  ‚îÇ        ‚îÇ                  ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                       ‚îÇ
                  ‚îÇ                       ‚îÇ
                  ‚îÇ                       ‚ñº
                  ‚îÇ            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ            ‚îÇ   Model Registry   ‚îÇ
                  ‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                  ‚îÇ                        ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                   ‚îÇ      ‚îÇ                                         ‚îÇ
         ‚ñº                   ‚ñº      ‚ñº                                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ BaseAggregator  ‚îÇ  ‚îÇBaseCollaboration ‚îÇ                   ‚îÇ          TraceCollector         ‚îÇ
‚îÇ  (Abstract)     ‚îÇ  ‚îÇPhase (Abstract)  ‚îÇ                   ‚îÇ          Tracing System         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ(Records all collaboration steps)‚îÇ
    ‚îÇ      ‚îÇ              ‚îÇ      ‚îÇ                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò 
    ‚ñº      ‚ñº              ‚ñº      ‚ñº                                       
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                             ‚îÇ  ‚îÇ                                                            ‚îÇ
‚îÇ Aggregation Implementations ‚îÇ  ‚îÇ              Collaboration Phase Implementations           ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ ‚îÇ WeightedVoting          ‚îÇ ‚îÇ  ‚îÇ ‚îÇ AsyncThinking  ‚îÇ ‚îÇChainOfThought   ‚îÇ ‚îÇBaseDebate        ‚îÇ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚îÇ
‚îÇ ‚îÇ SequentialRefinement    ‚îÇ ‚îÇ  ‚îÇ ‚îÇ Integration    ‚îÇ ‚îÇCompetitiveEval  ‚îÇ ‚îÇStructuredCritique‚îÇ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚îÇ
‚îÇ ‚îÇ ConfidenceBased         ‚îÇ ‚îÇ  ‚îÇ ‚îÇ ExpertCommittee‚îÇ ‚îÇPerspectiveRot   ‚îÇ ‚îÇSynthesisOriented ‚îÇ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚îÇ
‚îÇ ‚îÇ MultidimensionalVoting  ‚îÇ ‚îÇ  ‚îÇ ‚îÇ HierarchicalRev‚îÇ ‚îÇAdversarialImp   ‚îÇ ‚îÇRoleBasedDebate   ‚îÇ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ ‚îÇ EnsembleFusion          ‚îÇ ‚îÇ  ‚îÇ                    ‚îÇRoleBasedWorkflow‚îÇ                     ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ  ‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ ‚îÇ AdaptiveSelection       ‚îÇ ‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ ‚îÇ Bagging        ‚îÇ ‚îÇUncertaintyBased ‚îÇ ‚îÇStackedGen      ‚îÇ  ‚îÇ
‚îÇ                             ‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                    Exception Hierarchy                                                  ‚îÇ
‚îÇ                                                                                                         ‚îÇ
‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ          ‚îÇ                        AiEnsembleSuiteError (Base)                          ‚îÇ                ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ                 ‚îÇ              ‚îÇ                 ‚îÇ                ‚îÇ                                     ‚îÇ
‚îÇ                 ‚ñº              ‚ñº                 ‚ñº                ‚ñº                                     ‚îÇ
‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                               ‚îÇ
‚îÇ          ‚îÇModelError  ‚îÇ ‚îÇConfigError  ‚îÇ ‚îÇCollabError    ‚îÇ ‚îÇAggrError    ‚îÇ                               ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                               ‚îÇ
‚îÇ                                ‚îÇ                                                                        ‚îÇ
‚îÇ                                ‚ñº                                                                        ‚îÇ
‚îÇ                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                              ‚îÇ
‚îÇ                         ‚îÇValidationError ‚îÇ                                                              ‚îÇ
‚îÇ                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

[Back to top](#ai-ensemble-suite)


## Class Hierarchy and Interaction Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                                         ‚îÇ
‚îÇ                                     ENSEMBLE CLASS                                      ‚îÇ
‚îÇ                        (Main user-facing interface & orchestrator)                      ‚îÇ
‚îÇ                                                                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                 ‚îÇ                                         ‚îÇ                             ‚îÇ
‚îÇ   Public API:   ‚îÇ           Core Control Flow:            ‚îÇ      Context Management:    ‚îÇ
‚îÇ   ‚óè initialize()‚îÇ   ‚óè _execute_collaboration_phases()     ‚îÇ      ‚óè __aenter__()         ‚îÇ
‚îÇ   ‚óè shutdown()  ‚îÇ   ‚óè _aggregate_results()                ‚îÇ      ‚óè __aexit__()          ‚îÇ
‚îÇ   ‚óè ask()       ‚îÇ   ‚óè _get_phase_class()                  ‚îÇ      ‚óè _initialization_lock ‚îÇ
‚îÇ   ‚óè configure() ‚îÇ                                         ‚îÇ                             ‚îÇ
‚îÇ                 ‚îÇ                                         ‚îÇ                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                             ‚îÇ                                 ‚îÇ
          ‚ñº                             ‚ñº                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                             ‚îÇ  ‚îÇ                         ‚îÇ   ‚îÇ                             ‚îÇ
‚îÇ       ConfigManager         ‚îÇ  ‚îÇ     ModelManager        ‚îÇ   ‚îÇ     TemplateManager         ‚îÇ
‚îÇ      (Config handling)      ‚îÇ  ‚îÇ(Model loading/inference)‚îÇ   ‚îÇ    (Prompt template         ‚îÇ
‚îÇ                             ‚îÇ  ‚îÇ                         ‚îÇ   ‚îÇ     management)             ‚îÇ
‚îÇ ‚óè load()                    ‚îÇ  ‚îÇ  ‚óè initialize()         ‚îÇ   ‚îÇ  ‚óè get_template()           ‚îÇ
‚îÇ ‚óè update()                  ‚îÇ  ‚îÇ  ‚óè shutdown()           ‚îÇ   ‚îÇ  ‚óè render_template()        ‚îÇ
‚îÇ ‚óè validate()                ‚îÇ  ‚îÇ  ‚óè get_model()          ‚îÇ   ‚îÇ                             ‚îÇ
‚îÇ ‚óè get_collaboration_mode()  ‚îÇ  ‚îÇ  ‚óè run_inference()      ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ ‚óè get_aggregation_strategy()‚îÇ  ‚îÇ                         ‚îÇ
‚îÇ                             ‚îÇ  ‚îÇ                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                                  ‚îÇ
          ‚îÇ                                  ‚ñº
          ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ              ‚îÇ                                                ‚îÇ
          ‚îÇ              ‚îÇ              Model Registry                    ‚îÇ
          ‚îÇ              ‚îÇ         (Loaded GGUF Models)                   ‚îÇ
          ‚îÇ              ‚îÇ                                                ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îø‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
                                                                                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ                                                                    ‚îÇ              ‚îÇ
‚îÇ                    COLLABORATION PHASES                            ‚îÇ              ‚îÇ
‚îÇ                                                                    ‚îÇ              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§              ‚îÇ
‚îÇ                      ‚îÇ                     ‚îÇ                       ‚îÇ              ‚îÇ
‚îÇ   Simple Phases:     ‚îÇ   Complex Phases:   ‚îÇ     Debate Types:     ‚îÇ              ‚îÇ
‚îÇ   ‚óè AsyncThinking    ‚îÇ   ‚óè CompetitiveEval ‚îÇ   ‚óè StructuredCritique‚îÇ              ‚îÇ
‚îÇ   ‚óè Integration      ‚îÇ   ‚óè PerspectiveRot  ‚îÇ   ‚óè SynthesisOriented ‚îÇ              ‚îÇ
‚îÇ   ‚óè ExpertCommittee  ‚îÇ   ‚óè ChainOfThought  ‚îÇ   ‚óè RoleBasedDebate   ‚îÇ              ‚îÇ
‚îÇ   ‚óè HierarchicalRev  ‚îÇ   ‚óè AdversarialImp  ‚îÇ                       ‚îÇ              ‚îÇ
‚îÇ                      ‚îÇ   ‚óè RoleBasedWork   ‚îÇ                       ‚îÇ              ‚îÇ
‚îÇ                      ‚îÇ                     ‚îÇ                       ‚îÇ              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§              ‚îÇ
‚îÇ                                                                    ‚îÇ              ‚îÇ
‚îÇ   Machine Learning-Oriented Phases:                                ‚îÇ              ‚îÇ
‚îÇ   ‚óè Bagging                                                        ‚îÇ              ‚îÇ
‚îÇ   ‚óè UncertaintyBasedCollaboration                                  ‚îÇ              ‚îÇ
‚îÇ   ‚óè StackedGeneralization                                          ‚îÇ              ‚îÇ
‚îÇ                                                                    ‚îÇ              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
                                 ‚îÇ                                                  ‚îÇ
                                 ‚îÇ                                                  ‚îÇ
                                 ‚ñº                                                  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ                                                                    ‚îÇ              ‚îÇ
‚îÇ                     AGGREGATION STRATEGIES                         ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ                                                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                      ‚îÇ                     ‚îÇ                       ‚îÇ
‚îÇ   ‚óè WeightedVoting   ‚îÇ   ‚óè ConfidenceBased ‚îÇ   ‚óè EnsembleFusion    ‚îÇ
‚îÇ   ‚óè SequentialRef    ‚îÇ   ‚óè MultiDimVoting  ‚îÇ   ‚óè AdaptiveSelection ‚îÇ
‚îÇ                      ‚îÇ                     ‚îÇ                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                                    ‚îÇ
‚îÇ                    UTILITY COMPONENTS                              ‚îÇ
‚îÇ                                                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                  ‚îÇ                                 ‚îÇ
‚îÇ   ‚óè TraceCollector               ‚îÇ   ‚óè Exceptions:                 ‚îÇ
‚îÇ     (Execution tracing)          ‚îÇ     - AiEnsembleSuiteError      ‚îÇ
‚îÇ                                  ‚îÇ     - ConfigurationError        ‚îÇ
‚îÇ   ‚óè Logger                       ‚îÇ     - ModelError                ‚îÇ
‚îÇ     (Structured logging)         ‚îÇ     - CollaborationError        ‚îÇ
‚îÇ                                  ‚îÇ     - AggregationError          ‚îÇ
‚îÇ                                  ‚îÇ     - ValidationError           ‚îÇ
‚îÇ                                  ‚îÇ                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

[Back to top](#ai-ensemble-suite)

# Project File Structure

```
ai_ensemble_suite/
‚îú‚îÄ‚îÄ üìÑ __init__.py             # Package exports (Ensemble class)
‚îú‚îÄ‚îÄ üìÑ ensemble.py             # Main Ensemble class implementation
‚îÇ
‚îú‚îÄ‚îÄ üìÅ config/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py         # Configuration package exports
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ config_manager.py   # Core configuration handling
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ defaults.py         # Default config values
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ schema.py           # JSON Schema for config validation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ template_manager.py # Manages prompt templates
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ utils.py            # Configuration utilities
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py         # Model package exports
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ model_manager.py    # Core model management
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ llm_interface.py    # Common LLM interface
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ gguf_model.py       # GGUF format model implementation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ llama_cpp.py        # llama.cpp specific implementation
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ metadata.py         # Model metadata handling
‚îÇ
‚îú‚îÄ‚îÄ üìÅ collaboration/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py                 # Collaboration package exports
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ base.py                     # BaseCollaborationPhase abstract class
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ async_thinking.py           # Independent parallel thinking
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ integration.py              # Result integration approach
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ expert_committee.py         # Expert committee pattern
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ hierarchical_review.py      # Hierarchical review pattern
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ competitive_evaluation.py   # Competitive evaluation pattern
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ perspective_rotation.py     # Perspective rotation pattern
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ chain_of_thought.py         # Chain-of-thought implementation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ adversarial_improvement.py  # Adversarial improvement pattern
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ role_based_workflow.py      # Role-based workflow pattern
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ structured_debate.py        # Structured debate with subtypes
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ bagging.py                  # ML-inspired bagging approach
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ uncertaintybased.py         # Uncertainty-based collaboration
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ stackedgeneralization.py    # Stacked generalization approach
‚îÇ
‚îú‚îÄ‚îÄ üìÅ aggregation/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py                 # Aggregation package exports
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ base.py                     # BaseAggregator abstract class
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ weighted_voting.py          # Weighted voting implementation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ sequential_refinement.py    # Sequential refinement pattern
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ confidence_based.py         # Confidence-based aggregation
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ multidimensional_voting.py  # Multi-dimensional voting
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ ensemble_fusion.py          # Ensemble fusion approach
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ adaptive_selection.py       # Adaptive selection strategy
‚îÇ
‚îú‚îÄ‚îÄ üìÅ exceptions/
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ __init__.py         # Exception exports
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ errors.py           # Custom exception definitions
‚îÇ
‚îî‚îÄ‚îÄ üìÅ utils/
    ‚îú‚îÄ‚îÄ üìÑ __init__.py         # Utilities package exports
    ‚îú‚îÄ‚îÄ üìÑ logging.py          # Logging configuration
    ‚îú‚îÄ‚îÄ üìÑ tracing.py          # Execution tracing (TraceCollector)
    ‚îú‚îÄ‚îÄ üìÑ concurrency.py      # Concurrency utilities
    ‚îú‚îÄ‚îÄ üìÑ prompt_tools.py     # Prompt manipulation utilities
    ‚îî‚îÄ‚îÄ üìÑ validators.py       # Validation utilities
 
```
[Back to top](#ai-ensemble-suite)

## API Reference

### Core Classes

#### Ensemble

```python
class Ensemble:
    """Coordinates the collaboration of multiple AI models for complex tasks."""
    
    def __init__(self, config_path: Optional[str] = None, config_dict: Optional[Dict[str, Any]] = None) -> None:
        """Initialize the Ensemble orchestration layer."""
        
    async def initialize(self) -> None:
        """Load models and prepare the ensemble for processing queries."""
        
    async def shutdown(self) -> None:
        """Release resources used by the ensemble."""
        
    async def ask(self, query: str, **kwargs: Any) -> Union[str, Dict[str, Any]]:
        """Process a query through the configured collaboration and aggregation pipeline."""
        
    def configure(self, config_dict: Dict[str, Any]) -> None:
        """Update the ensemble's configuration dynamically."""
```

#### ModelManager

```python
class ModelManager:
    """Manages the loading, execution, and lifecycle of GGUF models."""
    
    def __init__(self, config_manager: ConfigProvider, max_workers: Optional[int] = None) -> None:
        """Initialize the ModelManager."""
        
    async def initialize(self) -> None:
        """Initialize the ModelManager: Instantiates models and loads them asynchronously."""
        
    async def shutdown(self) -> None:
        """Shutdown the ModelManager: Unloads models and shuts down the executor."""
        
    async def run_inference(self, model_id: str, prompt: str, **kwargs: Any) -> Dict[str, Any]:
        """Run inference on a specific model using its generate method via thread pool."""
```

#### BaseCollaborationPhase

```python
class BaseCollaborationPhase(ABC):
    """Abstract base class for collaboration phases."""
    
    def __init__(self, model_manager: "ModelManager", config_manager: "ConfigManager", phase_name: str) -> None:
        """Initialize the collaboration phase."""
        
    @abstractmethod
    async def execute(self, query: str, context: Dict[str, Any], trace_collector: Optional[TraceCollector] = None) -> Dict[str, Any]:
        """Execute the collaboration phase."""
```

#### BaseAggregator

```python
class BaseAggregator(ABC):
    """Abstract base class for aggregation strategies."""
    
    def __init__(self, config_manager: "ConfigManager", strategy_name: str, model_manager: Optional["ModelManager"] = None, strategy_config_override: Optional[Dict[str, Any]] = None) -> None:
        """Initialize the aggregator."""
        
    @abstractmethod
    async def aggregate(self, outputs: Dict[str, Dict[str, Any]], context: Dict[str, Any], trace_collector: Optional[TraceCollector] = None) -> Dict[str, Any]:
        """Aggregate the outputs from collaboration phases."""
```

[Back to top](#ai-ensemble-suite)

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

### Guidelines

- Follow PEP 8 and PEP 484 (Type Hinting)
- Use Google Python Style Guide for formatting and documentation
- Apply Google Docstrings for all modules, classes, and functions
- Write tests for new features
- Format code using black (configured in pyproject.toml)
- Run type checking with mypy

[Back to top](#ai-ensemble-suite)

## Running Tests

### üëâ Note: Tests are currently broken. They were originally developed early on in the development process and are now out of date. I will be updating these later.
 
```bash
# Install test dependencies
pip install ".[dev]"

# Run tests
pytest

# Run with coverage
pytest --cov=ai_ensemble_suite
```

[Back to top](#ai-ensemble-suite)

## Roadmap

- Refinement and cleanup of the current codebase
- Rewriting the existing tests due to API changes from early code
- Adding OpenAI API compatibility for local LLM servers like LM Studio, Ollama
- Support for Internet API providers

[Back to top](#ai-ensemble-suite)

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Special Thanks
üôè Special thanks to Georgi Gerganov and the whole team working on llama.cpp for making all of this possible.


[Back to top](#ai-ensemble-suite)

