{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'university': 'Tsinghua University', 'major': 'Computer Science', 'gpa': 3.8}, {'university': 'Peking University', 'major': 'Electrical Engineering', 'gpa': 85}, {'university': 'Stanford University', 'major': 'Mechanical Engineering', 'gpa': 4.0}, {'university': 'Unknown University', 'major': 'Philosophy', 'gpa': 75}, {'university': 'Fudan University', 'major': 'CS', 'gpa': 3.2}]\n"
     ]
    }
   ],
   "source": [
    "fake_data = [\n",
    "    {\"university\": \"Tsinghua University\", \"major\": \"Computer Science\", \"gpa\": 3.8},\n",
    "    {\"university\": \"Peking University\", \"major\": \"Electrical Engineering\", \"gpa\": 85},\n",
    "    {\n",
    "        \"university\": \"Stanford University\",\n",
    "        \"major\": \"Mechanical Engineering\",\n",
    "        \"gpa\": 4.0,\n",
    "    },\n",
    "    {\"university\": \"Unknown University\", \"major\": \"Philosophy\", \"gpa\": 75},\n",
    "    {\"university\": \"Fudan University\", \"major\": \"CS\", \"gpa\": 3.2},\n",
    "]\n",
    "\n",
    "print(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Return the cleaned data into json foramts.\n",
    "1. clean the key 'university' into f these categories ['985', '211', 'g5', 'other'] \n",
    "2. clean the jey 'major' into these categories ['CS', 'EE', 'ME', 'other'] \n",
    "3. clean the key 'gpa' from different scale to 4.0 scale\n",
    "\n",
    "data: {data}\n",
    "\"\"\"\n",
    "\n",
    "format = {\n",
    "    \"format\": {\n",
    "        \"type\": \"json_schema\",\n",
    "        \"name\": \"cleaned_data\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"university\": {\"type\": \"string\", \"enum\": [\"985\", \"211\", \"g5\", \"other\"]},\n",
    "                \"major\": {\"type\": \"string\", \"enum\": [\"CS\", \"EE\", \"ME\", \"other\"]},\n",
    "                \"gpa\": {\n",
    "                    \"type\": \"number\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"university\", \"major\", \"gpa\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "        \"strict\": True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_jsonl_file(\n",
    "    data_items,\n",
    "    output_path,\n",
    "    model_name,\n",
    "    system_prompt,\n",
    "    data_cleaning_prompt,\n",
    "    output_format,\n",
    "):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, item in enumerate(data_items):\n",
    "            full_prompt = f\"{data_cleaning_prompt}\\nData: {str(item)}\"\n",
    "            request = {\n",
    "                \"custom_id\": f\"request_{idx}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/responses\",\n",
    "                \"body\": {\n",
    "                    \"model\": model_name,\n",
    "                    \"input\": [\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": full_prompt},\n",
    "                    ],\n",
    "                    \"text\": output_format,\n",
    "                },\n",
    "            }\n",
    "            f.write(json.dumps(request) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_jsonl_file(\n",
    "    data_items=fake_data,\n",
    "    output_path=\"batch_requests.jsonl\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    system_prompt=\"You are a helpful data cleaner.\",\n",
    "    data_cleaning_prompt=prompt,\n",
    "    output_format=format,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-2GSXnRLwRynXFE2Et2CvR1', bytes=4744, created_at=1744820383, filename='batch_requests.jsonl', object='file', purpose='batch', status='processed', expires_at=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(\"batch_requests.jsonl\", \"rb\"), purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67ffd8bc3abc8190bdd7ac0f67fcb03c', completion_window='24h', created_at=1744820412, endpoint='/v1/responses', input_file_id='file-2GSXnRLwRynXFE2Et2CvR1', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1744906812, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'test batch data cleaning'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/responses\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"test batch data cleaning\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_67ffd8bc3abc8190bdd7ac0f67fcb03c', completion_window='24h', created_at=1744820412, endpoint='/v1/responses', input_file_id='file-2GSXnRLwRynXFE2Et2CvR1', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1744906812, failed_at=None, finalizing_at=None, in_progress_at=1744820413, metadata={'description': 'test batch data cleaning'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=5))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.retrieve(\"batch_67ffd8bc3abc8190bdd7ac0f67fcb03c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmdatacleaner._utils.settings import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Settings(openai_key='xxxx')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Settings().model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxxx'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
