# Web server configuration
HOST=0.0.0.0
PORT=8080

# Application mode. If the value is "dev", it will enable uvicorn reload
ENV_MODE=development

# Authentication secret, HTTP bearer token header is required if set
AUTH_SECRET=

# Observability backend
# OBSERVABILITY_BACKEND=langfuse

# Langfuse configuration
# LANGFUSE_SECRET_KEY=
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_HOST=http://langfuse-web:3000

# Langsmith configuration
# LANGSMITH_TRACING=true
# LANGSMITH_API_KEY=
# LANGSMITH_PROJECT=default
# LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# Database type.
# If the value is "postgres", then it will require Postgresql related environment variables.
# If the value is "sqlite", then you can configure optional file path via SQLITE_DB_PATH
MEMORY_BACKEND=postgres

# If DATABASE_TYPE=sqlite (Optional)
SQLITE_DB_PATH=

# If DATABASE_TYPE=postgres
POSTGRES_USER=
POSTGRES_PASSWORD=
POSTGRES_HOST=
POSTGRES_PORT=
POSTGRES_DB=agents
# Connection pool settings (optional)
POSTGRES_POOL_SIZE=10
POSTGRES_MIN_SIZE=3
POSTGRES_MAX_IDLE=5

# Agent URL: used in Streamlit app - if not set, defaults to http://{HOST}:{PORT}
# AGENT_URL=http://0.0.0.0:8080

# Use a fake model for testing
USE_FAKE_MODEL=false

# Set a default model
DEFAULT_MODEL_TYPE="openai-compatible"

# If MODEL is set to "openai-compatible", set the following
# This is just a flexible solution. If you need multiple model options, you still need to add it to models.py
MODEL_NAME=
MODEL_API_KEY=
MODEL_BASE_URL=http://litellm:4000/v1
