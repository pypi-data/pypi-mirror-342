"""EPUB processing and text extraction module."""

import base64
import re
from dataclasses import dataclass
from typing import Optional

import ebooklib  # type: ignore
from bs4 import BeautifulSoup
from ebooklib import epub
from loguru import logger

from .config import METADATA_FIELDS, ErrorCodes, WarningTypes
from .helpers import ConversionError, ConversionWarning, StrPath


@dataclass
class Chapter:
    """Class representing a chapter in the EPUB book."""

    title: str
    content: str
    order: int
    id: str

    def __str__(self) -> str:
        """Return a string representation of the chapter."""
        return (
            f"Chapter(title='{self.title}', id='{self.id}', order={self.order}, "
            + f"content='{self.content[: len(self.title)]}...')"
        )

    def __eq__(self, other: object) -> bool:
        """Check if two chapters are equal."""
        if not isinstance(other, Chapter):
            return False
        return (
            self.id == other.id
            and self.order == other.order
            and self.title == other.title
            and self.content == other.content
        )

    def __lt__(self, other: object) -> bool:
        """Compare two chapters."""
        if not isinstance(other, Chapter):
            return False
        return self.order < other.order

    def __le__(self, other: object) -> bool:
        """Compare two chapters."""
        if not isinstance(other, Chapter):
            return False
        return self.order <= other.order


@dataclass
class BookMetadata:
    """Class representing book metadata."""

    title: str
    creator: Optional[str] = None
    date: Optional[str] = None
    identifier: Optional[str] = None
    language: Optional[str] = None
    publisher: Optional[str] = None
    description: Optional[str] = None
    cover_image: Optional[str] = None  # Base64 encoded str

    @property
    def book_sentence(self) -> str:
        """Get a sentence that describes the book."""
        return (
            f"A book by {self.creator}, published in {self.date} by {self.publisher}."
            + "Audio generated by Epub2Audio."
        )

    def __str__(self) -> str:
        """Return a string representation of the book metadata."""
        return (
            f"BookMetadata(title={self.title}, "
            + (f"creator={self.creator}, " if self.creator else "")
            + (f"date={self.date}, " if self.date else "")
            + (f"publisher={self.publisher}, " if self.publisher else "")
            + (f"description={self.description}, " if self.description else "")
            + (f"cover_image={len(self.cover_image)}, " if self.cover_image else "")
            + ")"
        )


@dataclass
class CoverImage:
    """Class representing a cover image."""

    image: bytes
    width: int
    height: int


@dataclass
class Book:
    """Class representing a book."""

    metadata: BookMetadata
    chapters: list[Chapter]

    def __str__(self) -> str:
        """Return a string representation of the book."""
        return (
            f"Book(\n\tmetadata={self.metadata},\n\t"
            + f"chapters={'\n\t\t'.join(str(chapter) for chapter in self.chapters)}\n)"
        )


def get_book_length(chapters: list[Chapter]) -> int:
    """Get the length of an EPUB book.

    Args:
        chapters: List of chapters
    """
    return sum(len(chapter.content) for chapter in chapters)


class EpubProcessor:
    """Class for processing EPUB files and extracting content."""

    def __init__(self, epub_path: StrPath):
        """Initialize the EPUB processor.

        Args:
            epub_path: Path to the EPUB file

        Raises:
            ConversionError: If the EPUB file is invalid or cannot be read
        """
        self.epub_path = epub_path
        self.warnings: list[ConversionWarning] = []
        try:
            self.epub = epub.read_epub(epub_path, options={"ignore_ncx": True})
        except Exception as e:
            raise ConversionError(
                f"Failed to read EPUB file: {str(e)}", ErrorCodes.INVALID_EPUB
            ) from e

        self._chapters_in_one_page = False
        self.metadata = self._extract_metadata()
        self.chapters = self._extract_chapters()
        if len(self.chapters) == 0:
            raise ConversionError(
                "No valid chapters found in EPUB file", ErrorCodes.INVALID_EPUB
            )
        if len(self.chapters) == 1:
            logger.warning("Only one chapter found in EPUB file")
            self.warnings.append(
                ConversionWarning(
                    type=WarningTypes.FORMATTING_ISSUE,
                    message="Only one chapter found in EPUB file",
                )
            )
        self.book = Book(metadata=self.metadata, chapters=self.chapters)

        logger.debug(f"Metadata: {self.metadata}")
        logger.trace(f"Number of chapters: {len(self.chapters)}")
        logger.trace(f"Chapter titles: {[chapter.title for chapter in self.chapters]}")
        logger.trace(f"Book length: {get_book_length(self.chapters)}")

    def _extract_metadata(self) -> BookMetadata:
        """Extract metadata from the EPUB file.

        Returns:
            BookMetadata: Extracted metadata
        """
        metadata = {}

        # Extract Dublin Core metadata
        for field in METADATA_FIELDS:
            value = self.epub.get_metadata("DC", field)
            if value:
                metadata[field] = value[0][0]
            else:
                if field == "title":
                    raise ConversionError(
                        "EPUB file missing required title metadata",
                        ErrorCodes.INVALID_EPUB,
                    )
                logger.warning(f"Missing metadata field: {field}")
                self.warnings.append(
                    ConversionWarning(
                        type=WarningTypes.UNSUPPORTED_METADATA,
                        message=f"Missing metadata field: {field}",
                    )
                )

        for cover in self.epub.get_items_of_type(ebooklib.ITEM_COVER):
            logger.trace(f"Cover: {cover}")
            cover_bytes = cover.get_content()
            # cover_image = Image.open(io.BytesIO(cover_bytes))
            # cover_image.thumbnail((256, 256))
            # cover_image.show()
            # TODO: if more than one cover,
            # show the cover images to the user, or use the largest
            if cover_bytes:
                metadata["cover_image"] = base64.b64encode(cover_bytes).decode("utf-8")
                # just take the first cover
                break

        return BookMetadata(**metadata)

    def _clean_text(self, html_content: str) -> str:
        """Clean HTML content and extract plain text.

        Args:
            html_content: Raw HTML content

        Returns:
            str: Cleaned text content
        """
        soup = BeautifulSoup(html_content, "html.parser")

        # Remove script and style elements
        for element in soup(["script", "style"]):
            element.decompose()

        # Handle non-text elements
        for element in soup.find_all(["img", "svg"]):
            logger.warning(f"Skipping non-text element: {element.name}")
            self.warnings.append(
                ConversionWarning(
                    type=WarningTypes.NON_TEXT_ELEMENT,
                    message=f"Skipping non-text element: {element.name}",
                )
            )
            element.decompose()

        # Get text and clean it
        text = soup.get_text()

        # Normalize whitespace
        text = re.sub(r"\s+", " ", text)
        text = text.strip()

        return text

    def _handle_link(
        self,
        item: epub.Link,
        page_count: dict[str, int],
        flattened_table_of_contents: list[epub.EpubItem | epub.Link],
    ) -> list[epub.EpubItem | epub.Link]:
        """Handle a link.

        Args:
            item: Link to handle
            page_count: Dictionary of page counts
            flattened_table_of_contents: Current list of flattened TOC items

        Returns:
            List of EPUB items
        """
        link_split = item.href.split("#")
        link = link_split[0]
        # We don't use the anchor directly here
        if item not in flattened_table_of_contents:
            # link within one big page
            page_count[link] = page_count.get(link, 0) + 1
            page = self.epub.get_item_with_href(link)
            if page not in flattened_table_of_contents:
                flattened_table_of_contents.append(page)
            if page_count[link] > 1:
                self._chapters_in_one_page = True
            flattened_table_of_contents.append(item)
        else:
            logger.trace(f"link already in flattened_table_of_contents: {link}")
            item_from_link = self.epub.get_item_with_href(link)
            if item_from_link in flattened_table_of_contents:
                self._chapters_in_one_page = True
            flattened_table_of_contents.append(item_from_link)

        return flattened_table_of_contents

    def _flatten_table_of_contents(
        self, table_of_contents: list[epub.Section | epub.Link]
    ) -> list[epub.EpubItem | epub.Link]:
        """Flatten the table of contents.

        Args:
            table_of_contents: Table of contents

        Returns:
            list[epub.EpubItem]: Flattened list of EPUB items
        """
        logger.trace(f"length of toc: {len(table_of_contents)}")
        flattened_table_of_contents: list[epub.EpubItem | epub.Link] = []
        page_count: dict[str, int] = {}
        for item in table_of_contents:
            if isinstance(item, epub.EpubItem):
                flattened_table_of_contents.append(item)
            elif isinstance(item, epub.Link):
                flattened_table_of_contents = self._handle_link(
                    item, page_count, flattened_table_of_contents
                )
            elif isinstance(item, epub.Section):
                flattened_table_of_contents.extend(
                    self._flatten_table_of_contents(item.children)
                )
            elif isinstance(item, tuple):
                section, children = item
                flattened_table_of_contents.extend(
                    self._flatten_table_of_contents(children)
                )
            else:
                logger.warning(f"Skipping non-link or section item: {item}")
                self.warnings.append(
                    ConversionWarning(
                        type=WarningTypes.FORMATTING_ISSUE,
                        message=f"Skipping non-link or section item: {item}",
                    )
                )
        return flattened_table_of_contents

    def _get_chapters_in_one_page(
        self, item: epub.EpubItem, table_of_contents: list[epub.Link]
    ) -> list[Chapter]:
        """Get the chapters from a single page EPUB format.

        Args:
            item: The HTML content of the book page
            table_of_contents: The table of contents of the book

        Returns:
            list[Chapter]: List of chapters extracted from the page
        """
        chapters: list[Chapter] = []
        order = 0

        raw_content = item.get_content().decode("utf-8")
        soup = BeautifulSoup(raw_content, "html.parser")

        # Find all chapter headings (headings with class or standard HTML headings)
        chapter_heads = soup.find_all(
            ["p", "h1", "h2", "h3"], class_=lambda c: c and "Heading" in c
        )

        if not chapter_heads and soup.find_all(["h1", "h2"]):
            # Use regular heading elements if no class-based headings found
            chapter_heads = soup.find_all(["h1", "h2"])

        # Process chapters from the headings we found
        for i, head in enumerate(chapter_heads):
            # Get the chapter title
            title = head.get_text(strip=True)

            # Get the chapter content by finding all content between this heading
            # and the next heading (or end of document)
            content = []
            current = head.find_next_sibling()
            next_heading = chapter_heads[i + 1] if i < len(chapter_heads) - 1 else None

            while current and current != next_heading:
                if current.name and current.name in ["p", "div"]:
                    content.append(current.get_text(strip=True))
                current = current.find_next_sibling()

            # Join the content paragraphs
            chapter_content = " ".join(content)
            order += 1

            # Create the chapter
            chapter = Chapter(
                title=title,
                content=chapter_content,
                order=order,
                id=head.get("id", f"chapter_{order}"),
            )
            chapters.append(chapter)

        # If we couldn't find chapters by headings, try table of contents links
        if not chapters:
            for link in table_of_contents:
                if not isinstance(link, epub.Link):
                    logger.debug(f"Skipping non-link item: {link}")
                    continue

                anchor = (
                    link.href.split("#")[1] if len(link.href.split("#")) > 1 else None
                )
                if not anchor:
                    logger.debug(f"Skipping non-chapter link: {link}")
                    continue

                head = soup.find(id=anchor)
                if not head:
                    logger.debug(f"Skipping non-chapter link: {link}")
                    continue

                # Get the chapter title
                title = link.title or head.get_text(strip=True)

                # Get the chapter content
                content = []
                current = head.find_next_sibling()
                while current and not (
                    current.name in ["h1", "h2", "h3"]
                    or (
                        current.name == "p"
                        and current.get("class")
                        and "Heading" in current.get("class")[0]
                    )
                ):
                    if current.name in ["p", "div"]:
                        content.append(current.get_text(strip=True))
                    current = current.find_next_sibling()

                # Join the content paragraphs
                chapter_content = " ".join(content)
                order += 1

                # Create the chapter
                chapter = Chapter(
                    title=title,
                    content=chapter_content,
                    order=order,
                    id=head.get("id", f"chapter_{order}"),
                )
                chapters.append(chapter)

        return chapters

    def _get_title_chapter(self) -> Chapter:
        """Get the title chapter."""
        return Chapter(
            title=self.metadata.title,
            content=self.metadata.book_sentence,
            order=-1,
            id="title",
        )

    def _get_chapters_from_pages(
        self,
        table_of_contents: list[epub.EpubItem],
    ) -> list[Chapter]:
        """Get the chapters from the pages of the EPUB file.

        Args:
            table_of_contents: The table of contents of the book
        """
        chapters: list[Chapter] = []
        order = 0

        for item in table_of_contents:
            if isinstance(item, epub.Link):
                item = self.epub.get_item_with_href(item.href)
            # Skip non-chapter items (e.g., TOC, copyright pages)
            if not self._is_chapter(item):
                logger.trace(f"Skipping non-chapter item: {item}")
                continue

            # Extract title from content or use fallback
            raw_content = item.get_content().decode("utf-8")
            title = self._extract_chapter_title(raw_content) or f"Chapter {order + 1}"
            logger.trace(f"chapter title: {title}")

            # Skip likely table of contents
            if title == self.metadata.title:
                continue

            content = self._clean_text(raw_content)
            # remove the title from the content
            content = self._remove_title_from_content(content, title)

            # Skip empty chapters
            if not content:
                logger.trace(f"Skipping empty chapter: {title}")
                continue

            chapter = Chapter(title=title, content=content, order=order, id=item.id)
            chapters.append(chapter)
            order += 1

        return chapters

    def _find_content_item_for_single_page(
        self, table_of_contents: list[epub.EpubItem | epub.Link]
    ) -> tuple[epub.EpubItem | None, list[epub.Link]]:
        """Find the main content item and TOC links for a single-page EPUB.

        Args:
            table_of_contents: The flattened table of contents

        Returns:
            tuple: (content_item, toc_links) - Main content item and TOC links
        """
        content_item = None
        # Find the first actual content item
        for item in table_of_contents:
            if isinstance(item, epub.EpubItem) and self._is_chapter(item):
                content_item = item
                break

        # Extract links from the table of contents
        toc_links = [item for item in table_of_contents if isinstance(item, epub.Link)]
        return content_item, toc_links

    def _get_unique_chapter_items(
        self, table_of_contents: list[epub.EpubItem | epub.Link]
    ) -> list[epub.EpubItem]:
        """Filter out duplicate chapter items from the table of contents.

        Args:
            table_of_contents: The flattened table of contents

        Returns:
            list[epub.EpubItem]: List of unique chapter items
        """
        unique_items = {}
        for item in table_of_contents:
            if isinstance(item, epub.Link):
                href = item.href.split("#")[0]
                epub_item = self.epub.get_item_with_href(href)
                if epub_item and self._is_chapter(epub_item):
                    unique_items[epub_item.file_name] = epub_item
            elif isinstance(item, epub.EpubItem) and self._is_chapter(item):
                unique_items[item.file_name] = item

        return list(unique_items.values())

    def _extract_chapters(self) -> list[Chapter]:
        """Extract chapters from the EPUB file.

        Returns:
            List[Chapter]: List of extracted chapters
        """
        chapters = []

        # Get the table of contents
        table_of_contents = self.epub.toc
        if table_of_contents:
            logger.trace(f"raw toc: {table_of_contents}")
            table_of_contents = self._flatten_table_of_contents(table_of_contents)
        else:
            table_of_contents = self.epub.get_items_of_type(ebooklib.ITEM_DOCUMENT)
            logger.trace("no toc, using all documents")

        logger.trace(f"toc: {table_of_contents}")
        logger.trace(f"chapters in one page: {self._chapters_in_one_page}")

        # Standardized handling for both EPUB formats
        if self._chapters_in_one_page:
            # For single-page EPUBs
            content_item, toc_links = self._find_content_item_for_single_page(
                table_of_contents
            )

            if content_item:
                chapters = self._get_chapters_in_one_page(content_item, toc_links)
            else:
                logger.warning("Could not find main content item for single-page EPUB")
        else:
            # For multi-page EPUBs
            unique_items = self._get_unique_chapter_items(table_of_contents)
            chapters = self._get_chapters_from_pages(unique_items)

        if not chapters:
            raise ConversionError(
                "No valid chapters found in EPUB file", ErrorCodes.INVALID_EPUB
            )

        # Add title chapter as the first chapter for both formats
        if self.metadata.title:
            chapters.insert(0, self._get_title_chapter())
            logger.trace(f"Book title added: {chapters[0]}")

        return sorted(chapters)

    def _is_cover(self, item: epub.EpubItem) -> bool:
        """Determine if an EPUB item is a cover.

        Args:
            item: EPUB item to check
        """
        return re.search(r"cover\.x?html$", item.file_name.lower()) is not None

    def _is_chapter(self, item: epub.EpubItem) -> bool:
        """Determine if an EPUB item is a chapter.

        Args:
            item: EPUB item to check

        Returns:
            bool: True if the item is a chapter
        """
        # Skip common non-chapter files
        skip_patterns = [
            r"toc\.x?html$",
            r"copyright\.x?html$",
            r"cover\.x?html$",
            r"title\.x?html$",
            r"colophon\.x?html$",
        ]
        skip_id_patterns = [r"pg-(header|footer|toc)$", r"(cover|toc|title|copyright)$"]

        # Check for known non-chapter patterns
        for pattern in skip_patterns:
            if re.search(pattern, item.file_name.lower()):
                return False

        for pattern in skip_id_patterns:
            if hasattr(item, "id") and re.search(pattern, item.id.lower()):
                return False

        # Make sure it's a document type that could be a chapter
        if not isinstance(item, epub.EpubHtml):
            return False

        # Check if the content is too short to be a chapter
        try:
            content = item.get_content().decode("utf-8")
            if len(content) < 100:  # Arbitrary small size that's likely not a chapter
                return False
        except Exception:
            # If we can't decode the content, it's probably not a chapter
            return False

        return True

    @staticmethod
    def _extract_chapter_title(raw_content: str) -> Optional[str]:
        """Extract chapter title from an EPUB item.

        Args:
            raw_content: Raw string of html content to extract title from

        Returns:
            Optional[str]: Extracted title or None
        """
        soup = BeautifulSoup(raw_content, "html.parser")

        # First try class-based headings (common in some EPUB formats)
        heading_with_class = soup.find(
            ["p", "div"], class_=lambda c: c and ("Heading" in c or "head" in c.lower())
        )
        if heading_with_class:
            title = heading_with_class.get_text(strip=True)
            if title:
                return title

        # Then try to find title in common heading elements
        for heading in soup.find_all(["h1", "h2", "h3"]):
            title = heading.get_text(strip=True)
            if title:
                return title

        # Try the first paragraph as a last resort
        first_p = soup.find("p")
        if first_p:
            title = first_p.get_text(strip=True)
            if title and len(title) < 100:  # Only use short paragraphs as titles
                return title

        return None

    @staticmethod
    def _remove_title_from_content(content: str, title: str) -> str:
        """Remove the title from the content.

        Args:
            content: Content to remove title from
            title: Title to remove

        Returns:
            str: Content with title removed
        """
        title_split = title.split()
        content_split = content[: len(title)].split()
        rest_of_content = content[len(title) :]
        while title_split and content_split and title_split[0] == content_split[0]:
            logger.trace(f"removing title from content: {title_split[0]}")
            title_split.pop(0)
            content_split.pop(0)
        content_split.append(rest_of_content)
        content = " ".join(content_split)
        return content
