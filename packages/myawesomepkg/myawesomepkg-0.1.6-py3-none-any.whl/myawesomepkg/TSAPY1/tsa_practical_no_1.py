# -*- coding: utf-8 -*-
"""TSA_Practical_No_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-xNPJwhkAO4KzKFMvXII92dc9Y_VTQ8H

**Practical No 1:**
**Aim: Handling timeseries data**

a. Import timeseries data

b. Visualizing timeseries data using various plot

# **A. Load and Explore Time Series Data**
"""

from pandas import read_csv
series = read_csv('/content/daily-total-female-births.csv', header=0, index_col=0, parse_dates=True)
print(type(series))
print(series.head())

"""The arguments to the **readcsv()** function. We provide it a number of hints to ensure the data is loaded as a Series.

1.  **header=0:** We must specify the header information at row 0.
2.   **parse_dates=True:** We give the function a hint that data in the first column contains dates that need to be parsed.
3. **index_col=0:** We hint that the first column contains the index information for the time series.
4.  **squeeze=True:** We hint that we only have one data column and that we are interested in a Series and not a DataFrame.

You can use the **head()** function to peek at the first 5 records or specify the first n number of records to review
"""

print(series.head(10))

"""**Number of Observations**
You can get the dimensionality of your Series using the size parameter.
"""

print(series.size)

""" **Querying By Time**
 You can slice, dice, and query your series using the time index. For example, you can access all observations in January as follows:

**series.loc[]**

Access a group of rows and columns by label(s) or a boolean array.
.loc[] is primarily label based, but may also be used with a boolean array.
"""

print(series.loc["1959-01"])

"""**Descriptive Statistics**
Calculating descriptive statistics on your time series can help get an idea of the distribution and
spread of values.
The **describe()** function creates
a 7 number summary of the loaded time series including mean, standard deviation, median,
minimum, and maximum of the observations
"""

print(series.describe())

"""# **B. Data Visualization**
Visualization plays an important role in time series analysis and forecasting. Plots of the raw
sample data can provide valuable diagnostics to identify temporal structures like trends, cycles,
and seasonality that can influence the choice of model. A problem is that many novices in the
field of time series forecasting stop with line plots.

Different types of visualizations that you can use on your own time series data. They are:
1. Line Plots.
2. Histograms and Density Plots.
3. Box and Whisker Plots.
4. Heat Maps.
5. Lag Plots or Scatter Plots.
6. Autocorrelation Plots.

**Minimum Daily Temperatures Dataset**
We will use the Minimum Daily Temperatures dataset as an example. This dataset
describes the minimum daily temperatures over 10 years (1981-1990) in the city Melbourne,
Australia.
"""

from pandas import read_csv
from matplotlib import pyplot
series = read_csv('daily-min-temperatures.csv', header=0, index_col=0,parse_dates=True)
print(series.head())
series=series.squeeze()
type(series)
print(series.describe())

"""**Line Plot**
The first, and perhaps most popular, visualization for time series is the line plot. In this plot,
time is shown on the x-axis with observation values along the y-axis. Below is an example of
visualizing the Pandas Series of the Minimum Daily Temperatures dataset directly as a line
plot.
"""

series.plot()
pyplot.show()

"""Changing the style of the line to
be black dots instead of a connected line (the style=’k.’ argument).
"""

series.plot(style='k.')
pyplot.show()

series.plot(style='k--')
pyplot.show()

"""It can be helpful to compare line plots for the same interval, such as from day-to-day,
month-to-month, and year-to-year. The Minimum Daily Temperatures dataset spans 10
years. We can group data by year and create a line plot for each year for direct comparison. The example below shows how to do this. First the observations are grouped by year (series.groupby(Grouper(freq=’A’))).

A **Grouper** allows the user to specify a groupby instruction for an object.

This specification will select a column via the key parameter, or if the level and/or axis parameters are given, a level of the index of the target object.

If axis and/or level are passed as keywords to both Grouper and groupby, the values passed to Grouper take precedence

The groups are then enumerated and the observations for each year are stored as columns
in a new DataFrame. Finally, a plot of this contrived DataFrame is created with each column
visualized as a subplot with legends removed to cut back on the clutter.

The **squeeze()** method converts a single column DataFrame into a Series.
"""

from pandas import read_csv
from pandas import DataFrame
from pandas import Grouper
from matplotlib import pyplot
series = read_csv('/content/daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True)
#print(series.head())

series=series.squeeze()
#print(series.head())
groups = series.groupby(Grouper(freq='A'))
#print(groups)
years = DataFrame()
#print(years)
for name, group in groups:
  years[name.year] = group.values
  print(years)
years.plot(subplots=True, legend=False)
pyplot.show()

"""**Histogram and Density Plots**

Another important visualization is of the distribution of observations themselves. This means a
plot of the values without the temporal ordering. Some linear time series forecasting methods
assume a well-behaved distribution of observations (i.e. a bell curve or normal distribution).
This can be explicitly checked using tools like statistical hypothesis tests. But plots can provide
a useful first check of the distribution of observations both on raw observations and after any
type of data transform has been performed.
The example below creates a histogram plot of the observations in the Minimum Daily
Temperatures dataset. A histogram groups values into bins, and the frequency or count of
observations in each bin can provide insight into the underlying distribution of the observations. Histograms and density plots provide insight into the distribution of all observations, but we
may be interested in the distribution of values by time interval.
"""

series.hist()
pyplot.show()

"""Generate Kernel Density Estimate plot using Gaussian kernels."""

series.plot(kind='kde')
pyplot.show()

years.boxplot()
pyplot.show()

"""**Box and Whisker Plots by Interval**

 Another type of plot that is
useful to summarize the distribution of observations is the box and whisker plot. This plot
draws a box around the 25th and 75th percentiles of the data that captures the middle 50% of
observations. A line is drawn at the 50th percentile (the median) and whiskers are drawn above
and below the box to summarize the general extents of the observations. Dots are drawn for
outliers outside the whiskers or extents of the data.

Box and whisker plots can be created and compared for each interval in a time series, such
as years, months, or days. Below is an example of grouping the Minimum Daily Temperatures
dataset by years, as was done above in the plot example. A box and whisker plot is then created
for each year and lined up side-by-side for direct comparison.

Within an interval,
it can help to spot outliers (dots above or below the whiskers). Across intervals, in this case
years, we can look for multiple year trends, seasonality, and other structural information that
could be modeled
"""

from pandas import read_csv
from pandas import DataFrame
from pandas import Grouper
from matplotlib import pyplot
series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True)
series=series.squeeze()
groups = series.groupby(Grouper(freq='A'))
years = DataFrame()
for name, group in groups:
 years[name.year] = group.values
years.boxplot()
pyplot.show()

"""**Heat Maps**
A matrix of numbers can be plotted as a surface, where the values in each cell of the matrix are
assigned a unique color. This is called a heatmap, as larger values can be drawn with warmer
colors (yellows and reds) and smaller values can be drawn with cooler colors (blues and greens).
Like the box and whisker plots, we can compare observations between intervals using a heat
map.
In the case of the Minimum Daily Temperatures, the observations can be arranged into a
matrix of year-columns and day-rows, with minimum temperature in the cell for each day. A
heat map of this matrix can then be plotted. Below is an example of creating a heatmap of
the Minimum Daily Temperatures data. The matshow() function from the Matplotlib library
is used as no heatmap support is provided directly in Pandas. For convenience, the matrix is rotated (transposed) so that each row represents one year and each column one day. This
provides a more intuitive, left-to-right layout of the data.

"""

from pandas import read_csv
from pandas import DataFrame
from pandas import Grouper
from matplotlib import pyplot
series = read_csv('daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True)
series=series.squeeze()
groups = series.groupby(Grouper(freq='A'))
years = DataFrame()
for name, group in groups:
 years[name.year] = group.values
years = years.T
print(years)
pyplot.matshow(years, interpolation=None, aspect='auto')
pyplot.show()

"""The plot shows the cooler minimum temperatures in the middle days of the years and
the warmer minimum temperatures in the start and ends of the years, and all the fading and
complexity in between.

**Lag Scatter Plots**
Time series modeling assumes a relationship between an observation and the previous observation.
Previous observations in a time series are called lags, with the observation at the previous timestep called lag=1, the observation at two time steps ago lag=2, and so on. A useful type of plot
to explore the relationship between each observation and a lag of that observation is called the
scatter plot. Pandas has a built-in function for exactly this called the lag plot. It plots the
observation at time t on the x-axis and the observation at the next time step (t+1) on the
y-axis.

If the points cluster along a diagonal line from the bottom-left to the top-right of the plot,
it suggests a positive correlation relationship.
 If the points cluster along a diagonal line from the top-left to the bottom-right, it suggests
a negative correlation relationship.
 Either relationship is good as they can be modeled.

More points tighter in to the diagonal line suggests a stronger relationship and more spread
from the line suggests a weaker relationship. A ball in the middle or a spread across the plot
suggests a weak or no relationship.
"""

from pandas.plotting import lag_plot
lag_plot(series)
pyplot.show()

"""The plot created from running the example shows a relatively strong positive correlation
between observations and their lag1 values

**Autocorrelation Plots**
We can quantify the strength and type of relationship between observations and their lags. In
statistics, this is called correlation, and when calculated against lag values in time series, it is
called autocorrelation (self-correlation). A correlation value calculated between two groups of
numbers, such as observations and their lag=1 values, results in a number between -1 and 1.
The sign of this number indicates a negative or positive correlation respectively. A value close to
zero suggests a weak correlation, whereas a value closer to -1 or 1 indicates a strong correlation.
Correlation values, called correlation coefficients, can be calculated for each observation and
different lag values. Once calculated, a plot can be created to help better understand how this
relationship changes over the lag. This type of plot is called an autocorrelation plot and Pandas provides this capability built in, called the autocorrelation plot() function.
"""

from pandas.plotting import autocorrelation_plot
autocorrelation_plot(series)
pyplot.show()

"""The resulting plot shows lag along the x-axis and the correlation on the y-axis. Dotted lines
are provided that indicate any correlation values above those lines are statistically significant
(meaningful). We can see that for the Minimum Daily Temperatures dataset we see cycles of
strong negative and positive correlation. This captures the relationship of an observation with
past observations in the same and opposite seasons or times of year. Sine waves like those seen
in this example are a strong sign of seasonality in the dataset
"""