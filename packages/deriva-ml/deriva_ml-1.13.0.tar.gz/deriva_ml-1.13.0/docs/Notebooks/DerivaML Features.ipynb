{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ffee41-4986-4196-b35d-b38b6e10490a",
   "metadata": {},
   "source": [
    "# DerivaML Features\n",
    "\n",
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library.\n",
    "\n",
    "\n",
    "In DerivaML, \"features\" are the way we attach values to objects in the catalog. A feature could be a computed value that serves as input to a ML model, or it could be a label, that is the result of running a model.  A feature can be a controlled vocabulary term, an asset, or a value.\n",
    "\n",
    "Each feature in the catalog is distinguished by the name of the feature, the identity of the object that the feature is being attached to, and the execution RID of the process that generated the feature value\n",
    "\n",
    "## Set up Deriva for test case"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff605747-195b-40a1-b915-0e799f8d0748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:50:50.965124Z",
     "start_time": "2025-04-09T05:50:50.949635Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:50:52.148916Z",
     "start_time": "2025-04-09T05:50:50.968509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import builtins\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml import ColumnDefinition, BuiltinTypes, MLVocab, DerivaSystemColumns\n",
    "from deriva_ml.demo_catalog import create_demo_catalog, DemoML\n",
    "from deriva_ml import ExecutionConfiguration\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import random"
   ],
   "id": "e38951f9bf858b58",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set the details for the catalog we want and authenticate to the server if needed.",
   "id": "6a3738109c9344d1"
  },
  {
   "cell_type": "code",
   "id": "9ee79ab7-a3f7-4c69-9c80-336871c13ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:50:52.348380Z",
     "start_time": "2025-04-09T05:50:52.190067Z"
    }
   },
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a test catalog and get an instance of the DerivaML class.",
   "id": "a23e5177-106b-48b6-b5e0-a126d35f4084"
  },
  {
   "cell_type": "code",
   "id": "e9bddcf0-27ea-40b3-a388-b77635586fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:22.479284Z",
     "start_time": "2025-04-09T05:50:52.357455Z"
    }
   },
   "source": [
    "test_catalog = create_demo_catalog(hostname, domain_schema)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)\n",
    "display(f\"Created demo catalog at {hostname}:{test_catalog.catalog_id}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 22:51:13,505 - deriva_ml.WARNING - File /Users/carl/Repos/Projects/deriva-ml/docs/Notebooks/DerivaML Features.ipynb has been modified since last commit. Consider commiting before executing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Created demo catalog at dev.eye-ai.org:1854'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "353d51c9-b8a6-4b75-a0da-ffa2db134169",
   "metadata": {},
   "source": [
    "## Define Features\n",
    "A feature is a set of values that are attached to a table in the DerivaML catalog. Instances of features are distinguished from one another by the ID of the execution that produced the feature value. The execution could be the result of a program, or it could be a manual process by which a person defines a set of values\n",
    "\n",
    "To create a new feature, we need to know the name of the feature, the table to which it is attached, and the set of values that make up the feature.  The values could be terms from a controlled vocabulary, a set of one or more file based assets, or other values, such as integers, or strings. However, use of strings outside of controlled vocabularies is discouraged.\n",
    "\n",
    "For our example, we are going to define three features.  Two of them will use values from a controlled vocabulary, which we need to\n",
    "create.  The third feature will consist of a file whose contents we will generate.  To start, we will need to create the controlled \n",
    "vocabularies, and create an asset table for the feature values."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d726b44-c60f-435a-9966-cfe3fc3da2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:25.883018Z",
     "start_time": "2025-04-09T05:51:22.509957Z"
    }
   },
   "source": [
    "# Prerequisites for our feature, which will include a CV term and asset.\n",
    "\n",
    "# Create a vocabulary and add a term to it to use in our features.\n",
    "ml_instance.create_vocabulary(\"SubjectHealth\", \"A vocab\")\n",
    "ml_instance.add_term(\"SubjectHealth\", \"Sick\", description=\"The subject self reports that they are sick\")\n",
    "ml_instance.add_term(\"SubjectHealth\", \"Well\", description=\"The subject self reports that they feel well\")\n",
    "\n",
    "ml_instance.create_vocabulary(\"ImageQuality\", \"Controlled vocabulary for image quality\")\n",
    "ml_instance.add_term(\"ImageQuality\", \"Good\", description=\"The image is good\")\n",
    "ml_instance.add_term(\"ImageQuality\", \"Bad\", description=\"The image is bad\")\n",
    "\n",
    "box_asset = ml_instance.create_asset(\"BoundingBox\", comment=\"A file that contains a cropped version of a image\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We are now ready to create our new features. Each feature will be associated with a table, have a name, and then the set of values that \n",
    "define the feature. After we create the features, we can list the features associated with each table type that we have."
   ],
   "id": "ef0ada11d1d5e769"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:29.080404Z",
     "start_time": "2025-04-09T05:51:25.894048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ml_instance.create_feature(\"Subject\", \"Health\",\n",
    "                                        terms=[\"SubjectHealth\"],\n",
    "                                        metadata=[ColumnDefinition(name='Scale', type=BuiltinTypes.int2, nullok=True)],\n",
    "                           optional=['Scale'])\n",
    "\n",
    "ml_instance.create_feature('Image', 'BoundingBox', assets=[box_asset])\n",
    "ml_instance.create_feature('Image', 'Quality', terms=[\"ImageQuality\"])\n",
    "\n",
    "display(\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")]\n",
    ")"
   ],
   "id": "8dcaabf3e33a1f9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Subject:Health']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Image:BoundingBox', 'Image:Quality']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "83d2bd27-da2d-4918-9c8a-378c95addfcc",
   "metadata": {},
   "source": [
    "Now we can add some features to our images.  To streamline the creation of new feature, we create a class that is specific to the arguments required to create it."
   ]
  },
  {
   "cell_type": "code",
   "id": "7f6b68c6-4bc0-4837-a2b6-729d116a8702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:29.143218Z",
     "start_time": "2025-04-09T05:51:29.097628Z"
    }
   },
   "source": [
    "ImageQualityFeature = ml_instance.feature_record_class(\"Image\", \"Quality\")\n",
    "ImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"BoundingBox\")\n",
    "SubjectWellnessFeature= ml_instance.feature_record_class(\"Subject\", \"Health\")\n",
    "\n",
    "display(\n",
    "    Markdown('### SubjectWellnessFeature'),\n",
    "    Markdown(f'* feature_columns: ' f'```{[c.name for c in SubjectWellnessFeature.feature_columns()]}```'),\n",
    "    Markdown(f'* required columns: ' f'```{[c.name  for c in SubjectWellnessFeature.feature_columns() if not c.nullok]}```'),\n",
    "    Markdown(f'* term columns: ' f'```{[c.name for c in SubjectWellnessFeature.term_columns()]}```'),\n",
    "    Markdown(f'* value columns: ' f'```{[c.name for c in SubjectWellnessFeature.value_columns()]}```'),\n",
    "    Markdown(f'* asset columns: ' f'```{[c.name for c in SubjectWellnessFeature.asset_columns()]}```'),\n",
    "\n",
    "    Markdown('### ImageQualityFeature'),\n",
    "    Markdown( f'* feature_columns:* ' f'```{[c.name for c in ImageQualityFeature.feature_columns()]}```'),\n",
    "    Markdown(f'*  required columns:* ' f'```{[c.name  for c in ImageQualityFeature.feature_columns() if not c.nullok]}```'),\n",
    "    Markdown(f'* term columns: * ' f'```{[c.name for c in ImageQualityFeature.term_columns()]}```'),\n",
    "    Markdown(f'* value columns: * ' f'```{[c.name for c in ImageQualityFeature.value_columns()]}```'),\n",
    "    Markdown(f'* asset columns: * ' f'```{[c.name for c in ImageQualityFeature.asset_columns()]}```'),\n",
    "\n",
    "    Markdown('### ImageBoundingboxFeature'),\n",
    "    Markdown( f'* feature_columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.feature_columns()]}```'),\n",
    "    Markdown(f'* required columns:* ' f'```{[c.name  for c in ImageBoundingboxFeature.feature_columns() if not c.nullok]}```'),\n",
    "    Markdown( f'* term columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.term_columns()]}```'),\n",
    "    Markdown( f'* value columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.value_columns()]}```'),\n",
    "    Markdown( f'* asset columns:* ' f'```{[c.name for c in ImageBoundingboxFeature.asset_columns()]}```'),\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### SubjectWellnessFeature"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* feature_columns: ```['SubjectHealth', 'Scale']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* required columns: ```['SubjectHealth']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* term columns: ```['SubjectHealth']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* value columns: ```['Scale']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* asset columns: ```[]```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### ImageQualityFeature"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* feature_columns:* ```['ImageQuality']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "*  required columns:* ```['ImageQuality']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* term columns: * ```['ImageQuality']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* value columns: * ```[]```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* asset columns: * ```[]```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### ImageBoundingboxFeature"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* feature_columns:* ```['BoundingBox']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* required columns:* ```['BoundingBox']```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* term columns:* ```[]```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* value columns:* ```[]```"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "* asset columns:* ```['BoundingBox']```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "92416df1-e3f9-4097-bc19-b24712dc7242",
   "metadata": {},
   "source": [
    "## Add feature values\n",
    "\n",
    "Now using feature classes, we can create some instances of the feature and add them.  We must have a execution_rid in order to define the feature. In our example, we will assume that the execution that calculates the feature values will use a model file to configure it, so ww will need to create and upload the file before we can start the execution."
   ]
  },
  {
   "cell_type": "code",
   "id": "cdcc8f5c-874b-4bf9-89ef-e1ea90b9f91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:31.775007Z",
     "start_time": "2025-04-09T05:51:29.174514Z"
    }
   },
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"Feature Notebook Workflow\", description=\"A Workflow that uses Deriva ML API\")\n",
    "ml_instance.add_term(MLVocab.asset_type, \"API_Model\", description=\"Model for our Notebook workflow\")\n",
    "\n",
    "# Get the workflow for this notebook\n",
    "notebook_workflow = ml_instance.create_workflow(\n",
    "    name=\"API Workflow\", \n",
    "    workflow_type=\"Feature Notebook Workflow\"\n",
    ")\n",
    "\n",
    "feature_execution = ml_instance.create_execution(\n",
    "    ExecutionConfiguration(\n",
    "        workflow=notebook_workflow,\n",
    "        description=\"Our Sample Workflow instance\")\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 22:51:30,380 - deriva_ml.WARNING - File /Users/carl/Repos/Projects/deriva-ml/docs/Notebooks/DerivaML Features.ipynb has been modified since last commit. Consider commiting before executing\n",
      "2025-04-08 22:51:30,987 - deriva_ml.INFO - Downloading assets ...\n",
      "2025-04-08 22:51:31,641 - deriva_ml.INFO - Initialize status finished.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:32.045122Z",
     "start_time": "2025-04-09T05:51:31.797623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the IDs of al of the things that we are going to want to attach features to.\n",
    "subject_rids = [i['RID'] for i in ml_instance.domain_path.tables['Subject'].entities().fetch()]\n",
    "image_rids = [i['RID'] for i in ml_instance.domain_path.tables['Image'].entities().fetch()]"
   ],
   "id": "f99531b95369739d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have the list of objects that we want to add features to, we can define the sets of feature values we want to record and then add these features in the catalog.",
   "id": "11eb83790ebd673c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:38.352689Z",
     "start_time": "2025-04-09T05:51:32.049590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a new set of images.  For fun, lets wrap this in an execution so we get status updates\n",
    "bounding_box_files = []\n",
    "for i in range(10):\n",
    "    bounding_box_file = feature_execution.asset_file_path(\"BoundingBox\", f\"box{i}.txt\")\n",
    "    with open(bounding_box_file, \"w\") as fp:\n",
    "        fp.write(f\"Hi there {i}\")\n",
    "    bounding_box_files.append(bounding_box_file)\n",
    "\n",
    "image_bounding_box_feature_list = [\n",
    "    ImageBoundingboxFeature(\n",
    "        Image=image_rid,\n",
    "        BoundingBox=asset_name,\n",
    "    )\n",
    "    for image_rid, asset_name in zip(image_rids, itertools.cycle(bounding_box_files))\n",
    "]\n",
    "\n",
    "image_quality_feature_list = [\n",
    "    ImageQualityFeature(\n",
    "        Image=image_rid,\n",
    "        ImageQuality=[\"Good\", \"Bad\"][random.randint(0, 1)],\n",
    "    )\n",
    "    for image_rid in image_rids\n",
    "]\n",
    "\n",
    "subject_feature_list = [\n",
    "    SubjectWellnessFeature(\n",
    "        Subject=subject_rid,\n",
    "        SubjectHealth=[\"Well\", \"Sick\"][random.randint(0, 1)],\n",
    "        Scale=random.randint(1, 10),\n",
    "    )\n",
    "    for subject_rid in subject_rids\n",
    "]\n",
    "\n",
    "with feature_execution.execute() as execution:\n",
    "    feature_execution.add_features(image_bounding_box_feature_list)\n",
    "    feature_execution.add_features(image_quality_feature_list)\n",
    "    feature_execution.add_features(subject_feature_list)\n",
    "\n",
    "# Upload all of the new assets that we have created during the execution.\n",
    "feature_execution.upload_execution_outputs()"
   ],
   "id": "bf0c2b3fe320ecea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 22:51:33,317 - deriva_ml.INFO - Start execution  ...\n",
      "2025-04-08 22:51:33,432 - deriva_ml.INFO - Successfully run Ml.\n",
      "2025-04-08 22:51:33,550 - deriva_ml.INFO - Algorithm execution ended.\n",
      "2025-04-08 22:51:33,840 - deriva_ml.INFO - Uploading execution files...\n",
      "2025-04-08 22:51:33,956 - deriva.transfer.upload.deriva_upload.INFO - Initializing uploader: GenericUploader v1.7.7 [Python 3.10.16, macOS-15.4-x86_64-i386-64bit]\n",
      "2025-04-08 22:51:34,124 - deriva.transfer.upload.deriva_upload.INFO - Scanning files in directory [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset]...\n",
      "2025-04-08 22:51:34,126 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box7.txt].\n",
      "2025-04-08 22:51:34,126 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box6.txt].\n",
      "2025-04-08 22:51:34,127 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box4.txt].\n",
      "2025-04-08 22:51:34,127 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box5.txt].\n",
      "2025-04-08 22:51:34,127 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box1.txt].\n",
      "2025-04-08 22:51:34,128 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box0.txt].\n",
      "2025-04-08 22:51:34,128 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box2.txt].\n",
      "2025-04-08 22:51:34,129 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box3.txt].\n",
      "2025-04-08 22:51:34,129 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box8.txt].\n",
      "2025-04-08 22:51:34,129 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box9.txt].\n",
      "2025-04-08 22:51:34,129 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250408_225131.txt].\n",
      "2025-04-08 22:51:34,130 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/configuration.json].\n",
      "2025-04-08 22:51:34,130 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box7.txt]\n",
      "2025-04-08 22:51:34,131 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box7.txt].\n",
      "2025-04-08 22:51:34,131 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box7.txt]. Please wait...\n",
      "2025-04-08 22:51:34,133 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box7.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:34,613 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box6.txt]\n",
      "2025-04-08 22:51:34,613 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box6.txt].\n",
      "2025-04-08 22:51:34,614 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box6.txt]. Please wait...\n",
      "2025-04-08 22:51:34,615 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box6.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:34,784 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box4.txt]\n",
      "2025-04-08 22:51:34,786 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box4.txt].\n",
      "2025-04-08 22:51:34,786 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box4.txt]. Please wait...\n",
      "2025-04-08 22:51:34,787 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box4.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:34,954 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box5.txt]\n",
      "2025-04-08 22:51:34,955 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box5.txt].\n",
      "2025-04-08 22:51:34,955 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box5.txt]. Please wait...\n",
      "2025-04-08 22:51:34,956 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box5.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:35,123 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box1.txt]\n",
      "2025-04-08 22:51:35,124 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box1.txt].\n",
      "2025-04-08 22:51:35,124 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box1.txt]. Please wait...\n",
      "2025-04-08 22:51:35,125 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box1.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:35,292 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box0.txt]\n",
      "2025-04-08 22:51:35,293 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box0.txt].\n",
      "2025-04-08 22:51:35,294 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box0.txt]. Please wait...\n",
      "2025-04-08 22:51:35,295 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box0.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:35,466 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box2.txt]\n",
      "2025-04-08 22:51:35,467 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box2.txt].\n",
      "2025-04-08 22:51:35,467 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box2.txt]. Please wait...\n",
      "2025-04-08 22:51:35,468 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box2.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:35,634 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box3.txt]\n",
      "2025-04-08 22:51:35,635 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box3.txt].\n",
      "2025-04-08 22:51:35,635 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box3.txt]. Please wait...\n",
      "2025-04-08 22:51:35,636 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box3.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:35,800 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box8.txt]\n",
      "2025-04-08 22:51:35,801 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box8.txt].\n",
      "2025-04-08 22:51:35,802 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box8.txt]. Please wait...\n",
      "2025-04-08 22:51:35,803 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box8.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:35,968 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box9.txt]\n",
      "2025-04-08 22:51:35,969 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box9.txt].\n",
      "2025-04-08 22:51:35,969 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box9.txt]. Please wait...\n",
      "2025-04-08 22:51:35,971 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/demo-schema/BoundingBox/box9.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:36,145 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250408_225131.txt]\n",
      "2025-04-08 22:51:36,146 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250408_225131.txt].\n",
      "2025-04-08 22:51:36,147 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250408_225131.txt]. Please wait...\n",
      "2025-04-08 22:51:36,149 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250408_225131.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:36,517 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/configuration.json]\n",
      "2025-04-08 22:51:36,517 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/configuration.json].\n",
      "2025-04-08 22:51:36,518 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/configuration.json]. Please wait...\n",
      "2025-04-08 22:51:36,519 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/49W/asset/deriva-ml/Execution_Metadata/configuration.json] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-08 22:51:36,818 - deriva.transfer.upload.deriva_upload.INFO - File upload processing completed: 12 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n",
      "2025-04-08 22:51:37,284 - deriva_ml.INFO - Updating features...\n",
      "2025-04-08 22:51:37,892 - deriva_ml.INFO - Upload assets complete\n",
      "2025-04-08 22:51:38,081 - deriva_ml.INFO - Successfully end the execution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'demo-schema/BoundingBox': [('box7.txt', '49Y'),\n",
       "  ('box6.txt', '4A0'),\n",
       "  ('box4.txt', '4A2'),\n",
       "  ('box5.txt', '4A4'),\n",
       "  ('box1.txt', '4A6'),\n",
       "  ('box0.txt', '4A8'),\n",
       "  ('box2.txt', '4AA'),\n",
       "  ('box3.txt', '4AC'),\n",
       "  ('box8.txt', '4AE'),\n",
       "  ('box9.txt', '4AG')],\n",
       " 'deriva-ml/Execution_Metadata': [('environment_snapshot_20250408_225131.txt',\n",
       "   '4AJ'),\n",
       "  ('configuration.json', '4AM')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:38.766830Z",
     "start_time": "2025-04-09T05:51:38.392823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "display(\n",
    "    Markdown('### Wellness'),\n",
    "    pd.DataFrame(ml_instance.list_feature_values(\"Subject\", \"Health\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),\n",
    "    Markdown('### Image Quality'),\n",
    "    pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"Quality\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),\n",
    "    Markdown('### BoundingBox'),\n",
    "    pd.DataFrame(ml_instance.list_feature_values(\"Image\", \"BoundingBox\")).drop(columns=DerivaSystemColumns + ['Feature_Name']),\n",
    ")"
   ],
   "id": "1dc086187029b49d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### Wellness"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  Execution Subject SubjectHealth  Scale\n",
       "0       49W     3MR          Sick      2\n",
       "1       49W     3MT          Well     10\n",
       "2       49W     3MW          Well      7\n",
       "3       49W     3MY          Well      8"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution</th>\n",
       "      <th>Subject</th>\n",
       "      <th>SubjectHealth</th>\n",
       "      <th>Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49W</td>\n",
       "      <td>3MR</td>\n",
       "      <td>Sick</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49W</td>\n",
       "      <td>3MT</td>\n",
       "      <td>Well</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49W</td>\n",
       "      <td>3MW</td>\n",
       "      <td>Well</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49W</td>\n",
       "      <td>3MY</td>\n",
       "      <td>Well</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### Image Quality"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  Execution Image ImageQuality\n",
       "0       49W   3N6         Good\n",
       "1       49W   3N8          Bad\n",
       "2       49W   3NA         Good\n",
       "3       49W   3NC          Bad"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution</th>\n",
       "      <th>Image</th>\n",
       "      <th>ImageQuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49W</td>\n",
       "      <td>3N6</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49W</td>\n",
       "      <td>3N8</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49W</td>\n",
       "      <td>3NA</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49W</td>\n",
       "      <td>3NC</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### BoundingBox"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  Execution Image BoundingBox\n",
       "0       49W   3N6         4A8\n",
       "1       49W   3N8         4A6\n",
       "2       49W   3NA         4AA\n",
       "3       49W   3NC         4AC"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Execution</th>\n",
       "      <th>Image</th>\n",
       "      <th>BoundingBox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49W</td>\n",
       "      <td>3N6</td>\n",
       "      <td>4A8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49W</td>\n",
       "      <td>3N8</td>\n",
       "      <td>4A6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49W</td>\n",
       "      <td>3NA</td>\n",
       "      <td>4AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49W</td>\n",
       "      <td>3NC</td>\n",
       "      <td>4AC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:38.849079Z",
     "start_time": "2025-04-09T05:51:38.829281Z"
    }
   },
   "cell_type": "code",
   "source": "display(HTML(f'<a href={ml_instance.chaise_url(\"Subject\")}>Browse Subject Table</a>'))",
   "id": "cd0d85fc85f7fc66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<a href=https://dev.eye-ai.org/chaise/recordset/#1854/demo-schema:Subject>Browse Subject Table</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T05:51:39.142636Z",
     "start_time": "2025-04-09T05:51:38.926190Z"
    }
   },
   "cell_type": "code",
   "source": "test_catalog.delete_ermrest_catalog(really=True)",
   "id": "6e76bbdf-2441-4444-be7f-e55399bcc32a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [204]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deriva-test",
   "language": "python",
   "name": "deriva-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
