{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ffee41-4986-4196-b35d-b38b6e10490a",
   "metadata": {},
   "source": [
    "# DerivaML Execution\n",
    "\n",
    "DerivaML is a class library built on the Deriva Scientific Asset management system that is designed to help simplify a number of the basic operations associated with building and testing ML libraries based on common toolkits such as TensorFlow.  This notebook reviews the basic features of the DerivaML library."
   ]
  },
  {
   "cell_type": "code",
   "id": "ff605747-195b-40a1-b915-0e799f8d0748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:44:58.697470Z",
     "start_time": "2025-04-09T15:44:58.683021Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9493a5ef-86b9-490b-a1d5-f461fdcd68ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:45:04.519191Z",
     "start_time": "2025-04-09T15:45:02.869957Z"
    }
   },
   "source": [
    "import builtins\n",
    "from deriva.core.utils.globus_auth_utils import GlobusNativeLogin\n",
    "from deriva_ml import ExecutionConfiguration, MLVocab, DerivaSystemColumns, DatasetSpec\n",
    "from deriva_ml.demo_catalog import create_demo_catalog, DemoML\n",
    "from IPython.display import display, Markdown, JSON\n",
    "import itertools\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "ba06990f-6dc5-4805-9e82-0881a524bfef",
   "metadata": {},
   "source": [
    "Set the details for the catalog we want and authenticate to the server if needed."
   ]
  },
  {
   "cell_type": "code",
   "id": "9ee79ab7-a3f7-4c69-9c80-336871c13ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:45:06.052182Z",
     "start_time": "2025-04-09T15:45:05.278152Z"
    }
   },
   "source": [
    "hostname = 'dev.eye-ai.org'\n",
    "domain_schema = 'demo-schema'\n",
    "\n",
    "gnl = GlobusNativeLogin(host=hostname)\n",
    "if gnl.is_logged_in([hostname]):\n",
    "    print(\"You are already logged in.\")\n",
    "else:\n",
    "    gnl.login([hostname], no_local_server=True, no_browser=True, refresh_tokens=True, update_bdbag_keychain=True)\n",
    "    print(\"Login Successful\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are already logged in.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "a23e5177-106b-48b6-b5e0-a126d35f4084",
   "metadata": {},
   "source": "Create a test catalog and get an instance of the DerivaML class.  Use options so that we create some initial datasets and features.  Use the exploration API to find out what features and datasets we have."
  },
  {
   "cell_type": "code",
   "id": "e9bddcf0-27ea-40b3-a388-b77635586fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:46:19.294592Z",
     "start_time": "2025-04-09T15:45:07.869738Z"
    }
   },
   "source": [
    "test_catalog = create_demo_catalog(hostname, domain_schema, create_features=True, create_datasets=True)\n",
    "ml_instance = DemoML(hostname, test_catalog.catalog_id)\n",
    "print(f'Creating catalog at {ml_instance.catalog_id}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 08:45:28,168 - deriva_ml.WARNING - File /Users/carl/Repos/Projects/deriva-ml/docs/Notebooks/DerivaML Execution.ipynb has been modified since last commit. Consider commiting before executing\n",
      "2025-04-09 08:45:42,354 - deriva_ml.WARNING - File /Users/carl/Repos/Projects/deriva-ml/docs/Notebooks/DerivaML Execution.ipynb has been modified since last commit. Consider commiting before executing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating catalog at 1866\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:52:08.605555Z",
     "start_time": "2025-04-09T15:52:07.666074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "display(\n",
    "    Markdown('## Datasets'),\n",
    "    pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns),\n",
    "\n",
    "    Markdown('## Features'),\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Subject\")],\n",
    "    [f'{f.target_table.name}:{f.feature_name}' for f in ml_instance.find_features(\"Image\")]\n",
    ")"
   ],
   "id": "9b151033-6eb5-4fbb-a8dd-8d9b2154299a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Datasets"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "             Description  Deleted Version MLVocab.dataset_type\n",
       "0            Dataset 3MR    False     4MP   [TestSet, Testing]\n",
       "1            Dataset 3MT    False     4MR   [TestSet, Testing]\n",
       "2       Nested Dataset 0    False     4MM  [TestSet, Training]\n",
       "3            Dataset 3MW    False     4MY   [TestSet, Testing]\n",
       "4            Dataset 3MY    False     4MW   [TestSet, Testing]\n",
       "5       Nested Dataset 2    False     4MT  [TestSet, Training]\n",
       "6  Double nested dataset    False     4MJ            [TestSet]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Version</th>\n",
       "      <th>MLVocab.dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset 3MR</td>\n",
       "      <td>False</td>\n",
       "      <td>4MP</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset 3MT</td>\n",
       "      <td>False</td>\n",
       "      <td>4MR</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nested Dataset 0</td>\n",
       "      <td>False</td>\n",
       "      <td>4MM</td>\n",
       "      <td>[TestSet, Training]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset 3MW</td>\n",
       "      <td>False</td>\n",
       "      <td>4MY</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset 3MY</td>\n",
       "      <td>False</td>\n",
       "      <td>4MW</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nested Dataset 2</td>\n",
       "      <td>False</td>\n",
       "      <td>4MT</td>\n",
       "      <td>[TestSet, Training]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Double nested dataset</td>\n",
       "      <td>False</td>\n",
       "      <td>4MJ</td>\n",
       "      <td>[TestSet]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Features"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Subject:Health']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Image:BoundingBox', 'Image:Quality']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:52:12.932331Z",
     "start_time": "2025-04-09T15:52:11.216288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = pd.DataFrame(ml_instance.find_datasets()).drop(columns=DerivaSystemColumns)\n",
    "training_dataset_rid = [ds['RID'] for ds in ml_instance.find_datasets() if 'Training' in ds['Dataset_Type']][0]\n",
    "testing_dataset_rid = [ds['RID'] for ds in ml_instance.find_datasets() if 'Testing' in ds['Dataset_Type']][0]\n",
    "\n",
    "display(\n",
    "    Markdown(f'Training Dataset: {training_dataset_rid}'),\n",
    "    Markdown('## Datasets'),\n",
    "    datasets)"
   ],
   "id": "29a0bd7230799257",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Training Dataset: 4K4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Datasets"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "             Description  Deleted Version MLVocab.dataset_type\n",
       "0            Dataset 3MR    False     4MP   [TestSet, Testing]\n",
       "1            Dataset 3MT    False     4MR   [TestSet, Testing]\n",
       "2       Nested Dataset 0    False     4MM  [TestSet, Training]\n",
       "3            Dataset 3MW    False     4MY   [TestSet, Testing]\n",
       "4            Dataset 3MY    False     4MW   [TestSet, Testing]\n",
       "5       Nested Dataset 2    False     4MT  [TestSet, Training]\n",
       "6  Double nested dataset    False     4MJ            [TestSet]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Deleted</th>\n",
       "      <th>Version</th>\n",
       "      <th>MLVocab.dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset 3MR</td>\n",
       "      <td>False</td>\n",
       "      <td>4MP</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset 3MT</td>\n",
       "      <td>False</td>\n",
       "      <td>4MR</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nested Dataset 0</td>\n",
       "      <td>False</td>\n",
       "      <td>4MM</td>\n",
       "      <td>[TestSet, Training]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset 3MW</td>\n",
       "      <td>False</td>\n",
       "      <td>4MY</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset 3MY</td>\n",
       "      <td>False</td>\n",
       "      <td>4MW</td>\n",
       "      <td>[TestSet, Testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nested Dataset 2</td>\n",
       "      <td>False</td>\n",
       "      <td>4MT</td>\n",
       "      <td>[TestSet, Training]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Double nested dataset</td>\n",
       "      <td>False</td>\n",
       "      <td>4MJ</td>\n",
       "      <td>[TestSet]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initializing the environment for an execution\n",
    "\n",
    "In DerivaML, the catalog is the source of record for all of the data created and used by a machine learning experiment.  While we can use the Deriva API to interact directly with the catalog, DerivaML provides a much simpler way of retrieving and adding data to a catalog.\n",
    "\n",
    "The core concept in this process is an execution.  An execution can be the process of training a model, of executing a model, for running analysis scripts, or even a manual operation.  Every execution in DerivaML is uniquely identified by a *resource identifier* (RID).\n",
    "\n",
    "The steps involved in creating and using an execution are:\n",
    "1. Create an Execution configuration object that identifies the inputs, and code for the execution.\n",
    "2. Create a workflow object to represent the code/operation that you will perform\n",
    "3. Create an execution instance, which will download all of the required inputs from the catalog\n",
    "Locate the input files using methods in the execution instance\n",
    "4. Perform your computation, placing output files in locations provided by the execution instance methods\n",
    "5. Upload the results of the computation using the execution instance methods. This will upload all of your files and tag them with the execution RID so you know how they were generated.  In addition, and new tabular data in CSV format will be uploaded to corrisponding tables in the catalog.\n",
    "\n",
    "\n",
    "### Creating an `ExectutionConfiguration`\n",
    "An execution can be described by the datasets and files that it needs, the code that it runs, and the resulting files that it creates.\n",
    "This information is captured in an ExecutionConfiguration object:\n",
    "\n",
    "\n",
    "    class ExecutionConfiguration:\n",
    "     \"\"\"\n",
    "        Define the parameters that are used to configure a specific execution.\n",
    "\n",
    "        Arguments:\n",
    "            datasets: List of dataset RIDS, MINIDS for datasets to be downloaded prior to execution.  By default,\n",
    "                     all  the datasets are materialized. However, if the assets associated with a dataset are not\n",
    "                     needed, a dictionary that defines the rid and the materialization parameter for the\n",
    "                     download_dataset_bag method can be specified, e.g.  datasets=[{'rid': RID, 'materialize': True}].\n",
    "            assets: List of assets to be downloaded prior to execution.  The values must be RIDs in an asset table\n",
    "            workflow: A workflow instance.  Must have a name, URI to the workflow instance, and a type.\n",
    "            description: A description of the execution.  Can use markdown format.\n",
    "\n",
    "## Creating a `Workflow`\n",
    "\n",
    "The actual code that is being run is represented by a `Workflow` class.  A workflow class is intended to be quite general and could be a Python script, a Jupyter notebook, a manual process, or even a Airflow or some other type of workflow system.  In order to create a workflow class instance, we will need to have a name for the workflow, a URI to name the resource that the workflow is capturing, and a workflow type.\n",
    "\n",
    "The url for the workflow will depend on what the workflow is actually doing. In general, its a good idea to make the URL a reference to a tagged code or repository in GitHub. This will require some disiplane on your process to ensure that you always have workflows that are commited and tagged in a repo.\n",
    "\n",
    "The workflow type is a controlled vocabulary.  You can create new workflow types using the standard APIs for adding terms.\n"
   ],
   "id": "353d51c9-b8a6-4b75-a0da-ffa2db134169"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:52:22.661065Z",
     "start_time": "2025-04-09T15:52:15.770104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"Manual Workflow\", description=\"Initial setup of Model File\")\n",
    "ml_instance.add_term(MLVocab.asset_type, \"API_Model\", description=\"Model for our API workflow\")\n",
    "\n",
    "api_workflow = ml_instance.create_workflow(\n",
    "    name=\"Manual Workflow\",\n",
    "    workflow_type=\"Manual Workflow\",\n",
    "    description=\"A manual operation\"\n",
    ")\n",
    "\n",
    "manual_execution = ml_instance.create_execution(ExecutionConfiguration( description=\"Sample Execution\", workflow=api_workflow))\n",
    "\n",
    "# Now lets create model configuration for our program.\n",
    "model_file = manual_execution.asset_file_path(\"Execution_Asset\",'modelfile.txt', asset_types=\"API_Model\")\n",
    "with builtins.open(model_file, \"w\") as fp:\n",
    "    fp.write(f\"My model\")\n",
    "\n",
    "# Now upload the file and retrieve the RID of the new asset from the returned results.\n",
    "uploaded_assets = manual_execution.upload_execution_outputs()\n",
    "training_model_rid = [a.asset_rid  for a  in uploaded_assets['deriva-ml/Execution_Asset'] if 'API_Model' in a.asset_types][0]\n",
    "\n",
    "display(\n",
    "    Markdown(f'## Training Model: {training_model_rid}'),\n",
    "    JSON(ml_instance.retrieve_rid(training_model_rid))\n",
    ")"
   ],
   "id": "1d726b44-c60f-435a-9966-cfe3fc3da2e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 08:52:16,855 - deriva_ml.WARNING - File /Users/carl/Repos/Projects/deriva-ml/docs/Notebooks/DerivaML Execution.ipynb has been modified since last commit. Consider commiting before executing\n",
      "2025-04-09 08:52:17,549 - deriva_ml.INFO - Downloading assets ...\n",
      "2025-04-09 08:52:19,020 - deriva_ml.INFO - Initialize status finished.\n",
      "2025-04-09 08:52:19,334 - deriva_ml.INFO - Uploading execution files...\n",
      "2025-04-09 08:52:19,473 - deriva.transfer.upload.deriva_upload.INFO - Initializing uploader: GenericUploader v1.7.7 [Python 3.10.16, macOS-15.4-x86_64-i386-64bit]\n",
      "2025-04-09 08:52:19,643 - deriva.transfer.upload.deriva_upload.INFO - Scanning files in directory [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset]...\n",
      "2025-04-09 08:52:19,644 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Asset/modelfile.txt].\n",
      "2025-04-09 08:52:19,645 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250409_085218.txt].\n",
      "2025-04-09 08:52:19,645 - deriva.transfer.upload.deriva_upload.INFO - Including file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/configuration.json].\n",
      "2025-04-09 08:52:19,646 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Asset/modelfile.txt]\n",
      "2025-04-09 08:52:19,646 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Asset/modelfile.txt].\n",
      "2025-04-09 08:52:19,647 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Asset/modelfile.txt]. Please wait...\n",
      "2025-04-09 08:52:19,648 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Asset/modelfile.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-09 08:52:20,454 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250409_085218.txt]\n",
      "2025-04-09 08:52:20,456 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250409_085218.txt].\n",
      "2025-04-09 08:52:20,456 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250409_085218.txt]. Please wait...\n",
      "2025-04-09 08:52:20,458 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/environment_snapshot_20250409_085218.txt] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-09 08:52:20,992 - deriva.transfer.upload.deriva_upload.INFO - Processing: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/configuration.json]\n",
      "2025-04-09 08:52:20,995 - deriva.transfer.upload.deriva_upload.INFO - Computed metadata for: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/configuration.json].\n",
      "2025-04-09 08:52:20,996 - deriva.transfer.upload.deriva_upload.INFO - Computing checksums for file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/configuration.json]. Please wait...\n",
      "2025-04-09 08:52:20,998 - deriva.transfer.upload.deriva_upload.INFO - Uploading file: [/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4N4/asset/deriva-ml/Execution_Metadata/configuration.json] to host https://dev.eye-ai.org. Please wait...\n",
      "2025-04-09 08:52:21,373 - deriva.transfer.upload.deriva_upload.INFO - File upload processing completed: 3 files were uploaded successfully, 0 files failed to upload due to errors, 0 files were skipped because they did not satisfy the matching criteria of the configuration.\n",
      "2025-04-09 08:52:21,979 - deriva_ml.INFO - Updating features...\n",
      "2025-04-09 08:52:22,139 - deriva_ml.INFO - Upload assets complete\n",
      "2025-04-09 08:52:22,278 - deriva_ml.INFO - Successfully end the execution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "## Training Model: 4N6"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ],
      "application/json": {
       "RID": "4N6",
       "RCT": "2025-04-09T15:52:20.381197+00:00",
       "RMT": "2025-04-09T15:52:20.381197+00:00",
       "RCB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
       "RMB": "https://auth.globus.org/aef862ea-d274-11e5-bb09-7bf5b06f98da",
       "URL": "/hatrac/Execution_Asset/c604e0f3dd9caa5d5a1a120239642e70.modelfile.txt:qAemOjwhrLMOKaw_Rv62zvUgoyke.0UR",
       "Filename": "modelfile.txt",
       "Description": null,
       "Length": 8,
       "MD5": "c604e0f3dd9caa5d5a1a120239642e70"
      }
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup for a ML run\n",
   "id": "cfce553e81530e79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:53:02.382791Z",
     "start_time": "2025-04-09T15:52:27.578446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ml_instance.add_term(MLVocab.workflow_type, \"ML Demo\", description=\"A ML Workflow that uses Deriva ML API\")\n",
    "\n",
    "config = ExecutionConfiguration(\n",
    "        assets = [training_model_rid],\n",
    "    description=\"Sample Execution\",\n",
    "    workflow=api_workflow,\n",
    "    datasets=[DatasetSpec(rid=training_dataset_rid, version=ml_instance.dataset_version(training_dataset_rid)),\n",
    "            DatasetSpec(rid=testing_dataset_rid, version=ml_instance.dataset_version(training_dataset_rid), materialize=False)],\n",
    ")\n",
    "\n",
    "ml_execution = ml_instance.create_execution(config)"
   ],
   "id": "cdcc8f5c-874b-4bf9-89ef-e1ea90b9f91f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 08:52:29,125 - deriva_ml.INFO - Materialize bag 4K4... \n",
      "2025-04-09 08:52:31,225 - deriva_ml.INFO - Creating new MINID for dataset 4K4\n",
      "2025-04-09 08:52:33,613 - deriva_ml.INFO - Downloading dataset minid for catalog: 4K4@1.2.0\n",
      "2025-04-09 08:52:33,777 - deriva.transfer.download.deriva_export.INFO - Processing export config file: /var/folders/0k/27qzm97x3t7g3j1m6ksf_9f40000gn/T/tmpdigmt76m/download_spec.json\n",
      "2025-04-09 08:52:33,778 - deriva.transfer.download.deriva_export.INFO - Requesting bdbag export at: https://dev.eye-ai.org/deriva/export/bdbag\n",
      "2025-04-09 08:52:41,613 - deriva.transfer.download.deriva_export.INFO - Export successful. Service responded with URL list: ['https://identifiers.fair-research.org/hdl:20.500.12582/x6cHs8W3J1j8', 'https://dev.eye-ai.org/deriva/export/bdbag/1994d30b-6b5e-4078-97f8-2a4c6bdbdf23']\n",
      "2025-04-09 08:52:43,048 - deriva_ml.INFO - Materializing bag: 1 of 4 file(s) downloaded.\n",
      "2025-04-09 08:52:43,327 - deriva_ml.INFO - Materializing bag: 2 of 4 file(s) downloaded.\n",
      "2025-04-09 08:52:43,572 - deriva_ml.INFO - Materializing bag: 3 of 4 file(s) downloaded.\n",
      "2025-04-09 08:52:43,978 - deriva_ml.INFO - Materializing bag: 4 of 4 file(s) downloaded.\n",
      "2025-04-09 08:52:44,170 - deriva_ml.INFO - Validating bag: 1 of 45 file(s) validated.\n",
      "2025-04-09 08:52:44,408 - deriva_ml.INFO - Validating bag: 2 of 45 file(s) validated.\n",
      "2025-04-09 08:52:44,543 - deriva_ml.INFO - Validating bag: 3 of 45 file(s) validated.\n",
      "2025-04-09 08:52:44,685 - deriva_ml.INFO - Validating bag: 4 of 45 file(s) validated.\n",
      "2025-04-09 08:52:44,908 - deriva_ml.INFO - Validating bag: 5 of 45 file(s) validated.\n",
      "2025-04-09 08:52:45,043 - deriva_ml.INFO - Validating bag: 6 of 45 file(s) validated.\n",
      "2025-04-09 08:52:45,175 - deriva_ml.INFO - Validating bag: 7 of 45 file(s) validated.\n",
      "2025-04-09 08:52:45,489 - deriva_ml.INFO - Validating bag: 8 of 45 file(s) validated.\n",
      "2025-04-09 08:52:45,667 - deriva_ml.INFO - Validating bag: 9 of 45 file(s) validated.\n",
      "2025-04-09 08:52:45,810 - deriva_ml.INFO - Validating bag: 10 of 45 file(s) validated.\n",
      "2025-04-09 08:52:45,971 - deriva_ml.INFO - Validating bag: 11 of 45 file(s) validated.\n",
      "2025-04-09 08:52:46,187 - deriva_ml.INFO - Validating bag: 12 of 45 file(s) validated.\n",
      "2025-04-09 08:52:46,429 - deriva_ml.INFO - Validating bag: 13 of 45 file(s) validated.\n",
      "2025-04-09 08:52:46,618 - deriva_ml.INFO - Validating bag: 14 of 45 file(s) validated.\n",
      "2025-04-09 08:52:46,812 - deriva_ml.INFO - Validating bag: 15 of 45 file(s) validated.\n",
      "2025-04-09 08:52:47,007 - deriva_ml.INFO - Validating bag: 16 of 45 file(s) validated.\n",
      "2025-04-09 08:52:47,220 - deriva_ml.INFO - Validating bag: 17 of 45 file(s) validated.\n",
      "2025-04-09 08:52:47,467 - deriva_ml.INFO - Validating bag: 18 of 45 file(s) validated.\n",
      "2025-04-09 08:52:47,653 - deriva_ml.INFO - Validating bag: 19 of 45 file(s) validated.\n",
      "2025-04-09 08:52:47,795 - deriva_ml.INFO - Validating bag: 20 of 45 file(s) validated.\n",
      "2025-04-09 08:52:47,957 - deriva_ml.INFO - Validating bag: 21 of 45 file(s) validated.\n",
      "2025-04-09 08:52:48,111 - deriva_ml.INFO - Validating bag: 22 of 45 file(s) validated.\n",
      "2025-04-09 08:52:48,257 - deriva_ml.INFO - Validating bag: 23 of 45 file(s) validated.\n",
      "2025-04-09 08:52:48,468 - deriva_ml.INFO - Validating bag: 24 of 45 file(s) validated.\n",
      "2025-04-09 08:52:48,625 - deriva_ml.INFO - Validating bag: 25 of 45 file(s) validated.\n",
      "2025-04-09 08:52:48,829 - deriva_ml.INFO - Validating bag: 26 of 45 file(s) validated.\n",
      "2025-04-09 08:52:49,020 - deriva_ml.INFO - Validating bag: 27 of 45 file(s) validated.\n",
      "2025-04-09 08:52:49,173 - deriva_ml.INFO - Validating bag: 28 of 45 file(s) validated.\n",
      "2025-04-09 08:52:49,345 - deriva_ml.INFO - Validating bag: 29 of 45 file(s) validated.\n",
      "2025-04-09 08:52:49,485 - deriva_ml.INFO - Validating bag: 30 of 45 file(s) validated.\n",
      "2025-04-09 08:52:49,663 - deriva_ml.INFO - Validating bag: 31 of 45 file(s) validated.\n",
      "2025-04-09 08:52:49,920 - deriva_ml.INFO - Validating bag: 32 of 45 file(s) validated.\n",
      "2025-04-09 08:52:50,047 - deriva_ml.INFO - Validating bag: 33 of 45 file(s) validated.\n",
      "2025-04-09 08:52:50,172 - deriva_ml.INFO - Validating bag: 34 of 45 file(s) validated.\n",
      "2025-04-09 08:52:50,332 - deriva_ml.INFO - Validating bag: 35 of 45 file(s) validated.\n",
      "2025-04-09 08:52:50,477 - deriva_ml.INFO - Validating bag: 36 of 45 file(s) validated.\n",
      "2025-04-09 08:52:50,608 - deriva_ml.INFO - Validating bag: 37 of 45 file(s) validated.\n",
      "2025-04-09 08:52:50,739 - deriva_ml.INFO - Validating bag: 38 of 45 file(s) validated.\n",
      "2025-04-09 08:52:50,861 - deriva_ml.INFO - Validating bag: 39 of 45 file(s) validated.\n",
      "2025-04-09 08:52:51,080 - deriva_ml.INFO - Validating bag: 40 of 45 file(s) validated.\n",
      "2025-04-09 08:52:51,291 - deriva_ml.INFO - Validating bag: 41 of 45 file(s) validated.\n",
      "2025-04-09 08:52:51,425 - deriva_ml.INFO - Validating bag: 42 of 45 file(s) validated.\n",
      "2025-04-09 08:52:51,572 - deriva_ml.INFO - Validating bag: 43 of 45 file(s) validated.\n",
      "2025-04-09 08:52:51,717 - deriva_ml.INFO - Validating bag: 44 of 45 file(s) validated.\n",
      "2025-04-09 08:52:52,023 - deriva_ml.INFO - Validating bag: 45 of 45 file(s) validated.\n",
      "2025-04-09 08:52:52,025 - deriva_ml.INFO - Loading /Users/carl/deriva-ml/cache/4K4_06860ce9c1a2cf2eb2dea9b6d45620c66abd30df2630338530e65fce171e7aba/Dataset_4K4\n",
      "2025-04-09 08:52:52,082 - deriva_ml.INFO - Creating new database for dataset: 4K4 in /Users/carl/deriva-ml/DemoML_working/4K4@334-PJYR-28DP.db\n",
      "2025-04-09 08:52:52,083 - deriva_ml.INFO - Materialize bag 4HM... \n",
      "2025-04-09 08:52:54,758 - deriva_ml.INFO - Creating new MINID for dataset 4HM\n",
      "2025-04-09 08:52:55,650 - deriva_ml.INFO - Downloading dataset minid for catalog: 4HM@1.2.0\n",
      "2025-04-09 08:52:55,843 - deriva.transfer.download.deriva_export.INFO - Processing export config file: /var/folders/0k/27qzm97x3t7g3j1m6ksf_9f40000gn/T/tmpuaox661k/download_spec.json\n",
      "2025-04-09 08:52:55,845 - deriva.transfer.download.deriva_export.INFO - Requesting bdbag export at: https://dev.eye-ai.org/deriva/export/bdbag\n",
      "2025-04-09 08:52:59,277 - deriva.transfer.download.deriva_export.INFO - Export successful. Service responded with URL list: ['https://identifiers.fair-research.org/hdl:20.500.12582/prjmwNXQFhCZ', 'https://dev.eye-ai.org/deriva/export/bdbag/d9842f2e-86d3-451d-b61d-2234249edfff']\n",
      "2025-04-09 08:53:00,092 - deriva_ml.INFO - Loading /Users/carl/deriva-ml/cache/4HM_3a4f41f32f3a0af2fbadbd4d7cedace9b124b74e300d14f4993110c05ef59219/Dataset_4HM\n",
      "2025-04-09 08:53:00,137 - deriva_ml.INFO - Creating new database for dataset: 4HM in /Users/carl/deriva-ml/DemoML_working/4HM@334-PJY3-F22T.db\n",
      "2025-04-09 08:53:00,278 - deriva_ml.INFO - Downloading assets ...\n",
      "2025-04-09 08:53:02,140 - deriva_ml.INFO - Initialize status finished.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:55:59.092159Z",
     "start_time": "2025-04-09T15:55:59.070400Z"
    }
   },
   "cell_type": "code",
   "source": "ml_execution.asset_paths",
   "id": "b67cc7bbfea212b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Execution_Asset': [AssetFilePath('/Users/carl/deriva-ml/DemoML_working/deriva-ml/execution/4NT/downloaded-assets/Execution_Asset/modelfile.txt')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with ml_execution.execute() as deriva_exec:\n",
    "    # Get the input datasets:\n",
    "    training_dataset = ml_execution.datasets[0]  # Input dataset\n",
    "    image_rids = training_dataset.get_table_as_dataframe('Image')['RID']\n",
    "\n",
    "    # Get input files\n",
    "    with open(ml_execution.asset_paths[0], 'rt') as model_file:\n",
    "        training_model = model_file.read()\n",
    "        print(f'Got model file: {training_model}')\n",
    "\n",
    "    # Put your ML code here....\n",
    "    pass\n",
    "\n",
    "    # Write a new model\n",
    "    model_file = manual_execution.asset_path('API_Model', 'modelfile.txt')\n",
    "    with open(model_file, 'w') as f:\n",
    "        f.write(\"Hello there a new model;\\n\")\n",
    "\n",
    "    # Create some new feature values.\n",
    "    bb_csv_path, bb_asset_paths = ml_execution.asset_path('Image', 'BoundingBox')\n",
    "    bounding_box_files = [bb_asset_paths['BoundingBox'] / f\"box{i}.txt\" for i in range(10)]\n",
    "    for i in range(10):\n",
    "        bounding_box_files.append(fn := bb_asset_paths['BoundingBox'] / f\"box{i}.txt\")\n",
    "        with builtins.open(fn, \"w\") as fp:\n",
    "            fp.write(f\"Hi there {i}\")\n",
    "\n",
    "    ImageBoundingboxFeature = ml_instance.feature_record_class(\"Image\", \"BoundingBox\")\n",
    "    image_bounding_box_feature_list = [ImageBoundingboxFeature(Image=image_rid,\n",
    "                                                               Execution=ml_execution.execution_rid,\n",
    "                                                               BoundingBox=asset_rid)\n",
    "                                       for image_rid, asset_rid in zip(image_rids, itertools.cycle(bounding_box_files))]\n",
    "\n",
    "    ml_execution.write_feature_file(image_bounding_box_feature_list)\n",
    "\n",
    "upload_status = ml_execution.upload_execution_outputs()"
   ],
   "id": "c8860e47d5f72069"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now lets check the assets produced by this execution to make sure that they are what we expect.",
   "id": "4fb891bc938549c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get datapath to the ML schema.\n",
    "schema_path = ml_instance.pathBuilder.schemas[ml_instance.ml_schema]\n",
    "\n",
    "# Now get path to the execution table, and get our execution record.  We filter on the RID for the\n",
    "# execution we are looking for.\n",
    "executions = schema_path.Execution.filter(schema_path.Execution.RID == ml_execution.execution_rid)\n",
    "execution_info = list(executions.entities().fetch())[0]\n",
    "\n",
    "# To get the assets for the execution, we need to go through the linking table to the assets.\n",
    "asset_path = executions.link(schema_path.Execution_Asset_Execution).link(schema_path.Execution_Asset)\n",
    "pd.DataFrame(asset_path.entities().fetch()).drop(columns=DerivaSystemColumns + ['MD5'])\n",
    "\n",
    "# Now lets display our results.\n",
    "display(\n",
    "    Markdown(f'### Execution: {ml_execution.execution_rid}'),\n",
    "    JSON(execution_info),\n",
    "    Markdown(f'### Execution Assets'),\n",
    "    pd.DataFrame(asset_path.entities().fetch()).drop(columns=DerivaSystemColumns + ['MD5']),\n",
    ")"
   ],
   "id": "d5fea96ac8e0567f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cd670182dfb20afd",
   "metadata": {},
   "source": "test_catalog.delete_ermrest_catalog(really=True)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deriva-test",
   "language": "python",
   "name": "deriva-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
