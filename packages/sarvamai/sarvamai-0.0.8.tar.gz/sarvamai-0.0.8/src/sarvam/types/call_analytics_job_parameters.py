# This file was auto-generated by Fern from our API Definition.

from ..core.pydantic_utilities import UniversalBaseModel
import typing
from .question import Question
import pydantic
from .speech_to_text_translate_model import SpeechToTextTranslateModel
from ..core.pydantic_utilities import IS_PYDANTIC_V2


class CallAnalyticsJobParameters(UniversalBaseModel):
    questions: typing.List[Question] = pydantic.Field()
    """
    List of questions to be answered based on the call content. Each question should be a valid JSON object with the following structure:
    ```[{id: "q001", text: "What was the main issue discussed in the call?", description: "Identify the primary concern or topic of the conversation", type: "enum", properties: {"options": ["NEW_CONNECTION", "INTERNET_ISSUES", "REFUND"]}}].```The `type` field must be one of: `boolean`, `enum`, `short answer`, `long answer`, or `number`. For `enum` type questions, include an 'options' list in the properties.
    """

    model: typing.Optional[SpeechToTextTranslateModel] = pydantic.Field(default=None)
    """
    Model to be used for converting speech to text in target language
    """

    with_diarization: typing.Optional[bool] = pydantic.Field(default=None)
    """
    Enables speaker diarization, which identifies and separates different speakers in the audio.
     When set to true, the API will provide speaker-specific segments in the response.
     Note: This parameter is currently in Beta mode.
    """

    num_speakers: typing.Optional[int] = pydantic.Field(default=None)
    """
    Number of speakers to be detected in the audio.
    """

    if IS_PYDANTIC_V2:
        model_config: typing.ClassVar[pydantic.ConfigDict] = pydantic.ConfigDict(extra="allow", frozen=True)  # type: ignore # Pydantic v2
    else:

        class Config:
            frozen = True
            smart_union = True
            extra = pydantic.Extra.allow
