# This file was auto-generated by Fern from our API Definition.

import typing_extensions
import typing
from .question import QuestionParams
import typing_extensions
from ..types.speech_to_text_translate_model import SpeechToTextTranslateModel


class CallAnalyticsJobParametersParams(typing_extensions.TypedDict):
    questions: typing.Sequence[QuestionParams]
    """
    List of questions to be answered based on the call content. Each question should be a valid JSON object with the following structure:
    ```[{id: "q001", text: "What was the main issue discussed in the call?", description: "Identify the primary concern or topic of the conversation", type: "enum", properties: {"options": ["NEW_CONNECTION", "INTERNET_ISSUES", "REFUND"]}}].```The `type` field must be one of: `boolean`, `enum`, `short answer`, `long answer`, or `number`. For `enum` type questions, include an 'options' list in the properties.
    """

    model: typing_extensions.NotRequired[SpeechToTextTranslateModel]
    """
    Model to be used for converting speech to text in target language
    """

    with_diarization: typing_extensions.NotRequired[bool]
    """
    Enables speaker diarization, which identifies and separates different speakers in the audio.
     When set to true, the API will provide speaker-specific segments in the response.
     Note: This parameter is currently in Beta mode.
    """

    num_speakers: typing_extensions.NotRequired[int]
    """
    Number of speakers to be detected in the audio.
    """
