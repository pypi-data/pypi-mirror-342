Metadata-Version: 2.1
Name: onnx-asr
Version: 0.1.0
Summary: Automatic Speech Recognition in Python using ONNX models
Keywords: asr,speech recognition,onnx
Author-Email: Ilya Stupakov <istupakov@gmail.com>
License: MIT
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: License :: OSI Approved :: MIT License
Project-URL: Documentation, https://github.com/istupakov/onnx-asr#readme
Project-URL: Issues, https://github.com/istupakov/onnx-asr/issues
Project-URL: Source, https://github.com/istupakov/onnx-asr
Requires-Python: >=3.10
Requires-Dist: numpy
Provides-Extra: cpu
Requires-Dist: onnxruntime>=1.18.1; extra == "cpu"
Provides-Extra: gpu
Requires-Dist: onnxruntime-gpu>=1.18.1; extra == "gpu"
Provides-Extra: hub
Requires-Dist: huggingface_hub; extra == "hub"
Description-Content-Type: text/markdown

# Automatic Speech Recognition in Python using ONNX models

The simple speech recognition package with minimal dependencies:
* NumPy ([numpy](https://numpy.org/))
* ONNX Runtime ([onnxruntime](https://onnxruntime.ai/))
* (*optional*)  Hugging Face Hub ([huggingface_hub](https://huggingface.co/))

## Supported models
* Nvidia NeMo Conformer/FastConformer (with CTC and RNN-T decoders)
* Kaldi Icefall Zipformer (with stateless RNN-T decoder) including Alpha Cephei Vosk 0.52+
* Sber GigaAM v2 (with CTC and RNN-T decoders)


## Installation

The package can be installed from [PyPI](https://pypi.org/project/onnx-asr/):

1. With CPU `onnxruntime` and `huggingface_hub`
```shell
pip install onnx-asr[cpu,hub]
```
2. With CPU `onnxruntime`
```shell
pip install onnx-asr[cpu]
```
3. With GPU `onnxruntime`
```shell
pip install onnx-asr[gpu]
```
4. Without `onnxruntime` (if you already have some `onnxruntime` version installed)
```shell
pip install onnx-asr
```

## Usage examples

### Load ONNX model from Hugging Face

Load ONNX model from Hugging Face and recognize wav file:
```py
import onnx_asr
model = onnx_asr.load_model("nemo-fastconformer-ru-ctc")
print(model.recognize("test.wav"))
```

#### Supported model names:
* `gigaam-v2-ctc` for Sber GigaAM v2 CTC ([origin](https://github.com/salute-developers/GigaAM), [onnx](https://huggingface.co/istupakov/gigaam-v2-onnx))
* `gigaam-v2-rnnt` for Sber GigaAM v2 RNN-T ([origin](https://github.com/salute-developers/GigaAM), [onnx](https://huggingface.co/istupakov/gigaam-v2-onnx))
* `nemo-fastconformer-ru-ctc` for Nvidia FastConformer-Hybrid Large (ru) with CTC decoder ([origin](https://huggingface.co/nvidia/stt_ru_fastconformer_hybrid_large_pc), [onnx](https://huggingface.co/istupakov/stt_ru_fastconformer_hybrid_large_pc_onnx))
* `nemo-fastconformer-ru-rnnt` for Nvidia FastConformer-Hybrid Large (ru) with RNN-T decoder ([origin](https://huggingface.co/nvidia/stt_ru_fastconformer_hybrid_large_pc), [onnx](https://huggingface.co/istupakov/stt_ru_fastconformer_hybrid_large_pc_onnx))
* `vosk-model-ru` for Alpha Cephei Vosk 0.54-ru ([origin](https://huggingface.co/alphacep/vosk-model-ru))
* `vosk-model-small-ru` for Alpha Cephei Vosk 0.52-small-ru ([origin](https://huggingface.co/alphacep/vosk-model-small-ru))

Supported wav file formats: PCM_U8, PCM_16, PCM_24 and PCM_32 formats with 16 kHz sample rate. For other formats, you either need to convert them first, or use a library that can read them into a numpy array. 

Example with `soundfile`:
```py
import onnx_asr
import soundfile as sf

model = onnx_asr.load_model("gigaam-v2-ctc")

waveform, sample_rate = sf.read("test.wav", dtype="float32")
model.recognize(waveform)
```

Batch processing is also supported:
```py
import onnx_asr
model = onnx_asr.load_model("nemo-fastconformer-ru-ctc")
print(model.recognize(["test1.wav", "test2.wav", "test3.wav", "test4.wav"]))
```

### CLI

Package has simple CLI interface
```shell
onnx-asr nemo-fastconformer-ru-ctc test.wav
```

For full usage parameters, see help:
```shell
onnx-asr -h
```

### Load ONNX model from local directory

Load ONNX model from local directory and recognize wav file:
```py
import onnx_asr
model = onnx_asr.load_model("gigaam-v2-ctc", "models/gigaam-onnx")
print(model.recognize("test.wav"))
```
Supported model types:
* All models from [supported model names](#supported-model-names)
* `nemo-conformer-ctc` for NeMo Conformer with CTC decoder
* `nemo-conformer-rnnt` for NeMo Conformer with RNN-T decoder
* `kaldi-rnnt` or `vosk` for Kaldi Icefall Zipformer with stateless RNN-T decoder


## Convert model to ONNX

### Nvidia NeMo Conformer/FastConformer
Install **NeMo Toolkit**
```shell
pip install nemo_toolkit['asr']
```

Download model and export to ONNX format
```py
import nemo.collections.asr as nemo_asr
from pathlib import Path

model_name = "stt_ru_fastconformer_hybrid_large_pc"
onnx_dir = Path("nemo-onnx")
onnx_dir.mkdir(exist_ok=True)

model = nemo_asr.models.ASRModel.from_pretrained("nvidia/" + model_name)

# For export Hybrid models with CTC decoder
# model.set_export_config({"decoder_type": "ctc"})

model.export(Path(onnx_dir, model_name).with_suffix(".onnx"))

with Path(onnx_dir, f"vocab-{model_name}.txt").open("wt") as f:
    for i, token in enumerate([*model.tokenizer.vocab, "<blk>"]):
        f.write(f"{token} {i}\n")
```

### Sber GigaAM v2
Install **GigaAM**
```shell
git clone https://github.com/salute-developers/GigaAM.git
pip install ./GigaAM --extra-index-url https://download.pytorch.org/whl/cpu
```

Download model and export to ONNX format
```py
import gigaam
from pathlib import Path

onnx_dir = "gigaam-onnx"
model_type = "rnnt"  # or "ctc"

model = gigaam.load_model(
    model_type,
    fp16_encoder=False,  # only fp32 tensors
    use_flash=False,  # disable flash attention
)
model.to_onnx(dir_path=onnx_dir)

with Path(onnx_dir, "v2_vocab.txt").open("wt") as f:
    for i, token in enumerate(["\u2581", *(chr(ord("Ð°") + i) for i in range(32)), "<blk>"]):
        f.write(f"{token} {i}\n")
```