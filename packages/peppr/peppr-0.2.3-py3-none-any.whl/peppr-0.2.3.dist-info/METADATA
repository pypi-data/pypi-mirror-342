Metadata-Version: 2.4
Name: peppr
Version: 0.2.3
Summary: It's a package for evaluation of predicted poses, right?
Project-URL: repository, https://github.com/aivant/peppr
Author: The pepp'r contributors
License: Copyright (c) 2025, The "pepp'r" contributors
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
        EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
        MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
        IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
        DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
        OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE
        OR OTHER DEALINGS IN THE SOFTWARE.
License-File: LICENSE.txt
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: BSD License
Classifier: Natural Language :: English
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: POSIX :: Linux
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Bio-Informatics
Requires-Python: >=3.11
Requires-Dist: biotite>=1.2
Requires-Dist: click>=8.0.0
Requires-Dist: numpy>=1.25
Requires-Dist: pandas>=2.0.0
Requires-Dist: rdkit>=2024.09.1
Provides-Extra: docs
Requires-Dist: ipython<8.29; extra == 'docs'
Requires-Dist: jupyter-sphinx>=0.5.3; extra == 'docs'
Requires-Dist: matplotlib>=3.3; extra == 'docs'
Requires-Dist: numpydoc>=1.8.0; extra == 'docs'
Requires-Dist: pydata-sphinx-theme==0.16.1; extra == 'docs'
Requires-Dist: sphinx-copybutton>=0.5; extra == 'docs'
Requires-Dist: sphinx-design>=0.5; extra == 'docs'
Requires-Dist: sphinx-notfound-page>=1.0; extra == 'docs'
Requires-Dist: sphinx>=7.0; extra == 'docs'
Provides-Extra: lint
Requires-Dist: mypy==1.15.0; extra == 'lint'
Requires-Dist: numpydoc==1.8.0; extra == 'lint'
Requires-Dist: ruff==0.11.0; extra == 'lint'
Provides-Extra: tests
Requires-Dist: dockq; extra == 'tests'
Requires-Dist: pytest; extra == 'tests'
Description-Content-Type: text/x-rst

pepp'r
======

    I have a structure prediction model and now I want to know how well it performs in
    reproducing the reference structures.
    But there are so many possible metrics, some for monomers, some for complexes!
    Is there a package that handles this for me?

|

Try

.. image:: https://raw.githubusercontent.com/aivant/peppr/refs/heads/main/docs/static/assets/general/logo.svg
   :alt: pepp'r

|

    It's a Package for Evaluation of Predicted Poses, Right?

|

Yes, indeed!
It allows you to compute a variety of metrics on your structure predictions
for assessing their quality.
It supports

- all *CASP*/*CAPRI* metrics and more
- small molecules to huge protein complexes
- easy extension with custom metrics
- a command line interface and a Python API

Installation
------------

``peppr`` is available via *PyPI*:

.. code-block:: console

    $ pip install peppr

Usage example
-------------

Using the CLI, you can either compute a single metric for a system...

.. code-block:: console

    $ peppr run dockq reference.cif poses.cif

... or run an entire prediction model evaluation on many systems.

.. code-block:: console

    # Select the metrics you want to compute (here: RMSD and lDDT)
    $ peppr create peppr.pkl monomer-rmsd monomer-lddt

    # Run the evaluation on predicted poses and their corresponding references
    $ peppr evaluate-batch peppr.pkl "systems/*/reference.cif" "systems/*/poses"

    # Select the aggregation method over poses (here: Top-3 and Oracle) and report the results
    $ peppr tabulate peppr.pkl table.csv top3 oracle

Available metrics
-----------------

- RMSD
- TM-score
- lDDT
- lDDT-PLI
- fnat
- iRMSD
- LRMSD
- DockQ

... and more!