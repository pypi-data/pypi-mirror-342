"""
This module contains four napari widgets declared in
different ways:

- a pure Python function flagged with `autogenerate: true`
    in the plugin manifest. Type annotations are used by
    magicgui to generate widgets for each parameter. Best
    suited for simple processing tasks - usually taking
    in and/or returning a layer.
- a `magic_factory` decorated function. The `magic_factory`
    decorator allows us to customize aspects of the resulting
    GUI, including the widgets associated with each parameter.
    Best used when you have a very simple processing task,
    but want some control over the autogenerated widgets. If you
    find yourself needing to define lots of nested functions to achieve
    your functionality, maybe look at the `Container` widget!
- a `magicgui.widgets.Container` subclass. This provides lots
    of flexibility and customization options while still supporting
    `magicgui` widgets and convenience methods for creating widgets
    from type annotations. If you want to customize your widgets and
    connect callbacks, this is the best widget option for you.
- a `QWidget` subclass. This provides maximal flexibility but requires
    full specification of widget layouts, callbacks, events, etc.

References:
- Widget specification: https://napari.org/stable/plugins/building_a_plugin/guides.html#widgets
- magicgui docs: https://pyapp-kit.github.io/magicgui/

Replace code below according to your needs.
"""

from typing import TYPE_CHECKING

from magicgui import magic_factory
from magicgui.widgets import CheckBox, Container, create_widget
from qtpy.QtWidgets import QHBoxLayout, QPushButton, QWidget
from skimage.util import img_as_float

if TYPE_CHECKING:
    import napari

from utils import get_base_dir
from magicgui import magic_factory
from napari.types import ImageData, LabelsData
import os
import cv2
import supervision as sv
from skimage.io import imread
from PIL import Image
from skimage.measure import label
from tqdm import tqdm
import numpy as np
from utils import get_base_dir
from utils import SAM2_Model, MOLMO_Model, run_molmo_inference, extract_point_coordinates_from_molmo_response
TEXT = "detect tree foliage in center and give me all points coordinates"

def five_points(xy):
    leftmost = xy[np.argmin(xy[:, 0])] # Point le plus à gauche (max en y)
    rightmost = xy[np.argmax(xy[:, 0])] # Point le plus à droite (max en x)
    bottommost = xy[np.argmin(xy[:, 1])] # Point le plus bas (min en y)
    topmost = xy[np.argmax(xy[:, 1])] # Point le plus haut (max en y)
    extremes = np.array([leftmost, rightmost, bottommost, topmost])
    return extremes


@magic_factory(call_button="Run")
def individual_tree(rgb_data: ImageData) -> LabelsData:

    image_pil = Image.fromarray(rgb_data)
    molmo_model, molmo_processor = MOLMO_Model()
    sam2_model = SAM2_Model(sam2_model)
    #Molmo
    molmo_response = run_molmo_inference(
        model=molmo_model,
        processor=molmo_processor,
        image=image_pil,
        text=TEXT
    )
    xy = extract_point_coordinates_from_molmo_response(molmo_response)
    if len(xy)==0:
      print('No tree detected')
    else:
      xy = xy * np.array(image_pil.size) / 100
      key_points = sv.KeyPoints(xy=xy[np.newaxis, ...])
      sv.VertexAnnotator(color=sv.Color.RED, radius=10).annotate(image_pil.copy(), key_points)

    #SAM2
    sam2_model.set_image(cv2.cvtColor(rgb_data, cv2.COLOR_BGR2RGB))
    detections_list = []
    point_coords_set = five_points(xy)
    point_labels_set = np.array([1]*len(point_coords_set))
    masks, scores, logits = sam2_model.predict(
            point_coords=point_coords_set,
            point_labels=point_labels_set,
            multimask_output=False,
        )
    detections = sv.Detections(
            xyxy=sv.mask_to_xyxy(masks=masks),
            mask=masks.astype(bool)
        )
    detections_list.append(detections)

    detections = sv.Detections.merge(detections_list=detections_list)

    if detections.mask is None:
      instance_mask = np.zeros((rgb_data.shape[0],rgb_data.shape[1]),dtype='uint8')
    else:
      mask_tensor = detections.mask.astype('uint8')
      n,height,width = mask_tensor.shape
      instance_mask = np.zeros((height,width),dtype='uint8')
      for i in range(n):
        instance_mask[:,:] = np.where(mask_tensor[i,:,:]!=0,i+1,instance_mask[:,:])
    return instance_mask
