# PEC-DSS ğŸµğŸ”Š

[![License: GPL v3](https://img.shields.io/badge/License-GPL%20v3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

[English](README.md) | [í•œêµ­ì–´](i18n/README_ko.md) | [ä¸­æ–‡](i18n/README_zh.md) | [æ—¥æœ¬èª](i18n/README_jp.md)

**Paralinguistic Event Classification from Diarized Speaker Segments**

PEC-DSS is an advanced audio analysis system that identifies paralinguistic vocal events (like laughter, sighs, etc.) and attributes them to specific speakers through sophisticated speaker diarization and neural audio processing.

## âœ¨ Features

* ğŸ™ï¸ Advanced speaker identification using neural audio encoders
* ğŸ˜€ Attribution of paralinguistic events to specific speakers
* ğŸ” High-accuracy SNAC (Scalable Neural Audio Codec) model integration
* ğŸ”Š Voice embedding and similarity-based speaker matching
* ğŸ“Š Comprehensive audio codebook analysis
* ğŸ”„ Modular architecture for easy customization

## ğŸš€ Installation

### From PyPI

```bash
pip install pec-dss
```

### From Source with pip

```bash
git clone https://github.com/hwk06023/PEC-DSS.git
cd PEC-DSS
pip install -e .
```

### From Source with requirements.txt

```bash
git clone https://github.com/hwk06023/PEC-DSS.git
cd PEC-DSS
pip install -r requirements.txt
```

For development:

```bash
pip install -r requirements-dev.txt
```

## ğŸ“– Quick Start

### Basic Usage

```python
from snac_model import load_snac_model
from audio_encoder import get_codebook_vectors
from speaker_identification import assign_speakers_to_laughs
import librosa

# Load SNAC model
snac_model = load_snac_model(device="cpu")  # or "cuda" for GPU

# Prepare speaker reference samples
speaker_samples = {
    "speaker1": [audio1, audio2],  # Audio waveforms as numpy arrays
    "speaker2": [audio3, audio4]
}

# Process unidentified audio events
unidentified_events = [event1, event2]  # Audio waveforms as numpy arrays

# Identify speakers for each audio event
results = assign_speakers_to_laughs(speaker_samples, unidentified_events, snac_model)

# Print results
for speaker, events in results.items():
    print(f"Speaker {speaker} has {len(events)} attributed events")
```

### CLI Usage

```bash
pec-dss --speakers-dir ./speakers --unidentified-dir ./events --output-dir ./results
```

## ğŸ“ Directory Structure

PEC-DSS expects a specific directory structure for processing audio files:

### Speaker Reference Structure

```
speakers_directory/
   â”œâ”€â”€ speaker_A/       # Each speaker's name becomes their ID
   â”‚   â”œâ”€â”€ audio1.wav   # Reference voice samples for this speaker
   â”‚   â”œâ”€â”€ audio2.wav
   â”‚   â””â”€â”€ ...
   â”œâ”€â”€ speaker_B/
   â”‚   â”œâ”€â”€ audio1.wav
   â”‚   â””â”€â”€ ...
   â””â”€â”€ speaker_C/
       â”œâ”€â”€ audio1.wav
       â””â”€â”€ ...
```

### Unidentified Audio Structure

```
unidentified_directory/
   â”œâ”€â”€ laugh1.wav      # Non-linguistic vocal events to be classified
   â”œâ”€â”€ giggle1.wav
   â””â”€â”€ ...
```

### Output Structure (After Processing)

```
output_directory/
   â”œâ”€â”€ results.json           # JSON file with all results
   â”œâ”€â”€ speaker_A/             # Files assigned to each speaker
   â”‚   â”œâ”€â”€ 0_laugh1.wav
   â”‚   â””â”€â”€ ...
   â”œâ”€â”€ speaker_B/
   â”‚   â”œâ”€â”€ 0_giggle1.wav
   â”‚   â””â”€â”€ ...
   â””â”€â”€ unknown/               # Files below similarity threshold (if any)
       â””â”€â”€ ...
```

## ğŸ§© System Architecture

PEC-DSS consists of the following components:

* **snac_model.py**: SNAC model initialization and management
* **audio_encoder.py**: Audio encoding and vectorization
* **codebook_analysis.py**: Statistical analysis of audio codebooks
* **speaker_identification.py**: Speaker identification algorithms
* **main.py**: Integration and execution framework

## ğŸ”Š Audio Event Types

The system can identify various paralinguistic events including:

* Laughter
* Sighs
* Crying
* Coughing
* Other non-verbal vocal expressions

**Note:** PEC-DSS does not automatically classify these event types. It only determines which speaker produced the audio event.

## ğŸš€ Future Developments

* ğŸ§  Integration with more audio encoder models
* ğŸ˜¢ Expanded paralinguistic event recognition
* ğŸµ Emotional tone classification
* âš¡ Performance optimization for real-time processing

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the GNU General Public License v3.0.

## ğŸ™ Acknowledgements

* [SNAC](https://github.com/hubertsiuzdak/snac) - Scalable Neural Audio Codec
* [HuggingFace Transformers](https://huggingface.co/docs/transformers/index) - Machine learning tools
* [Llama](https://ai.meta.com/llama/) - Language models for text processing