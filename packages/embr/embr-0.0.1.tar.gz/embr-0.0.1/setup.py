# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['embr', 'embr.__tests__', 'embr.cache_utils', 'embr.cache_utils.__tests__']

package_data = \
{'': ['*']}

setup_kwargs = {
    'name': 'embr',
    'version': '0.0.1',
    'description': 'Natural Language Differential Programming',
    'long_description': '# 🔥 Embr DSL: A Shell-Inspired Chat Abstraction for Language Programs\n\n## 🧠 Overview\n\nEmbr is a domain-specific language (DSL) designed for interactive, composable natural language pipelines, inspired by the syntax and\nphilosophy of Unix shell scripting. 🐚\n\nIt treats a conversational state (chat log) as a mutable object that can be transformed, extended, and queried using intuitive operators\nlike `<<`, `>>`, `|`, and `|=`.\n\n## ✨ Core Design Principles\n\n- 🧱 **Declarative + Composable**: Like piping commands in a shell.\n- 🧑\u200d🎤 **Role-aware**: Messages are typed with `@` (e.g., `user @ "text"`).\n- 🛠️ **Reducers as Functions**: Language models and tools act like reducers.\n- 🔁 **Stateful by Default**: All operators mutate a shared conversation state (`Embr`).\n\n---\n\n## 🧮 Operator Table\n\n| 🔣 Operator | 📝 Description                        | 💡 Example Usage                |\n|-------------|---------------------------------------|---------------------------------|\n| `@`         | Assign role to a message              | `user @ "message"`              |\n| `<<`        | Append message to chat (in-place)     | `chat << "text"`                |\n| `>>`        | Also appends in-place.                | `updated_chat = chat >> gpt`    |\n| `>`         | Send chat to model, get response      | `chat > gpt`                    |\n| `\\|`        | Apply model and append output         | `chat = chat << "hello" \\| gpt` |\n| `\\| =`      | Register reducer into chat\'s pipeline | `chat \\|= gpt \\| claude`        |\n\n## 🔄 Chat Composition and Transfer Patterns\n\n### Operator Precedence\n\nIn Embr, operators follow standard Python precedence rules. For our operators, from highest to lowest:\n\n| Precedence | Operators | Description |\n|------------|-----------|-------------|\n| Highest    | `@`       | Role annotation |\n| High       | `>`       | Process through model |\n| Medium     | `>>`      | Chat transfer |\n| Low        | `\\|`      | Pipe and modify |\n| Low        | `<<`      | Append message |\n\nThis affects how expressions are evaluated when chained together.\n\n### Chat Transfer Pattern\n\nThe chat transfer pattern allows you to process a chat through a model and transfer the results to another chat:\n```python\n# Process task_chat and transfer results to global_chat\n(task_chat > gpt) >> global_chat\n```\nThis pattern creates a clean separation between task-specific conversations and your main conversation context.\n```\n\n┌────────────┐    ┌─────┐    ┌─────────────┐    ┌────────────┐\n│ task_chat  │ >  │ gpt │ -> │ response    │ >> │ global_chat│\n└────────────┘    └─────┘    │ (Spark)     │    └────────────┘\n                             └─────────────┘\n```\n### Parenthesis-Free Alternatives\n\nFor cleaner code without parentheses, several alternatives exist:\n```\npython\n# Manual two-step approach\nresponse = task_chat > gpt\nglobal_chat << response\n\n# Using helper methods (proposed)\ntask_chat.process(gpt).append_to(global_chat)\n\n# Using a new syntax pattern (proposed)\ntask_chat > gpt > global_chat\n```\nThe last approach would require updating the implementation of the `>` operator to handle different right-hand types.\n\n---\n\n## 🚀 Example Use Cases\n\n### 1. 🛠️ Manual append + model roundtrip\n```\npython\nchat = Embr()\nchat << user @ "hello"\nresponse = chat > gpt\nchat << response\n```\n### 2. 🧪 Pipe-style chaining\n```\npython\nchat = Embr()\nchat = chat << "what is the weather?" | gpt\n```\n### 3. 🔗 Register reducers to the chat\n```\npython\nchat |= gpt | claude | other_ai\nchat.apply_reducers()\n```\n### 4. ❓ Conditional reducers\n```\npython\ndef gpt_if_question(chat):\nif "?" in chat.last.content:\nreturn gpt(chat)\n\n\nchat |= gpt_if_question\nchat << "this is a statement"\nchat << "what is this?"\nchat.apply_reducers()\n```\n### 5. 🤖 Multi-agent routing\n```\npython\nchat |= on_call @ gpt | on_call @ images\n```\n---\n\n## 🧩 Functional Patterns\n\n### Currying and Composition\n\nEmbr uses a functional programming pattern similar to currying, where functions like `gpt` are designed to:\n\n1. **Accept an Embr object**: Each reducer (like `gpt`, `claude`) takes a chat as input\n2. **Return a result**: Either a `Spark` (message) or a modified `Embr` object\n3. **Enable operator-based application**: The same function works with `>`, `>>`, and `|` operators\n\nThis pattern enables multiple styles of interaction:\n```python\n# Direct application returning a response\nresponse = chat > gpt\n\n# Application with returned response\nresponse = chat >> gpt\n\n# Pipeline style with in-place modification\nchat = chat | gpt\n```\nEmbr brings the expressiveness of Unix pipelines 🧵 to AI-assisted conversation flows 💬, making it easy to test, iterate, and layer\nintelligence like shell commands.\n```\n\n',
    'author': 'Ge Yang',
    'author_email': 'ge.ike.yang@gmail.com',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'None',
    'packages': packages,
    'package_data': package_data,
    'python_requires': '>=3.9,<4.0',
}


setup(**setup_kwargs)
