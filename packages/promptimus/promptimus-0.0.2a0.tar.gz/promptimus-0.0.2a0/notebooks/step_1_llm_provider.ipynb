{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f623ca20-31bb-4341-a6c6-dd06d755e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e9812-1a98-41f8-8e3d-d7c3d26a1daa",
   "metadata": {},
   "source": [
    "# LLM Provider\n",
    "A provider is a class that implements `ProviderProtocol`, serving as an interface to interact with a large language model (LLM). It processes user queries and returns model-generated responses.\n",
    "\n",
    "```python\n",
    "class ProviderProtocol(Protocol):\n",
    "    async def achat(self, history: list[Message]) -> Message: ...\n",
    "```\n",
    "\n",
    "Expected Behavior\n",
    "\n",
    "-  Implements `achat(self, history: list[Message]) -> Message`\n",
    "-  Accepts a conversation history (list of `Message` objects)\n",
    "-  Returns a single assistant-generated response (`Message`)\n",
    "\n",
    "A provider facilitates structured communication with an LLM, ensuring consistency in message handling and response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2395675-787f-40f4-a5e5-c2abf9321c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptimus import Message, MessageRole\n",
    "from promptimus.llms import OpenAILike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e895c88d-e905-430f-9709-34296a7bd3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a provider\n",
    "#\n",
    "# do not forgent to export OPENAI_API_KEY with your token or pass it as api-key argument\n",
    "provider = OpenAILike(\n",
    "    model_name=\"gemma3:4b\",\n",
    "    base_url=\"http://lilan:11434/v1\",\n",
    "    api_key=\"DUMMY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca13ac1b-e5d9-4f02-a587-87ac6ccf3141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mrole\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMessageRole.ASSISTANT:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m\"Hi\u001b[0m\u001b[32m there! I'm Gemma, a large language model created by the Gemma team at Google DeepMind. I'm an open-weights model, which means I'm widely available for public use! \\n\\nI can take text and images as inputs and respond with text. \\n\\nYou can learn more about me on the Gemma site: \u001b[0m\u001b[32m[\u001b[0m\u001b[32mhttps://ai.google.dev/gemma\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mhttps://ai.google.dev/gemma\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\n\\nIt's nice to meet you!\"\u001b[0m,\n",
       "    \u001b[33mtool_requests\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using a provider with single message\n",
    "await provider.achat(\n",
    "    [\n",
    "        Message(role=MessageRole.USER, content=\"Hi, who are you?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c374c7c6-a4a7-4372-bc1b-50e5f727b6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mrole\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mMessageRole.ASSISTANT:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[1m>\u001b[0m,\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'Hi there! You can call me Mark. Nice to meet you! ðŸ˜Š \\n\\nWhatâ€™s on your mind?'\u001b[0m,\n",
       "    \u001b[33mtool_requests\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using provider with multiple messages\n",
    "await provider.achat(\n",
    "    [\n",
    "        Message(role=MessageRole.SYSTEM, content=\"Your name is Mark.\"),\n",
    "        Message(role=MessageRole.USER, content=\"Hi, what is your name?\"),\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptimus",
   "language": "python",
   "name": "promptimus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
