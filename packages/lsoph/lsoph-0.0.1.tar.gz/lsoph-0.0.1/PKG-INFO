Metadata-Version: 2.4
Name: lsoph
Version: 0.0.1
Summary: An interactive lsof alternative
Author-email: Gareth Davidson <gaz@bitplane.net>
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Classifier: Programming Language :: Python :: 3
Classifier: License :: Public Domain
Classifier: Operating System :: POSIX :: Linux
Classifier: Topic :: Software Development :: Libraries :: Python Modules
License-File: LICENSE.md
Requires-Dist: psutil~=7.0
Requires-Dist: textual~=3.1
Requires-Dist: flake8 ; extra == "dev"
Requires-Dist: pre-commit ; extra == "dev"
Requires-Dist: pytest ; extra == "dev"
Requires-Dist: coverage ; extra == "dev"
Requires-Dist: pytest-cov ; extra == "dev"
Requires-Dist: build ; extra == "dev"
Requires-Dist: twine ; extra == "dev"
Project-URL: Bug Tracker, https://github.com/bitplane/lsoph/issues
Project-URL: Homepage, https://bitplane.net/dev/python/lsoph
Project-URL: Source Code, https://github.com/bitplane/lsoph
Provides-Extra: dev

# ðŸ¤– `lsoph` - list open files using genai slop!

TUI that lists open files for a given process.

usage:

```shell
uvx lsoph
```

## Why?
Because I thought it'd only take a couple of hours, and I'd heard good
things about Gemini 2.5 Pro, so did it as a coding test.

It descended into madness over the course of a weekend. Vibe coders,
I never realised how bad you have it!

### Gemini 2.5 Pro

* â˜• Writes more code than a Java consultancy that's paid by LoC.
* ðŸ¤¡ Defends against every type of exception, even import errors; belt,
  braces and elasticated waist.
* ðŸ‘– Its trousers still fall down.
* ðŸ§± Hard codes special cases and unreachable logic.
* ðŸ”¥ Will put verbose debug logging in your hottest loops.
* ðŸ—‘ Starts at the complexity ceiling, and manages to climb higher with
  every change.
* âœ… It needs to be BEST CORRECT, with the pig-headed stubbornness of
  `class UnwaveringPigsHead(basemodel)`.
* ðŸ–• Leaves passive aggressive comments in your code if you abuse it enough,
  and doesn't like to tidy up.
* ðŸª¦ It can't write test cases, or testable code.
* ðŸ’£ Carried by an enormous context window and rapid generation speed,
  then the wheels come off.

### GPT 4o and 4.5

* ðŸ’© Can't take the volume of dogshit produced by Gemini (but to be fair who
  can?)
* ðŸ’¤ Gets lazy because it's got no context window left, or because Sama is
  saving all his GPUs. Probably both.
* ðŸ¥± Attention slips, it forgets where its up to and then hallucinates all
  the details.
* ðŸ¤¥ Sycophantmaxxer, but still ignores your requests.
* ðŸŽ‰ Can actually write unit tests.
* ðŸš¬ Has actually stopped being such an aggressively "safety focused" PR
  bellend.
* ðŸ˜Ž A classic case of being down with the kids, a move that's absolute chefs
  kiss.

### Claude 3.7

* ðŸ«— It has none of the tools that GPT has, none of the mental models that
  Gemini has.
* ðŸš½ Still pisses all over them from a great height.
* ðŸ’‡ Decent eye for aesthetics.
* ðŸªŸ Has a better window size than GPT, and can focus attention better too.
* ðŸ‘‰ Mostly does as its told.
* ðŸ’© Still can't write good code.
* ðŸ¤“ No banter game whatsoever.

## Summary

In the kingdom of the token generators, the one-eyed Claude is king.


