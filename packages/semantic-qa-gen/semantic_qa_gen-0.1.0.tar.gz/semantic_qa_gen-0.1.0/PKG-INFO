Metadata-Version: 2.4
Name: semantic-qa-gen
Version: 0.1.0
Summary: A Python library for generating high-quality question-answer pairs from PDF, DOCX, MD, and TXT files
Project-URL: Documentation, https://github.com/stephengenusa/semantic-qa-gen#readme
Project-URL: Issues, https://github.com/stephengenusa/semantic-qa-gen/issues
Project-URL: Source, https://github.com/stephengenusa/semantic-qa-gen
Author-email: Stephen Genusa <github@genusa.com>
License: MIT
Keywords: ai,fine-tuning,llm,nlp,qa-pairs,question-answering,question-generation,semantic-analysis
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Text Processing :: Linguistic
Requires-Python: >=3.10
Requires-Dist: commonmark<0.10.0,>=0.9.1
Requires-Dist: httpx<0.25.0,>=0.23.0
Requires-Dist: llama-index
Requires-Dist: openai>=0.27.0
Requires-Dist: pydantic<2.0.0,>=1.10.0
Requires-Dist: python-magic<0.5.0,>=0.4.27
Requires-Dist: pyyaml<7.0,>=6.0
Requires-Dist: tiktoken>=0.4.0
Requires-Dist: tqdm<5.0.0,>=4.65.0
Provides-Extra: dev
Requires-Dist: black>=23.3.0; extra == 'dev'
Requires-Dist: flake8>=6.0.0; extra == 'dev'
Requires-Dist: isort>=5.12.0; extra == 'dev'
Requires-Dist: mkdocs-material>=9.1.15; extra == 'dev'
Requires-Dist: mkdocs>=1.4.3; extra == 'dev'
Requires-Dist: mypy>=1.3.0; extra == 'dev'
Requires-Dist: pytest-asyncio<0.22.0,>=0.21.0; extra == 'dev'
Requires-Dist: pytest-cov<5.0.0,>=4.1.0; extra == 'dev'
Requires-Dist: pytest<8.0.0,>=7.3.1; extra == 'dev'
Provides-Extra: docs
Requires-Dist: pymupdf>=1.22.3; extra == 'docs'
Requires-Dist: python-docx>=0.8.11; extra == 'docs'
Provides-Extra: full
Requires-Dist: llama-index; extra == 'full'
Requires-Dist: nltk>=3.8.1; extra == 'full'
Requires-Dist: pymupdf>=1.22.3; extra == 'full'
Requires-Dist: python-docx>=0.8.11; extra == 'full'
Requires-Dist: rich>=13.3.5; extra == 'full'
Requires-Dist: sentence-transformers>=2.2.2; extra == 'full'
Requires-Dist: transformers>=4.28.0; extra == 'full'
Provides-Extra: pdf
Requires-Dist: pymupdf>=1.22.3; extra == 'pdf'
Provides-Extra: rag
Requires-Dist: llama-index; extra == 'rag'
Requires-Dist: nltk>=3.8.1; extra == 'rag'
Requires-Dist: sentence-transformers>=2.2.2; extra == 'rag'
Requires-Dist: transformers>=4.28.0; extra == 'rag'
Description-Content-Type: text/markdown

<div align="center">
    <h1>SemanticQAGen</h1>
  <p><em>Intelligent Question-Answer Generation with Advanced Semantic Understanding For AI Fine-Tuning</em></p>
</div>

<p align="center">
  <a href="#overview">Overview</a> â€¢
  <a href="#installation">Installation</a> â€¢
  <a href="#quickstart">Quickstart</a> â€¢
  <a href="#feature-overview">Feature Overview</a> â€¢
  <a href="#core-capabilities">Core Capabilities</a> â€¢
  <a href="#advanced-features">Advanced Features</a> â€¢
  <a href="#project-file-organization">Project File Organization</a> â€¢
  <a href="#architecture">Architecture</a> â€¢
  <a href="#configuration">Configuration</a> â€¢
  <a href="#api-reference">API Reference</a> â€¢
  <a href="#cli-reference">CLI Reference</a> â€¢
  <a href="#usage-examples">Usage Examples</a> â€¢
  <a href="#extension">Extension</a> â€¢
  <a href="#troubleshooting">Troubleshooting</a> â€¢
  <a href="#license">License</a>
</p>

---
> **Alpha Release (v0.10)**: This library is in active development and not functional yet. I estimate it is 90% complete, so the last %10 percent may take 90% of the time. However, the feature set is amazing IMO, and I am looking forward to completing this library. If you are interested in helping, please fork the repo and help bring this Python library to life. 
---

## Overview

SemanticQAGen is a powerful Python library for generating high-quality question-answer pairs from text documents. It uses advanced semantic understanding to intelligently process content, analyze information density, and create diverse questions across multiple cognitive levels.

This builds upon concepts from the [Augmentoolkit](https://github.com/e-p-armstrong/augmentoolkit) project by Evan Armstrong and other QA generation projects. I tried Evan's project on some test data and fell in love with it. I originally intended to fork his project and work on adding features I wanted to see. After making the plan, I realized that this wasn't simply a fork. It just felt wrong to try and completely redesign someone else's excellent library and I wanted a much different feature set and so this library is the result. 

SemanticQAGen features enhanced semantic chunking, dynamic question generation, optional *validation* of questions and answers using retrieval-augmented generation (RAG), and flexible LLM routing capabilities. You can run all tasks locally on an OpenAI compatible server, run them off an Internet hosted API, or split specific tasks (eg. chunking, validation, analysis, generation) between local and remote servers. The library is designed with the "for Humans" philosophy - simple for basic use cases while providing advanced capabilities for power users.

---

## Installation

### Basic Installation

```bash
pip install semantic-qa-gen
```

### With Optional Dependencies

```bash
# With PDF support
pip install semantic-qa-gen[pdf]

# With full document support (PDF, DOCX, etc.)
pip install semantic-qa-gen[docs]

# With RAG validation capabilities
pip install semantic-qa-gen[rag]

# With enhanced UI and NLP capabilities
pip install semantic-qa-gen[full]

# Development installation with testing tools
pip install semantic-qa-gen[dev]
```

### Requirements

- Python 3.10 or higher
- Required dependencies are automatically installed with the package

---

## Quickstart

### Basic Usage

```python
from semantic_qa_gen import SemanticQAGen

# Initialize with default settings
qa_gen = SemanticQAGen()

# Process a document
result = qa_gen.process_document("path/to/document.txt")

# Save the questions to a JSON file
qa_gen.save_questions(result, "output")
```

### CLI Usage

```bash
# Generate questions from a document with default settings
semantic-qa-gen process document.pdf -o questions_output

# Process a whole directory of documents
semantic-qa-gen process-batch input_directory/ -o output_directory/

# Create a config file interactively 
semantic-qa-gen init-config config.yml --interactive

# Process with a specific configuration
semantic-qa-gen process document.txt --config config.yml --format json
```

---

## Feature Overview

SemanticQAGen offers a comprehensive set of features designed to produce high-quality question and answer sets:

| Feature Category | Capability                                                         | Included |
|-----------------|--------------------------------------------------------------------|:--------:|
| **Document Processing** | Document format support: TXT, PDF, DOCX, MD                      | âœ… |
|  | Batch document processing                                          | âœ… |
|  | Automatic document type detection                                  | âœ… |
|  | Cross-page content handling                                        | âœ… |
|  | Header/footer detection and removal                                | âœ… |
| **Content Analysis** | Semantic document chunking                                         | âœ… |
|  | Information density analysis                                       | âœ… |
|  | Topic coherence evaluation                                         | âœ… |
|  | Key concept extraction                                             | âœ… |
|  | Educational level classification                                   | âœ… |
| **Question Generation** | Multi-level cognitive questions (factual, inferential, conceptual) | âœ… |
|  | Adaptive generation based on content quality                       | âœ… |
|  | Question diversity enforcement                                     | âœ… |
|  | Custom question categories                                         | âœ… |
| **Answer Validation** | Factual accuracy verification                                      | âœ… |
|  | RAG-enhanced fact checking                                         | âœ… |
|  | Question clarity evaluation                                        | âœ… |
|  | Answer completeness assessment                                     | âœ… |
| **LLM Integration** | OpenAI API support                                                 | âœ… |
|  | Local LLM support (Ollama, etc.)                                   | âœ… |
|  | Hybrid task routing                                                | âœ… |
|  | Automatic fallback mechanisms                                      | âœ… |
| **Processing Control** | Checkpoint and resume capability                                   | âœ… |
|  | Parallel processing                                                | âœ… |
|  | Progress tracking and reporting                                    | âœ… |
|  | Memory optimization                                                | âœ… |
| **Output Options** | Multiple export formats (JSON, CSV)                                | âœ… |
|  | Metadata inclusion                                                 | âœ… |
|  | Statistics and analytics                                           | âœ… |
|  | RAG retriever creation                                             | âœ… |
| **Extensibility** | Custom document loaders                                            | âœ… |
|  | Custom chunking strategies                                         | âœ… |
|  | Custom validators                                                  | âœ… |
|  | Plugin architecture                                                | âœ… |

---

## Core Capabilities

### Document Processing

#### Multiple Format Support
SemanticQAGen can read and process a variety of document formats including plain text, PDF, Markdown, and DOCX. Each format is handled by specialized loaders that extract content while preserving document structure.

```python
# Process different file types the same way
result_txt = qa_gen.process_document("document.txt")
result_pdf = qa_gen.process_document("document.pdf")
result_md = qa_gen.process_document("document.md")
result_docx = qa_gen.process_document("document.docx")
```

#### Batch Processing
Process multiple files in a single operation. The system can handle directories of mixed document types and will generate separate outputs for each.

```python
# Process all files in a directory
qa_gen.process_batch(
    input_dir="input/",
    output_dir="output/",
    file_types=["txt", "pdf", "docx", "md"]
)
```

#### Automatic Document Type Detection
The system automatically detects document types using both file extensions and content analysis, ensuring the correct loader is used even when file extensions are missing or incorrect.

#### Cross-Page Content Handling
For PDF documents, the system intelligently handles sentences and paragraphs that span across page boundaries, creating a seamless text flow for better semantic analysis.

#### Header/Footer Detection
Automatic detection and optional removal of repeating headers and footers in PDF documents, preventing them from being included in generated questions.

### Content Analysis

#### Semantic Document Chunking
Documents are intelligently broken down into semantically coherent chunks based on content structure rather than arbitrary size limits. This preserves context and produces more meaningful question-answer pairs.

```python
# Configure chunking strategy
config = {
    "chunking": {
        "strategy": "semantic",  # Options: semantic, fixed_size, hybrid
        "target_chunk_size": 1500,
        "preserve_headings": True
    }
}
```

#### Information Density Analysis
Each chunk is analyzed for information density - how rich in facts and teachable content it is. This analysis guides question generation to focus on content-rich sections.

#### Topic Coherence Evaluation
The system evaluates how well each chunk maintains a coherent topic or theme, which helps ensure generated questions relate to a consistent subject area.

#### Key Concept Extraction
Important concepts, terms, and ideas are automatically identified in each chunk, forming the basis for targeted question generation.

#### Educational Level Classification (Optional)
Content is classified by appropriate educational level (elementary, high school, undergraduate, etc.) to help generate questions at suitable complexity levels. You can remove this metadata if it isn't applicable to your dataset.

### Question Generation

#### Multi-level Cognitive Questions
The system generates questions across three cognitive domains:
- **Factual**: Direct recall of information stated in the content
- **Inferential**: Questions requiring connecting multiple pieces of information
- **Conceptual**: Higher-order questions about principles, implications, or broader understanding

```python
# Configure question categories
config = {
    "question_generation": {
        "categories": {
            "factual": {"min_questions": 3, "weight": 1.0},
            "inferential": {"min_questions": 2, "weight": 1.2},
            "conceptual": {"min_questions": 1, "weight": 1.5}
        }
    }
}
```

#### Adaptive Generation
The number and types of questions generated adapt automatically based on content quality. Information-dense chunks yield more questions, while sparse chunks yield fewer.

#### Question Diversity Enforcement
To avoid repetitive or overly similar questions, the system enforces diversity by comparing newly generated questions with existing ones and filtering out duplicates.

#### Custom Question Categories
Users can define custom question categories beyond the standard factual/inferential/conceptual to target specific learning objectives.

### Answer Validation

#### Factual Accuracy Verification
All generated answers are verified against the source content to ensure they do not contain factual errors or hallucinations.

#### RAG-Enhanced Fact Checking
Optional LlamaIndex-based retrieval-augmented validation ensures answers are firmly grounded in the source material. This provides an additional verification layer beyond prompt-based checking.

#### Question Clarity Evaluation
Questions are evaluated for clarity and unambiguity, filtering out poorly formed questions that might confuse learners.

#### Answer Completeness Assessment
The system checks that answers thoroughly address the questions asked, eliminating partial or incomplete responses.

---

## Advanced Features

### RAG-Enhanced Answer Validation

SemanticQAGen's most advanced validation feature uses Retrieval-Augmented Generation (RAG) through LlamaIndex to ensure factual correctness. Unlike many AI question generators that can "hallucinate" incorrect facts, the RAG validation system acts as a powerful factual grounding mechanism.

#### How RAG Validation Works

1. **Document Indexing**: Source documents are indexed using LlamaIndex's document-centric architecture
2. **Answer Verification**: Generated answers are validated against the source material using specialized evaluation metrics
3. **Factual Grounding**: The CorrectnessEvaluator compares answers directly with retrieved context to detect discrepancies
4. **Confidence Scoring**: Each answer receives a factual grounding score (0.0-1.0) indicating reliability

#### Why I Chose LlamaIndex Over Alternatives

I personally prefer LangChain architecture, however LlamaIndex was selected specifically for its document-centric approach, specialized evaluation tools, and embedding management capabilities, making it ideal for factual verification. This is strictly a validation mechanism - it does not pollute or alter the Q/A generation process. The source material remains the single source of truth.

```python
# Enable RAG validation
config = {
    "validation": {
        "factual_accuracy": {
            "enabled": True,
            "threshold": 0.7
        },
        "rag_factual": {
            "enabled": True,
            "model": "gpt-4",
            "threshold": 0.75
        },
        "use_enhanced_validation": True  # Combine traditional and RAG validation
    }
}
```

#### RAG Validator Benefits

- **Source-Grounded Answers**: Ensures all information in answers comes directly from the source material
- **Hallucination Prevention**: Drastically reduces the likelihood of generated answers containing false information
- **Enhanced Quality Control**: Provides a robust verification layer beyond simple prompt engineering

The RAG validation system can be configured to be more or less strict depending on your needs. When using the enhanced combined validation, it benefits from both traditional prompt-based and retrieval-based approaches.

### LLM Integration

#### OpenAI API Support
Full integration with OpenAI with optimized prompting strategies for each task in the pipeline.

#### Local LLM Support
Support for local LLM deployment via Ollama, LM Studio, and similar services, allowing use of models like Llama, Mistral, etc., without requiring external API access.

#### Hybrid Task Routing
Intelligently route different tasks to the most appropriate LLM based on task complexity and model capability. For example, use GPT-4 for complex question generation but a local model for simple validation tasks.

```python
config = {
    "llm_services": {
        "local": {
            "enabled": True,
            "url": "http://localhost:11434/api",
            "model": "mistral:7b",
            "default_for": ["chunking", "validation"]
        },
        "remote": {
            "enabled": True,
            "provider": "openai",
            "model": "gpt-4",
            "default_for": ["analysis", "generation"]
        }
    }
}
```

#### Automatic Fallback Mechanisms
If a primary LLM service fails, the system automatically tries fallback services, ensuring robustness in production environments.

### Processing Control

#### Checkpoint and Resume Capability
Processing can be interrupted and resumed later using a checkpoint system. This is essential for large documents or when processing must be paused.

```python
config = {
    "processing": {
        "enable_checkpoints": True,
        "checkpoint_dir": "./checkpoints",
        "checkpoint_interval": 10  # Save every 10 chunks
    }
}
```

#### Parallel Processing
Multi-threaded processing of documents and chunks with configurable concurrency levels to maximize throughput on multi-core systems.

#### Progress Tracking and Reporting
Detailed progress reporting during processing, with support for both simple console output and rich interactive displays.

#### Memory Optimization
Smart memory management techniques to handle very large documents without exhausting system resources.

### Output Options

#### Multiple Export Formats
Export question-answer pairs in various formats including JSON, CSV, with customizable formatting options.

```python
# Save questions in different formats
qa_gen.save_questions(result, "questions_output", format_name="json")
qa_gen.save_questions(result, "questions_output", format_name="csv")
```

#### Metadata Inclusion
Include rich metadata about source documents, generation parameters, and validation results with the generated questions.

#### Statistics and Analytics
Comprehensive statistics about generated questions, including category distribution, validation success rates, and content coverage.

#### RAG Retriever Creation
Generated questions and answers can be exported as a LlamaIndex retriever for use in downstream applications.

```python
# Create a retriever from generated QA pairs
retriever = qa_gen.create_qa_retriever(result, api_key="YOUR_OPENAI_API_KEY")
response = retriever.retrieve("How does photosynthesis work?")
```

---

## Project File Organization
```txt
.
â”œâ”€â”€ ğŸ“„ __init__.py
â”œâ”€â”€ ğŸ“„ semantic_qa_gen.py
â”œâ”€â”€ ğŸ“„ version.py
â”œâ”€â”€ ğŸ“ semantic_qa_gen
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ main.py
â”‚   â”œâ”€â”€ ğŸ“„ semantic_qa_gen.py
â”‚   â”œâ”€â”€ ğŸ“ chunking
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ analyzer.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ engine.py
â”‚   â”‚   â””â”€â”€ ğŸ“ strategies
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ base.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ fixed_size.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ nlp_helpers.py
â”‚   â”‚       â””â”€â”€ ğŸ“„ semantic.py
â”‚   â”œâ”€â”€ ğŸ“ cli
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ commands.py
â”‚   â”œâ”€â”€ ğŸ“ config
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ manager.py
â”‚   â”‚   â””â”€â”€ ğŸ“„ schema.py
â”‚   â”œâ”€â”€ ğŸ“ document
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ models.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ processor.py
â”‚   â”‚   â””â”€â”€ ğŸ“ loaders
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ base.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ docx.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ markdown.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ pdf.py
â”‚   â”‚       â””â”€â”€ ğŸ“„ text.py
â”‚   â”œâ”€â”€ ğŸ“ llm
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ router.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ service.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“ adapters
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ local.py
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ remote.py
â”‚   â”‚   â””â”€â”€ ğŸ“ prompts
â”‚   â”‚       â””â”€â”€ ğŸ“„ manager.py
â”‚   â”œâ”€â”€ ğŸ“ output
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ formatter.py
â”‚   â”‚   â””â”€â”€ ğŸ“ adapters
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ csv.py
â”‚   â”‚       â””â”€â”€ ğŸ“„ json.py
â”‚   â”œâ”€â”€ ğŸ“ pipeline
â”‚   â”‚   â””â”€â”€ ğŸ“„ semantic.py
â”‚   â”œâ”€â”€ ğŸ“ question
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ generator.py
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ processor.py
â”‚   â”‚   â””â”€â”€ ğŸ“ validation
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ base.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ diversity.py
â”‚   â”‚       â”œâ”€â”€ ğŸ“„ engine.py
â”‚   â”‚       â””â”€â”€ ğŸ“„ factual.py
â”‚   â””â”€â”€ ğŸ“ utils
â”‚       â”œâ”€â”€ ğŸ“„ checkpoint.py
â”‚       â”œâ”€â”€ ğŸ“„ error.py
â”‚       â”œâ”€â”€ ğŸ“„ logging.py
â”‚       â””â”€â”€ ğŸ“„ progress.py
â”œâ”€â”€ ğŸ“„ setup.py
â””â”€â”€ ğŸ“ tests
    â”œâ”€â”€ ğŸ“„ conftest.py
    â”œâ”€â”€ ğŸ“„ test_chunking.py
    â”œâ”€â”€ ğŸ“„ test_config.py
    â”œâ”€â”€ ğŸ“„ test_document_processor.py
    â”œâ”€â”€ ğŸ“„ test_llm_service.py
    â”œâ”€â”€ ğŸ“„ test_main.py
    â”œâ”€â”€ ğŸ“„ test_pipeline.py
    â”œâ”€â”€ ğŸ“„ test_question_generation.py
    â”œâ”€â”€ ğŸ“„ test_utils.py
    â”œâ”€â”€ ğŸ“„ test_validation.py
    â””â”€â”€ ğŸ“ integration
        â””â”€â”€ ğŸ“„ test_minimal_pipeline.py
```

## Architecture

SemanticQAGen implements a modular pipeline architecture with clearly defined components and interfaces:

```
                                   ARCHITECTURE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                       â”‚       SemanticQAGen Class       â”‚                     â”‚
â”‚                       â”‚      (Main User Interface)      â”‚                     â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                     â”‚                                         â”‚
â”‚                                     â–¼                                         â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚           â”‚              SemanticPipeline Orchestrator         â”‚              â”‚
â”‚           â””â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”˜              â”‚
â”‚            â”‚                â”‚                   â”‚             â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚               â”‚
â”‚  â”‚  Document Manager  â”‚     â”‚    â”‚   Chunking & Analysis    â”‚ â”‚               â”‚
â”‚  â””â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜     â”‚    â””â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â”‚               â”‚
â”‚   â”‚                â”‚        â”‚     â”‚                     â”‚     â”‚               â”‚
â”‚â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”‚  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”‚               â”‚
â”‚â”‚ Document â”‚   â”‚Document â”‚   â”‚  â”‚ Chunking â”‚       â”‚Semantic â”‚ â”‚               â”‚
â”‚â”‚ Loaders  â”‚   â”‚Processorâ”‚   â”‚  â”‚ Engine   â”‚       â”‚Analyzer â”‚ â”‚               â”‚
â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚               â”‚
â”‚                             â”‚                                 â”‚               â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚               â”‚
â”‚      â”‚               LLM Service Router                â”‚      â”‚               â”‚
â”‚      â”‚                                                 â”‚      â”‚               â”‚
â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚               â”‚
â”‚      â”‚  â”‚ Remote LLM     â”‚         â”‚ Local LLM      â”‚  â”‚      â”‚               â”‚
â”‚      â”‚  â”‚ (OpenAI, etc.) â”‚         â”‚ (Ollama, etc.) â”‚  â”‚      â”‚               â”‚
â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚               â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚               â”‚
â”‚                             â”‚                                 â”‚               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Question Generator    â”‚ â”‚ â”‚         Validation Engine              â”‚      â”‚
â”‚  â”‚                        â”‚â—„â”¼â”€â”¼â”€â”€â”€â”€â”                                   â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚    â”‚                                   â”‚      â”‚
â”‚  â”‚  â”‚Category: Factual â”‚  â”‚ â”‚ â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚    â”œâ”€â–ºâ”‚ Traditional â”‚ â”‚  RAG-based   â”‚ â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚    â”‚  â”‚ Validators  â”‚ â”‚  Validator   â”‚ â”‚      â”‚
â”‚  â”‚  â”‚Cat: Inferential  â”‚  â”‚ â”‚ â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚    â”‚                                   â”‚      â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚ â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚      â”‚
â”‚  â”‚  â”‚Cat: Conceptual   â”‚  â”‚ â”‚ â”‚    â””â”€â–ºâ”‚  Enhanced Validator          â”‚ â”‚      â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚ â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”˜      â”‚
â”‚            â”‚                â”‚                                         â”‚       â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                             â”‚                                                 â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚          â”‚           Output Formatter             â”‚                           â”‚
â”‚          â”‚                                        â”‚                           â”‚
â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                           â”‚
â”‚          â”‚  â”‚ JSON Adapterâ”‚    â”‚  CSV Adapter   â”‚ â”‚                           â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                           â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                             â”‚                                                 â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚           â”‚           Output Results             â”‚                            â”‚
â”‚           â”‚  â€¢ Questions & Answers               â”‚                            â”‚
â”‚           â”‚  â€¢ Document Metadata                 â”‚                            â”‚
â”‚           â”‚  â€¢ Statistics                        â”‚                            â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                                                               â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                      â”‚     Checkpoint Manager      â”‚                          â”‚
â”‚                      â”‚   (Resume Capabilities)     â”‚                          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                               â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                      â”‚     Progress Reporter       â”‚                          â”‚
â”‚                      â”‚   (Processing Feedback)     â”‚                          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                 DATA FLOW
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Document â”‚      â”‚ Document  â”‚     â”‚   List    â”‚      â”‚Chunk List â”‚        â”‚
â”‚  â”‚  Files    â”‚â”€â”€â”€â”€â”€â–ºâ”‚   Model   â”‚â”€â”€â”€â”€â–ºâ”‚ of Chunks â”‚â”€â”€â”€â”€â”€â–ºâ”‚w/Analysis â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                                                â”‚              â”‚
â”‚                                                                â–¼              â”‚
â”‚                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚ Question-Answer Generation     â”‚    â”‚
â”‚  â”‚   Final   â”‚     â”‚  Validated â”‚       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚
â”‚  â”‚  Output   â”‚â—„â”€â”€â”€â”€â”¤ Question   â”‚â—„â”€â”€â”€â”€â”€â”€â”¤ â”‚ Question 1 â”‚ â”‚ Question 2 â”‚  â”‚    â”‚
â”‚  â”‚           â”‚     â”‚  List      â”‚       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                           VALIDATION SUBSYSTEM
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Generated     â”‚     â”‚             Validation Engine                   â”‚   â”‚
â”‚   â”‚ Questions     â”‚â”€â”€â”€â”€â–ºâ”‚                                                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚                         â”‚    â”‚  Traditional Flow  â”‚  â”‚   RAG Flow      â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚                    â”‚  â”‚                 â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚  Factual     â”‚   â”‚  â”‚ â”‚ Source      â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚  Accuracy    â”‚   â”‚  â”‚ â”‚ Document    â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â”‚ Index       â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚  Answer      â”‚   â”‚  â”‚        â”‚        â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚ Completeness â”‚   â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â”‚ LlamaIndex  â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â”‚ Correctness â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚  Question    â”‚   â”‚  â”‚ â”‚ Evaluator   â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚  Clarity     â”‚   â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚        â”‚        â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚  Diversity   â”‚   â”‚  â”‚ â”‚ Accuracy    â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â”‚  Check       â”‚   â”‚  â”‚ â”‚ Score       â”‚ â”‚  â”‚   â”‚
â”‚                         â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚   â”‚
â”‚                         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚                         â”‚                                                 â”‚   â”‚
â”‚                         â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚                         â”‚            â”‚   Combine Results  â”‚               â”‚   â”‚
â”‚                         â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚                         â”‚                      â”‚                          â”‚   â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                â”‚                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚   â”‚ Final Valid   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Validation Results â”‚                   â”‚
â”‚   â”‚ Questions     â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                           â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                             BATCH PROCESSING 
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Input       â”‚         â”‚ Batch Processor       â”‚      â”‚ Checkpoint   â”‚     â”‚
â”‚   â”‚ Directory   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º                       â”‚â—„â”€â”€â”€â”€â–ºâ”‚ Store        â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚ â”‚ File Type      â”‚    â”‚                           â”‚
â”‚                           â”‚ â”‚ Detection      â”‚    â”‚                           â”‚
â”‚                           â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                           â”‚
â”‚                           â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                           â”‚
â”‚                           â”‚ â”‚ Processing     â”‚    â”‚                           â”‚
â”‚                           â”‚ â”‚ Queue          â”‚    â”‚                           â”‚
â”‚                           â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚                           â”‚
â”‚                           â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚                           â”‚ â”‚ Parallel       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º File 1      â”‚     â”‚
â”‚                           â”‚ â”‚ Scheduler      â”‚    â”‚      â”‚ Processing   â”‚     â”‚
â”‚                           â”‚ â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”˜    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â”‚    â”‚            â”‚     â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚                           â”‚    â”‚            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º File 2       â”‚     â”‚
â”‚                           â”‚    â”‚            â”‚     â”‚      â”‚ Processing   â”‚     â”‚
â”‚                           â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                      â”‚                                        â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                          â”‚ Results Aggregator    â”‚                            â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                                      â”‚                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚   â”‚ Output      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Final Outputs        â”‚                            â”‚
â”‚   â”‚ Directory   â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                             â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
### Core Components

1. **Document Processor**: Handles document loading and preprocessing
2. **Chunking Engine**: Splits documents into semantically coherent chunks
3. **Semantic Analyzer**: Evaluates information density and question potential
4. **Question Generator**: Creates diverse questions based on content analysis
5. **Validation Engine**: Ensures question quality and diversity
6. **Output Formatter**: Formats and exports the generated Q&A pairs

### Processing Pipeline

```
Document â†’ Chunks â†’ Analysis â†’ Questions â†’ Validation â†’ Output
```

The pipeline implements a two-phase approach:
1. **Analysis Phase**: Document is processed, chunked, and analyzed for content quality
2. **Generation Phase**: Questions are generated, validated, and formatted based on analysis

---

## Configuration

SemanticQAGen uses a hierarchical YAML configuration system with schema validation.

### Configuration File Example

```yaml
# SemanticQAGen configuration
version: 1.0

# Document processing settings
document:
  loaders:
    text:
      enabled: true
      encoding: utf-8
    pdf:
      enabled: true
      extract_images: false
      ocr_enabled: false
      detect_headers_footers: true
    markdown:
      enabled: true
      extract_metadata: true
    docx:
      enabled: true
      extract_tables: true

# Chunking settings
chunking:
  strategy: semantic
  target_chunk_size: 1500
  overlap_size: 150
  preserve_headings: true
  min_chunk_size: 500
  max_chunk_size: 2500

# LLM services configuration
llm_services:
  local:
    enabled: true
    url: "http://localhost:11434/api"
    model: "mistral:7b"
    default_for: [chunking, validation]
    timeout: 60
  remote:
    enabled: true
    provider: openai
    model: gpt-4
    api_key: ${OPENAI_API_KEY}
    default_for: [analysis, generation]
    timeout: 120
    rate_limit_tokens: 90000
    rate_limit_requests: 100

# Question generation settings
question_generation:
  max_questions_per_chunk: 10
  adaptive_generation: true
  categories:
    factual:
      min_questions: 2
      weight: 1.0
    inferential:
      min_questions: 2
      weight: 1.2
    conceptual:
      min_questions: 1
      weight: 1.5
  diversity:
    required: true
    min_similarity_threshold: 0.75

# Validation settings
validation:
  factual_accuracy:
    enabled: true
    threshold: 0.8
  answer_completeness:
    enabled: true
    threshold: 0.8
  question_clarity:
    enabled: true
    threshold: 0.8
  diversity:
    enabled: true
    similarity_metric: cosine
  rag_factual:
    enabled: true
    model: "gpt-4"
    threshold: 0.7
  use_enhanced_validation: true

# Batch processing settings
processing:
  concurrency: 3
  enable_checkpoints: true
  checkpoint_interval: 10
  checkpoint_dir: "./checkpoints"
  log_level: "INFO"
  batch:
    enabled: true
    input_dir: "./documents"
    output_dir: "./output"
    supported_types: ["txt", "pdf", "md", "docx"]
    parallel_processing: true
    max_concurrent_files: 2
    continue_on_error: true
    track_processed_files: true
    skip_completed_files: true
    resume_strategy: "auto-detect"

# Output settings
output:
  format: json
  include_metadata: true
  include_statistics: true
  output_dir: "./output"
  json_indent: 2
  csv_delimiter: ","
```

### Example JSON Output
```json
In the JSON output format, the metadata for each question/answer pair is integrated directly with the question/answer data. Each question is represented as a single JSON object that contains all its associated information, including the question text, answer text, category, and all metadata

{
  "questions": [
    {
      "id": "q_c05a3e9b",
      "text": "What is photosynthesis?",
      "answer": "Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll. It converts light energy into chemical energy, specifically glucose, while releasing oxygen as a byproduct.",
      "category": "factual",
      "chunk_id": "chunk_28a1e5",
      "metadata": {
        "source_page": 12,
        "confidence_score": 0.92,
        "generated_at": "2025-03-15T14:23:47Z",
        "validation_scores": {
          "factual_accuracy": 0.95,
          "question_clarity": 0.89,
          "answer_completeness": 0.91,
          "rag_factual_accuracy": 0.97
        },
        "topic": "Biology",
        "educational_level": "High School",
        "keywords": ["photosynthesis", "plants", "chlorophyll", "glucose", "energy conversion"]
      }
    },
    // Additional questions...
```


### Environment Variables

Configuration values can be specified using environment variables:

```yaml
llm_services:
  remote:
    api_key: ${OPENAI_API_KEY}
```

### Configuration Layering

Configuration is resolved in the following order:
1. Default values
2. Configuration file
3. Environment variables
4. Command-line arguments
5. Programmatic overrides

---

## API Reference

### Class Heirarchy

```
                                 CLASS HIERARCHY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                               â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                         â”‚     SemanticQAGen       â”‚                           â”‚
â”‚                         â”‚                         â”‚                           â”‚
â”‚                         â”‚ - process_document()    â”‚                           â”‚
â”‚                         â”‚ - process_batch()       â”‚                           â”‚
â”‚                         â”‚ - save_questions()      â”‚                           â”‚
â”‚                         â”‚ - create_qa_retriever() â”‚                           â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                      â”‚                                        â”‚
â”‚                                      â”‚                                        â”‚
â”‚                                      â”‚                                        â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚                 â”‚         SemanticPipeline              â”‚                     â”‚
â”‚                 â”‚                                       â”‚                     â”‚
â”‚                 â”‚ - build_pipeline()                    â”‚                     â”‚
â”‚                 â”‚ - run_pipeline()                      â”‚                     â”‚
â”‚                 â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                     â”‚             â”‚            â”‚                              â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”Œâ”€â”€â”€â”€â”€â”˜                              â”‚
â”‚      â”‚                   â”‚               â”‚                                    â”‚
â”‚      â–¼                   â–¼               â–¼                                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚ â”‚ConfigManager â”‚  â”‚EventEmitter â”‚  â”‚ProgressTrackerâ”‚                          â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                                               â”‚
â”‚                          DOCUMENT PROCESSING                                  â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚   DocumentProcessor   â”‚                                                    â”‚
â”‚  â”‚                       â”‚                                                    â”‚
â”‚  â”‚ - load_document()     â”‚                                                    â”‚
â”‚  â”‚ - extract_sections()  â”‚                                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚              â”‚                                                                â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚      â”‚                                  â”‚                                     â”‚
â”‚      â–¼                                  â–¼                                     â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚ â”‚DocumentLoaderâ”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  BaseLoader     â”‚                           â”‚
â”‚ â”‚Manager       â”‚                â”‚  (Abstract)     â”‚                           â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                                          â”‚                                    â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                        â”‚                 â”‚                â”‚               â”‚   â”‚
â”‚                        â–¼                 â–¼                â–¼               â–¼   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚              â”‚TextFileLoader â”‚  â”‚PDFLoader    â”‚  â”‚DocxLoader   â”‚ â”‚MarkdownLdrâ”‚â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                               â”‚
â”‚                                 CHUNKING                                      â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚  â”‚   ChunkingEngine    â”‚                                                      â”‚
â”‚  â”‚                     â”‚                                                      â”‚
â”‚  â”‚ - chunk_document()  â”‚                                                      â”‚
â”‚  â”‚ - process_chunks()  â”‚                                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚            â”‚                                                                  â”‚
â”‚            â”‚                                                                  â”‚
â”‚            â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚BaseChunkingStrategy   â”‚                                                    â”‚
â”‚  â”‚(Abstract)             â”‚                                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚              â”‚                                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚    â”‚         â”‚            â”‚                   â”‚                               â”‚
â”‚    â–¼         â–¼            â–¼                   â–¼                               â”‚
â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚â”‚Semantic   â”‚ â”‚ â”‚FixedSize   â”‚ â”‚RecursiveChunk â”‚ â”‚HybridChunking â”‚             â”‚
â”‚â”‚Chunking   â”‚ â”‚ â”‚Chunking    â”‚ â”‚Strategy       â”‚ â”‚Strategy       â”‚             â”‚
â”‚â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚              â”‚                                                                â”‚
â”‚              â–¼                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                    â”‚
â”‚  â”‚    SemanticAnalyzer   â”‚                                                    â”‚
â”‚  â”‚                       â”‚                                                    â”‚
â”‚  â”‚ - analyze_chunk()     â”‚                                                    â”‚
â”‚  â”‚ - get_content_score() â”‚                                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                    â”‚
â”‚                                                                               â”‚
â”‚                           LLM SERVICES                                        â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                     â”‚
â”‚  â”‚   LLMServiceRouter   â”‚                                                     â”‚
â”‚  â”‚                      â”‚                                                     â”‚
â”‚  â”‚ - route_request()    â”‚                                                     â”‚
â”‚  â”‚ - select_service()   â”‚                                                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                     â”‚
â”‚             â”‚                                                                 â”‚
â”‚             â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚  â”‚    BaseLLMService   â”‚                                                      â”‚
â”‚  â”‚     (Abstract)      â”‚                                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚            â”‚                                                                  â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                                                           â”‚
â”‚      â”‚            â”‚                                                           â”‚
â”‚      â–¼            â–¼                                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚ â”‚OpenAIServiceâ”‚ â”‚LocalLLMSvc  â”‚                                               â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                                               â”‚
â”‚                     QUESTION GENERATION                                       â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚  â”‚  QuestionGenerator     â”‚                                                   â”‚
â”‚  â”‚                        â”‚                                                   â”‚
â”‚  â”‚ - generate_questions() â”‚                                                   â”‚
â”‚  â”‚ - create_prompts()     â”‚                                                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚              â”‚                                                                â”‚
â”‚              â–¼                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  CategoryHandler       â”‚    â”‚   PromptTemplate    â”‚                        â”‚
â”‚  â”‚                        â”‚    â”‚                     â”‚                        â”‚
â”‚  â”‚ - get_category_prompts()    â”‚ - format()          â”‚                        â”‚
â”‚  â”‚ - get_question_count() â”‚    â”‚ - get_variables()   â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                               â”‚
â”‚                        VALIDATION                                             â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚ ValidationEngine   â”‚                                                       â”‚
â”‚  â”‚                    â”‚                                                       â”‚
â”‚  â”‚ - validate()       â”‚                                                       â”‚
â”‚  â”‚ - combine_results()â”‚                                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚           â”‚                                                                   â”‚
â”‚           â–¼                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                          â”‚
â”‚  â”‚  BaseValidator  â”‚                                                          â”‚
â”‚  â”‚   (Abstract)    â”‚                                                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                          â”‚
â”‚           â”‚                                                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚     â”‚     â”‚        â”‚             â”‚               â”‚                            â”‚
â”‚     â–¼     â–¼        â–¼             â–¼               â–¼                            â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚FactualAcc  â”‚ â”‚Question  â”‚ â”‚AnswerComp  â”‚ â”‚Diversity   â”‚ â”‚RAGFactualValid  â”‚ â”‚
â”‚ â”‚Validator   â”‚ â”‚Clarity   â”‚ â”‚Validator   â”‚ â”‚Validator   â”‚ â”‚                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                    â”‚          â”‚
â”‚                                                                    â–¼          â”‚
â”‚                                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                                           â”‚LlamaIndexAdapterâ”‚ â”‚
â”‚                                                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                               â”‚
â”‚                          OUTPUT                                               â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚  OutputFormatter   â”‚                                                       â”‚
â”‚  â”‚                    â”‚                                                       â”‚
â”‚  â”‚ - format_output()  â”‚                                                       â”‚
â”‚  â”‚ - save_output()    â”‚                                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚           â”‚                                                                   â”‚
â”‚           â–¼                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                       â”‚
â”‚  â”‚  BaseOutputAdapter â”‚                                                       â”‚
â”‚  â”‚     (Abstract)     â”‚                                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                       â”‚
â”‚           â”‚                                                                   â”‚
â”‚      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                                                           â”‚
â”‚      â”‚            â”‚                                                           â”‚
â”‚      â–¼            â–¼                                                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                   â”‚
â”‚ â”‚JSONAdapterâ”‚  â”‚CSVAdapterâ”‚                                                   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                   â”‚
â”‚                                                                               â”‚
â”‚                           MODELS                                              â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Document      â”‚  â”‚  Chunk     â”‚   â”‚  Question    â”‚   â”‚ValidationResultâ”‚   â”‚
â”‚  â”‚ (dataclass)    â”‚  â”‚ (dataclass)â”‚   â”‚ (dataclass)  â”‚   â”‚  (dataclass)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚DocumentMetadataâ”‚  â”‚Section     â”‚   â”‚ChunkAnalysis â”‚                        â”‚
â”‚  â”‚  (dataclass)   â”‚  â”‚(dataclass) â”‚   â”‚ (dataclass)  â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                               â”‚
â”‚                      BATCH PROCESSING                                         â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚
â”‚  â”‚   BatchProcessor  â”‚                                                        â”‚
â”‚  â”‚                   â”‚                                                        â”‚
â”‚  â”‚ - process_batch() â”‚                                                        â”‚
â”‚  â”‚ - queue_files()   â”‚                                                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚           â”‚                                                                   â”‚
â”‚           â–¼                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚  â”‚ ParallelScheduler  â”‚   â”‚ CheckpointManager  â”‚                              â”‚
â”‚  â”‚                    â”‚   â”‚                    â”‚                              â”‚
â”‚  â”‚ - run_parallel()   â”‚   â”‚ - save_checkpoint()â”‚                              â”‚
â”‚  â”‚ - handle_results() â”‚   â”‚ - load_checkpoint()â”‚                              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                               â”‚
â”‚                         UTILITIES                                             â”‚
â”‚                                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ TokenCounter  â”‚   â”‚ Logger     â”‚   â”‚TextCleaner â”‚   â”‚ExceptionHandlerâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Main Class: `SemanticQAGen`

```python
class SemanticQAGen:
    """Main interface for generating question-answer pairs from text documents."""
    
    def __init__(self, config_path: Optional[str] = None, 
                config_dict: Optional[Dict[str, Any]] = None,
                verbose: bool = False):
        """Initialize SemanticQAGen with optional configuration."""
        
    def process_document(self, document_path: str) -> Dict[str, Any]:
        """
        Process a document to generate question-answer pairs.
        
        Args:
            document_path: Path to the document file.
            
        Returns:
            Dictionary containing questions, statistics, and metadata.
        """
        
    def process_batch(self, input_dir: Optional[str] = None,
                     output_dir: Optional[str] = None,
                     file_types: Optional[List[str]] = None) -> Dict[str, Dict[str, Any]]:
        """
        Process multiple documents from a directory.
        
        Args:
            input_dir: Directory containing documents to process.
            output_dir: Directory to save outputs.
            file_types: List of file types to process (e.g., ["txt", "pdf"]).
            
        Returns:
            Dictionary mapping filenames to results.
        """
        
    def save_questions(self, result: Dict[str, Any], 
                      output_path: str,
                      format_name: Optional[str] = None) -> str:
        """
        Save generated questions to a file.
        
        Args:
            result: Results from process_document.
            output_path: Path where to save the output.
            format_name: Format to save in (json, csv, etc.).
            
        Returns:
            Path to the saved file.
        """
        
    def create_default_config_file(self, output_path: str) -> None:
        """Create a default configuration file."""
        
    def create_qa_retriever(self, result: Dict[str, Any], api_key: Optional[str] = None) -> Any:
        """
        Create a LlamaIndex retriever from generated QA pairs.
        
        Args:
            result: Results from process_document.
            api_key: Optional OpenAI API key.
            
        Returns:
            LlamaIndex retriever object for RAG applications.
        """
```

For additional API details, see the complete [API Documentation](https://semanticqagen.readthedocs.io/).

---

## CLI Reference

SemanticQAGen provides a comprehensive command-line interface:

### Main Commands

```
semantic-qa-gen process <document> [-o OUTPUT] [-f {json,csv}] [-c CONFIG] [-v]
semantic-qa-gen process-batch [input_dir] [-o OUTPUT_DIR] [--types TYPES] [-c CONFIG]
semantic-qa-gen init-config <output> [-i]
semantic-qa-gen interactive
semantic-qa-gen version
```

### Command Details

```
process             Process a document and generate questions
  document          Path to the document file
  -o, --output      Path for output file
  -f, --format      Output format (json, csv)
  -c, --config      Path to config file
  -v, --verbose     Enable verbose output

process-batch       Process multiple documents from a directory
  input_dir         Input directory containing documents
  -o, --output-dir  Output directory for results
  --types           File types to process (comma-separated)
  --exclude         Files to exclude (comma-separated)
  -c, --config      Path to config file
  --no-checkpoints  Disable checkpointing
  -v, --verbose     Enable verbose output

init-config         Create a default configuration file
  output            Path for the config file
  -i, --interactive Create config interactively

interactive         Run in interactive mode
version             Show the version and exit
```

### Examples

```bash
# Process a PDF document
semantic-qa-gen process document.pdf -o questions_output

# Process all files in a directory
semantic-qa-gen process-batch input_docs/ -o output_results/

# Process specific file types
semantic-qa-gen process-batch input_docs/ --types pdf,txt -o output_results/

# Process with a specific configuration
semantic-qa-gen process document.txt --config my_config.yml --format csv

# Create a default configuration file
semantic-qa-gen init-config config.yml

# Create a configuration file interactively
semantic-qa-gen init-config config.yml --interactive
```

---

## Usage Examples

### Basic Document Processing

```python
from semantic_qa_gen import SemanticQAGen

# Initialize with default settings
qa_gen = SemanticQAGen()

# Process a document
result = qa_gen.process_document("path/to/document.txt")

# Save the questions to a JSON file
qa_gen.save_questions(result, "qa_pairs.json")

# Display stats
print(f"Generated {len(result['questions'])} questions")
print(f"Factual questions: {result['statistics']['categories']['factual']}")
print(f"Inferential questions: {result['statistics']['categories']['inferential']}")
print(f"Conceptual questions: {result['statistics']['categories']['conceptual']}")
```

### Batch Processing with Checkpoints

```python
from semantic_qa_gen import SemanticQAGen

# Configuration for batch processing with checkpoints
config = {
    "processing": {
        "enable_checkpoints": True,
        "batch": {
            "input_dir": "./documents",
            "output_dir": "./results",
            "supported_types": ["txt", "pdf", "md", "docx"],
            "continue_on_error": True,
            "skip_completed_files": True
        }
    }
}

# Initialize with batch processing config
qa_gen = SemanticQAGen(config_dict=config)

# Process all files in the input directory
# Will resume from previous checkpoints if available
batch_results = qa_gen.process_batch()

print(f"Processed {len(batch_results)} documents")

# You can also specify directories explicitly
batch_results = qa_gen.process_batch(
    input_dir="./other_documents",
    output_dir="./other_results",
    file_types=["pdf", "txt"]
)
```

### Using Local and Remote LLMs Together

```python
from semantic_qa_gen import SemanticQAGen

# Configuration for hybrid LLM setup
config = {
    "llm_services": {
        "local": {
            "enabled": True,
            "url": "http://localhost:11434/api",
            "model": "mistral:7b",
            "default_for": ["chunking", "validation"]
        },
        "remote": {
            "enabled": True,
            "provider": "openai",
            "model": "gpt-4",
            "api_key": "YOUR_API_KEY",
            "default_for": ["analysis", "generation"]
        }
    }
}

# Initialize with hybrid LLM config
qa_gen = SemanticQAGen(config_dict=config)

# Process document using hybrid approach
# - Local model will handle chunking and validation
# - Remote model will handle analysis and question generation
result = qa_gen.process_document("document.pdf")
```

### RAG-Enhanced Validation

```python
from semantic_qa_gen import SemanticQAGen

# Configuration focusing on validation
config = {
    "validation": {
        "factual_accuracy": {
            "enabled": True,
            "threshold": 0.7
        },
        "rag_factual": {
            "enabled": True,
            "model": "gpt-4",
            "threshold": 0.75,
            "strict_mode": True
        },
        "use_enhanced_validation": True  # Combined approach
    }
}

# Process document with enhanced validation
qa_gen = SemanticQAGen(config_dict=config)
result = qa_gen.process_document("document.pdf")

# Create a retriever from the validated questions
retriever = qa_gen.create_qa_retriever(result, api_key="YOUR_OPENAI_API_KEY")

# Use the retriever in a separate application
response = retriever.retrieve("What is the most important concept?")
```

### Custom Question Categories

```python
config = {
    "question_generation": {
        "max_questions_per_chunk": 12,
        "categories": {
            "factual": {
                "min_questions": 4,  # Prefer more factual questions
                "weight": 1.5
            },
            "inferential": {
                "min_questions": 3,
                "weight": 1.2
            },
            "conceptual": {
                "min_questions": 2,
                "weight": 1.0
            },
            "applied": {  # Custom category - practical applications
                "min_questions": 3,
                "weight": 1.3
            }
        }
    }
}

qa_gen = SemanticQAGen(config_dict=config)
```

### Processing Large Documents Efficiently

```python
from semantic_qa_gen import SemanticQAGen

config = {
    "chunking": {
        "strategy": "semantic",
        "target_chunk_size": 1200,  # Smaller chunks
        "max_chunk_size": 1800
    },
    "processing": {
        "concurrency": 2,  # Lower concurrency to reduce memory usage
        "enable_checkpoints": True,
        "checkpoint_interval": 5  # Save checkpoints frequently
    }
}

qa_gen = SemanticQAGen(config_dict=config)
result = qa_gen.process_document("large_document.pdf")
```

---

## Extension

SemanticQAGen is designed to be easily extended with custom components.

### Creating a Custom Document Loader

```python
from semantic_qa_gen.document.loaders.base import BaseLoader
from semantic_qa_gen.document.models import Document, DocumentType, DocumentMetadata
from semantic_qa_gen.utils.error import DocumentError

class CustomFileLoader(BaseLoader):
    """Loader for custom file format."""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        
    def load(self, path: str) -> Document:
        """Load a document from a custom file format."""
        if not self.supports_type(path):
            raise DocumentError(f"Unsupported file type: {path}")
            
        # Implementation for loading custom format
        with open(path, 'r', encoding='utf-8') as file:
            content = file.read()
            
        # Create and return document
        return Document(
            content=content,
            doc_type=DocumentType.TEXT,
            path=path,
            metadata=self.extract_metadata(path)
        )
        
    def supports_type(self, file_path: str) -> bool:
        """Check if this loader supports the given file type."""
        _, ext = os.path.splitext(file_path.lower())
        return ext == '.custom'
        
    def extract_metadata(self, path: str) -> DocumentMetadata:
        """Extract metadata from the custom file."""
        # Implementation for extracting metadata
        return DocumentMetadata(
            title=os.path.basename(path),
            source=path
        )
```

### Registering a Custom Loader

```python
from semantic_qa_gen import SemanticQAGen
from semantic_qa_gen.document.processor import DocumentProcessor

# Create your custom loader
custom_loader = CustomFileLoader()

# Initialize SemanticQAGen
qa_gen = SemanticQAGen()

# Get the document processor
doc_processor = qa_gen.pipeline.document_processor

# Register your custom loader
doc_processor.loaders.append(custom_loader)

# Now you can process custom file formats
result = qa_gen.process_document("document.custom")
```

### Creating a Custom Validator

```python
from semantic_qa_gen.question.validation.base import BaseValidator, ValidationResult
from semantic_qa_gen.document.models import Question, Chunk

class CustomValidator(BaseValidator):
    """Custom validator for specialized validation logic."""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.threshold = self.config.get('threshold', 0.7)
    
    async def validate(self, question: Question, chunk: Chunk) -> ValidationResult:
        """Implement custom validation logic."""
        # Custom validation implementation
        score = 0.8  # Example score
        
        return ValidationResult(
            question_id=question.id,
            is_valid=score >= self.threshold,
            scores={"custom_score": score},
            reasons=[f"Custom validation: {score:.2f}"],
            suggested_improvements=None if score >= self.threshold else "Suggestion for improvement"
        )
```

### Creating a Custom Chunking Strategy

```python
from semantic_qa_gen.chunking.strategies.base import BaseChunkingStrategy
from semantic_qa_gen.document.models import Document, Section, Chunk

class CustomChunkingStrategy(BaseChunkingStrategy):
    """Custom strategy for document chunking."""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.target_size = self.config.get('target_chunk_size', 1500)
        
    def chunk_document(self, document: Document, sections: List[Section]) -> List[Chunk]:
        """Break a document into chunks using a custom strategy."""
        chunks = []
        
        # Custom implementation of chunking algorithm
        
        return chunks
```

---

## Troubleshooting

### Common Issues and Solutions

#### Installation Problems

**Issue**: Missing dependencies when installing
**Solution**: Install with the appropriate extra dependencies:
```bash
pip install semantic-qa-gen[full]
```

**Issue**: Conflicts with existing packages
**Solution**: Use a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install semantic-qa-gen
```

#### Processing Issues

**Issue**: Out of memory errors with large documents
**Solution**: Adjust chunking and processing settings:
```python
config = {
    "chunking": {
        "target_chunk_size": 1000,  # Smaller chunks
        "max_chunk_size": 1500
    },
    "processing": {
        "concurrency": 1,  # Reduce concurrency
        "enable_checkpoints": True,
        "checkpoint_interval": 3  # More frequent checkpoints
    }
}
```

**Issue**: Slow processing with PDF documents
**Solution**: Disable unnecessary PDF features:
```python
config = {
    "document": {
        "loaders": {
            "pdf": {
                "extract_images": False,
                "ocr_enabled": False,
                "fix_cross_page_sentences": False
            }
        }
    }
}
```

#### LLM Service Issues

**Issue**: OpenAI rate limits
**Solution**: Adjust rate limiting settings:
```python
config = {
    "llm_services": {
        "remote": {
            "rate_limit_tokens": 60000,  # Reduce token usage
            "rate_limit_requests": 50  # Reduce requests per minute
        }
    }
}
```

**Issue**: Local LLM not responding
**Solution**: Check connection settings and increase timeout:
```python
config = {
    "llm_services": {
        "local": {
            "url": "http://localhost:11434/api",  # Verify URL
            "timeout": 120  # Increase timeout
        }
    }
}
```

### Logging and Debugging

To enable detailed logging for troubleshooting:

```python
from semantic_qa_gen import SemanticQAGen
import logging

# Enable debug logging
logging.basicConfig(level=logging.DEBUG)

# Or enable verbose mode
qa_gen = SemanticQAGen(verbose=True)
```

For CLI usage:
```bash
semantic-qa-gen process document.pdf -o output --verbose
```

### Getting Help

- **Documentation**: Visit [readthedocs.io](https://readthedocs.io)
- **GitHub Issues**: Submit bugs or feature requests on our GitHub repository
- **Community Forum**: Join our community forum for discussions and help

---

## License

SemanticQAGen is released under the MIT License.

Copyright Â© 2025 Stephen Genusa

This project builds upon concepts from the original Augmentoolkit project. SemanticQAGen is not affiliated with or endorsed by the creators of Augmentoolkit.