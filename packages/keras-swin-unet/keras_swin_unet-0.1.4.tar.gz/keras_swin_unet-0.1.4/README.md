# Swin-UNet Road Extraction: Advanced Satellite Imagery Segmentation for GIS and Urban Planning

[![TensorFlow 2.x](https://img.shields.io/badge/TensorFlow-2.10%2B-orange)](https://www.tensorflow.org/)
[![Python 3.7+](https://img.shields.io/badge/Python-3.7%2B-blue)](https://www.python.org/)

## 🚀 Key Features for Remote Sensing Professionals
**State-of-the-art deep learning solution** for road extraction from satellite imagery, combining Swin Transformers and U-Net architecture. Ideal for:

- **GIS Specialists**: Accurate geospatial analysis for urban planning
- **AI Researchers**: Cutting-edge transformer-based segmentation models
- **Civil Engineers**: Infrastructure planning with precise road network detection
- **Environmental Scientists**: Land use monitoring and change detection

### Technical Highlights 🔬
- **Transformer-Powered Segmentation**: Swin Transformer backbone for superior spatial dependency handling
- **Multi-Class Capability**: Easily extendable from binary road extraction to complex land cover classification
- **AUC Focal Loss**: Optimized for imbalanced satellite datasets (98.38% accuracy on DeepGlobe)
- **GPU-Ready Implementation**: TensorFlow 2.x optimized for rapid training on large geospatial datasets

## 📊 Performance Benchmarks (DeepGlobe Dataset)
| Metric          | Score    | Industry Comparison |
|-----------------|----------|---------------------|
| **Accuracy**    | 98.38%   | +5.2% vs U-Net      |
| **F1 Score**     | 0.8966   | +12% vs ResNet50    |
| **Inference Speed** | 35ms/img | 3x faster than D-LinkNet |

![Road Extraction Visualization](Results/3.png)
*Visual comparison showing precise road network detection in challenging terrain*

## 🛠️ Quick Start for Developers

### 1. Installation
```bash
git clone https://github.com/your-repo/swin-unet-road-extraction.git
cd swin-unet-road-extraction
pip install -r requirements.txt
## 🗂️ Dataset Preparation
Structure your satellite imagery data:
```bash
data/
├── images/  # High-res satellite images (RGB)
└── masks/   # Pixel-level road annotations
```
⚙️ **Training Configuration**

```bash
python main.py \
  --model_dir './checkpoint/' \
  --data './data/' \
  --num_classes 2 \
  --b_s 64 \
  --e 100 \
  --input_shape 512 512 3

```
🌍 **Real-World Applications**

- 🏙️ **Urban Planning**: Automated road network mapping for smart cities
- 🚨 **Disaster Response**: Rapid infrastructure assessment post-natural disasters
- 🚗 **Autonomous Navigation**: High-precision road data for self-driving systems
- 🌾 **Agricultural Logistics**: Rural road network analysis for crop distribution

📊 **Performance Insights**

**Confusion Matrix**

|                     | Predicted Road | Predicted Non-Road |
|---------------------|----------------|--------------------|
| **Actual Road**      | 2,752,25       | 72,120             |
| **Actual Non-Road**  | 64,087         | 7,977,176          |

**Metric Breakdown**

| Metric     | Formula                              | Value   |
|------------|--------------------------------------|---------|
| Precision  | TP / (TP + FP)                       | 90.11%  |
| Recall     | TP / (TP + FN)                       | 89.22%  |
| F1 Score   | 2*(Precision*Recall)/(Precision+Recall) | 0.8966  |

🔧 **Extended Capabilities**

**Multi-Class Segmentation**

```python
# Change num_classes parameter
python main.py --num_classes 5  # Roads, buildings, water, vegetation, bare soil
```
**Transfer Learning Guide**

- Start with pre-trained weights
- Fine-tune on custom satellite dataset
- Adjust window sizes:

```python
model = SwinUNet(window_size=7,  # Optimal for 512px images
                 img_size=512,
                 in_chans=3)
```
🤝 **Collaboration & Support**


**Maintainer**:  
Laeeq Aslam(laeeq.aslam.100@gmail.com)

📚 **Citations & Acknowledgements**

```bibtex
@inproceedings{liu2021swin,
  title={Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  author={Liu, Ze and others},
  booktitle={ICCV},
  year={2021}
}
